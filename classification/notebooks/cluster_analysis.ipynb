{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setup_jwlab\n",
    "from jwlab.constants import cleaned_data_filepath\n",
    "from jwlab.cluster_analysis import prep_cluster_analysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from scipy import stats\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_per_window = 10\n",
    "num_sliding_windows = int(1200/ length_per_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"904\", \"905\", \"906\", \"908\", \"909\", \"912\",\"913\", \"914\", \"916\", \"917\", \"919\",\\\n",
    "                \"920\", \"921\", \"923\", \"924\", \"927\", \"928\", \"929\", \"930\", \"932\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\",\\\n",
    "               \"904\", \"905\", \"906\", \"908\", \"909\", \"912\",\"913\", \"914\", \"916\", \"917\", \"919\",\\\n",
    "                \"920\", \"921\", \"923\", \"924\", \"927\", \"928\", \"929\", \"930\", \"932\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in participants:\n",
    "    ps =[i]\n",
    "    X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, ps, downsample_num=1000, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "    y[0]\n",
    "    np.amax(y[0])\n",
    "    unique, counts = np.unique(y[0], return_counts=True)\n",
    "    \n",
    "    print(i)\n",
    "    print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train raw test avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "Xt, yt, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"average_trials\", length_per_window=length_per_window)\n",
    "Xa, ya, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"average_trials_and_participants\", length_per_window=length_per_window)\n",
    "\n",
    "model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "#model = SVC(gamma=.001, kernel = 'rbf', C = 1e-6)\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "\n",
    "for j in range(num_sliding_windows):\n",
    "    \n",
    "        \n",
    "        model.fit(X[j], y[j])\n",
    "        \n",
    "        # validation, predict raw\n",
    "#         y_pred = model.predict(X[j])\n",
    "#         testScore = accuracy_score(y[j],y_pred)\n",
    "        \n",
    "        #predict averaged across trials\n",
    "#         y_pred = model.predict(Xt[j])\n",
    "#         testScore = accuracy_score(yt[j],y_pred)\n",
    "        \n",
    "        # predict averaged across trials and ps\n",
    "        y_pred = model.predict(Xa[j])\n",
    "        testScore = accuracy_score(ya[j],y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        if j in results.keys(): \n",
    "            results[j].append(testScore)\n",
    "        else:\n",
    "            results[j]=[]\n",
    "            results[j].append(testScore)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]\n",
    "np.amax(y[0])\n",
    "unique, counts = np.unique(y[0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sliding_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross validation\n",
    "\n",
    "#X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n",
    "# for j in range(num_sliding_windows):\n",
    "#     #model = SVC(gamma=.001, kernel = 'rbf', C=1000)\n",
    "#     model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "#     cv_results = cross_validate(model, X[j], y[j], cv=num_folds)\n",
    "#     if j in results.keys(): \n",
    "#         results[j] += cv_results['test_score'].tolist()\n",
    "#     else:\n",
    "#         results[j] = cv_results['test_score'].tolist()\n",
    "    \n",
    "\n",
    "# for i in range(num_sliding_windows):\n",
    "#     assert len(results[i]) == num_iterations * num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized order of cross val, for raw data matrix\n",
    "\n",
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "num_iterations = 5\n",
    "num_folds = 5\n",
    "\n",
    "results = {}\n",
    "for i in range(num_iterations):\n",
    "    for j in range(num_sliding_windows):\n",
    "        Xfirst = X[j]\n",
    "        yfirst = y[j]\n",
    "        Xfirst['label'] = yfirst\n",
    "        Xfirst = Xfirst.sample(frac=1).reset_index(drop=True)\n",
    "        ys = Xfirst['label']\n",
    "        Xs = Xfirst.drop(columns=['label'])\n",
    "        \n",
    "        #model = SVC(gamma=.001, kernel = 'rbf', C=1)\n",
    "        model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "        cv_results = cross_validate(model, Xs, ys, cv=num_folds)\n",
    "        if j in results.keys(): \n",
    "            results[j] += cv_results['test_score'].tolist()\n",
    "        else:\n",
    "            results[j] = cv_results['test_score'].tolist()\n",
    "    print(i)\n",
    "\n",
    "    \n",
    "for i in range(num_sliding_windows):\n",
    "    assert len(results[i]) == num_iterations * num_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "# Cross validation with RepeatedKFold for averaged matrices\n",
    "\n",
    "#Xwin, ywin, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\", length_per_window=length_per_window)\n",
    "Xwin, ywin, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "num_iterations = 3\n",
    "num_folds = 5\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "\n",
    "\n",
    "\n",
    "results = {}\n",
    "for j in range(num_sliding_windows):\n",
    "    X = Xwin[j]\n",
    "    y = ywin[j]\n",
    "\n",
    "    #model = SVC(gamma=.001, kernel = 'rbf', C=1e-4)\n",
    "    model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "    rkf = RepeatedKFold(n_splits=num_folds, n_repeats=num_iterations, random_state=2652124)\n",
    "    for train_index, test_index in rkf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        testScore = accuracy_score(y_test,y_pred)\n",
    "\n",
    "        if j in results.keys(): \n",
    "            results[j].append(testScore)\n",
    "        else:\n",
    "            results[j]=[]\n",
    "            results[j].append(testScore)\n",
    "    \n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    assert len(results[i]) == num_iterations * num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMean = []\n",
    "stdev = []\n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    scoreMean.append(np.mean(results[i]))\n",
    "    stdev.append(np.std(results[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36962962962962964"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scoreMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5666666666666667,\n",
       " 0.4666666666666667,\n",
       " 0.4888888888888889,\n",
       " 0.5888888888888889,\n",
       " 0.5222222222222223,\n",
       " 0.41111111111111115,\n",
       " 0.4,\n",
       " 0.27222222222222225,\n",
       " 0.3777777777777777,\n",
       " 0.49444444444444435,\n",
       " 0.5722222222222223,\n",
       " 0.5888888888888889,\n",
       " 0.5833333333333333,\n",
       " 0.6277777777777777,\n",
       " 0.5888888888888888,\n",
       " 0.3722222222222222,\n",
       " 0.4166666666666667,\n",
       " 0.3888888888888889,\n",
       " 0.3111111111111111,\n",
       " 0.26666666666666666,\n",
       " 0.27222222222222225,\n",
       " 0.31111111111111106,\n",
       " 0.3611111111111111,\n",
       " 0.32222222222222224,\n",
       " 0.2722222222222222,\n",
       " 0.2944444444444444,\n",
       " 0.29444444444444445,\n",
       " 0.27777777777777773,\n",
       " 0.31666666666666665,\n",
       " 0.31666666666666665,\n",
       " 0.2777777777777778,\n",
       " 0.31666666666666665,\n",
       " 0.3111111111111111,\n",
       " 0.27222222222222225,\n",
       " 0.2722222222222222,\n",
       " 0.29444444444444445,\n",
       " 0.3277777777777778,\n",
       " 0.3722222222222222,\n",
       " 0.4111111111111111,\n",
       " 0.42777777777777776,\n",
       " 0.3333333333333333,\n",
       " 0.3333333333333333,\n",
       " 0.31666666666666665,\n",
       " 0.29444444444444445,\n",
       " 0.29444444444444445,\n",
       " 0.29444444444444445,\n",
       " 0.3388888888888889,\n",
       " 0.3,\n",
       " 0.3166666666666667,\n",
       " 0.35555555555555557,\n",
       " 0.3,\n",
       " 0.26111111111111107,\n",
       " 0.26111111111111107,\n",
       " 0.26111111111111107,\n",
       " 0.26111111111111107,\n",
       " 0.2222222222222222,\n",
       " 0.2444444444444444,\n",
       " 0.26666666666666666,\n",
       " 0.3055555555555555,\n",
       " 0.33888888888888885,\n",
       " 0.35,\n",
       " 0.3888888888888889,\n",
       " 0.3888888888888889,\n",
       " 0.40555555555555556,\n",
       " 0.40555555555555556,\n",
       " 0.4277777777777778,\n",
       " 0.43888888888888894,\n",
       " 0.46111111111111114,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5166666666666667,\n",
       " 0.49444444444444446,\n",
       " 0.49444444444444446,\n",
       " 0.4722222222222222,\n",
       " 0.4944444444444444,\n",
       " 0.4388888888888889,\n",
       " 0.4388888888888889,\n",
       " 0.4166666666666667,\n",
       " 0.4166666666666667,\n",
       " 0.44444444444444453,\n",
       " 0.3222222222222222,\n",
       " 0.32222222222222213,\n",
       " 0.32222222222222213,\n",
       " 0.32222222222222213,\n",
       " 0.2777777777777778,\n",
       " 0.2777777777777778,\n",
       " 0.29999999999999993,\n",
       " 0.2555555555555556,\n",
       " 0.2555555555555556,\n",
       " 0.23333333333333336,\n",
       " 0.2555555555555556,\n",
       " 0.2555555555555556,\n",
       " 0.2555555555555556,\n",
       " 0.2388888888888889,\n",
       " 0.21111111111111114,\n",
       " 0.23333333333333336,\n",
       " 0.2611111111111111,\n",
       " 0.2833333333333333,\n",
       " 0.29999999999999993,\n",
       " 0.29999999999999993,\n",
       " 0.2833333333333333,\n",
       " 0.29999999999999993,\n",
       " 0.36111111111111105,\n",
       " 0.3666666666666666,\n",
       " 0.38333333333333325,\n",
       " 0.34444444444444433,\n",
       " 0.32222222222222213,\n",
       " 0.3166666666666666,\n",
       " 0.3944444444444445,\n",
       " 0.3722222222222223,\n",
       " 0.45555555555555555,\n",
       " 0.4611111111111112,\n",
       " 0.4611111111111112,\n",
       " 0.4611111111111112,\n",
       " 0.5222222222222223,\n",
       " 0.5611111111111111,\n",
       " 0.5833333333333334]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21773242158072695,\n",
       " 0.17159383568311665,\n",
       " 0.24507494444569752,\n",
       " 0.2182986967154278,\n",
       " 0.21184084405486245,\n",
       " 0.26258449551325497,\n",
       " 0.24190601174530268,\n",
       " 0.22457092146008598,\n",
       " 0.21271321910085164,\n",
       " 0.29260431293919315,\n",
       " 0.2561587085199667,\n",
       " 0.29731307022799225,\n",
       " 0.305807976544953,\n",
       " 0.23346557099389662,\n",
       " 0.24241582476968254,\n",
       " 0.1992269008560123,\n",
       " 0.2527625148017183,\n",
       " 0.15713484026367724,\n",
       " 0.18121673811444547,\n",
       " 0.1699673171197595,\n",
       " 0.1442306109527463,\n",
       " 0.09844469525927414,\n",
       " 0.2446968393949471,\n",
       " 0.24507494444569752,\n",
       " 0.2051798368068821,\n",
       " 0.227438772116208,\n",
       " 0.24507494444569755,\n",
       " 0.25579698740491863,\n",
       " 0.23213980461973532,\n",
       " 0.2621139136018989,\n",
       " 0.25579698740491863,\n",
       " 0.26211391360189884,\n",
       " 0.2499382639822665,\n",
       " 0.22457092146008598,\n",
       " 0.22457092146008595,\n",
       " 0.2127132191008516,\n",
       " 0.2695446549046267,\n",
       " 0.2702308112670069,\n",
       " 0.22865684030285197,\n",
       " 0.2431785403137699,\n",
       " 0.25276251480171835,\n",
       " 0.25276251480171835,\n",
       " 0.23213980461973532,\n",
       " 0.2127132191008516,\n",
       " 0.2127132191008516,\n",
       " 0.2127132191008516,\n",
       " 0.24807903957517893,\n",
       " 0.22730302828309756,\n",
       " 0.2321398046197353,\n",
       " 0.2660873336628455,\n",
       " 0.29938207967349956,\n",
       " 0.2769989080515091,\n",
       " 0.2769989080515091,\n",
       " 0.2769989080515091,\n",
       " 0.2769989080515091,\n",
       " 0.2629368792488718,\n",
       " 0.257240820062005,\n",
       " 0.2494438257849294,\n",
       " 0.2270312971300283,\n",
       " 0.19594657876164884,\n",
       " 0.25855725062711327,\n",
       " 0.2539806544591658,\n",
       " 0.2539806544591658,\n",
       " 0.23544022333796769,\n",
       " 0.25251818171918916,\n",
       " 0.2597482161680213,\n",
       " 0.25903429393055033,\n",
       " 0.23346557099389662,\n",
       " 0.2581988897471611,\n",
       " 0.2581988897471611,\n",
       " 0.2581988897471611,\n",
       " 0.2581988897471611,\n",
       " 0.2581988897471611,\n",
       " 0.2656229575084871,\n",
       " 0.23661710487829837,\n",
       " 0.23661710487829837,\n",
       " 0.26469176110159104,\n",
       " 0.29260431293919315,\n",
       " 0.3110118889395201,\n",
       " 0.3110118889395201,\n",
       " 0.28054180384339106,\n",
       " 0.2950204010522612,\n",
       " 0.2681670752477149,\n",
       " 0.24507494444569752,\n",
       " 0.21271321910085164,\n",
       " 0.21271321910085164,\n",
       " 0.21271321910085164,\n",
       " 0.16573815433529218,\n",
       " 0.20563061692579718,\n",
       " 0.22730302828309756,\n",
       " 0.17864372434237252,\n",
       " 0.17864372434237252,\n",
       " 0.14337208778404378,\n",
       " 0.17864372434237252,\n",
       " 0.17864372434237252,\n",
       " 0.17864372434237252,\n",
       " 0.18970412309959858,\n",
       " 0.1517388920416407,\n",
       " 0.18807012088678618,\n",
       " 0.21702249982916233,\n",
       " 0.23921166824012205,\n",
       " 0.22730302828309756,\n",
       " 0.22730302828309756,\n",
       " 0.23921166824012205,\n",
       " 0.22730302828309756,\n",
       " 0.24469683939494707,\n",
       " 0.24305158726919285,\n",
       " 0.25603819159562025,\n",
       " 0.25974821616802124,\n",
       " 0.27363578568943886,\n",
       " 0.21343747458109497,\n",
       " 0.23067266102251882,\n",
       " 0.2506780927261884,\n",
       " 0.20831481399169638,\n",
       " 0.21914536581462243,\n",
       " 0.21914536581462246,\n",
       " 0.21914536581462243,\n",
       " 0.17338318371474704,\n",
       " 0.2140151142695358,\n",
       " 0.20637972912229677]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test\n",
    "accuracy_by_guessing = [0.5] * (num_iterations * num_folds)\n",
    "pvalues = []\n",
    "for i in range(num_sliding_windows):\n",
    "    istat = stats.ttest_1samp(results[i], .5)\n",
    "    pvalues += [istat.pvalue] if istat.statistic > 0 else [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding contiguous time cluster\n",
    "valid_window = [i for i,v in enumerate(pvalues) if v <= 0.025]\n",
    "print(valid_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
