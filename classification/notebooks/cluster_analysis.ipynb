{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analyses Regression by Rohan adapted from Jenn's repo.\n",
    "\n",
    "This code splits the df into windows of a specified length. \n",
    "The result is a list with each cell containing time_length X channels. \n",
    "The raw data contains 200ms of a prewindow and 1000ms of the test window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setup_jwlab\n",
    "from jwlab.constants import cleaned_data_filepath\n",
    "from jwlab.cluster_analysis import prep_cluster_analysis, prep_raw_pred_avg\n",
    "from jwlab.ml_prep import  average_trials_and_participants, average_trials\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from scipy import stats\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import kurtosis, skew\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import more_itertools as mit\n",
    "from regression.functions import get_w2v_embeds_from_dict, two_vs_two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "length_per_window = 100 #just change this, do not alter the prep files\n",
    "num_sliding_windows = int(1200/ length_per_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# all 9m \n",
    "participants = [\"904\"]#, \"905\", \"906\", \"908\", \"909\",  \"910\",\"912\",\"913\", \"914\", \"916\", \"917\", \"919\",\\\n",
    "#                 \"920\", \"921\",  \"923\",\"924\", \"927\", \"928\", \"929\", \"930\", \"932\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #subset 9m\n",
    "participants = [\"904\", \"905\", \"906\", \"908\", \"909\",\"910\", \"912\", \"913\", \"914\",  \"916\", \"917\", \"921\", \"923\", \"927\", \"929\", \"930\", \"932\"] \n",
    "# removed: 919, 920, 924, 928\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "participants = [\"106\", \"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\",  \"120\", \"121\", \"122\", \"124\"]\n",
    "# missing 105, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "participants = [\"106\", \"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\",\\\n",
    "               \"904\", \"905\", \"906\", \"908\", \"910\", \"909\", \"912\",\"913\", \"914\", \"916\", \"917\", \"919\",\\\n",
    "                \"920\",  \"923\",\"921\", \"924\", \"927\", \"928\", \"929\", \"930\", \"932\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial count code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#get trial counts\n",
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "for i in participants:\n",
    "    ps =[i]\n",
    "    X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, ps, downsample_num=1000, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "    y[0]\n",
    "    np.amax(y[0])\n",
    "    unique, counts = np.unique(y[0], return_counts=True)\n",
    "    \n",
    "    print(i)\n",
    "    print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(cleaned_data_filepath)\n",
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train raw test avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_iter = 10\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_iter): \n",
    "\n",
    "    X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_average_labels\", length_per_window=length_per_window)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, X_test_t, y_test_t, X_test_pt, y_test_pt = prep_raw_pred_avg(X, participants, length_per_window, num_sliding_windows)\n",
    "#     print(\"y_train\", y_train)\n",
    "#     print(\"y_test\", y_test)\n",
    "#     print(\"y_test_t\", y_test_t)\n",
    "#     print(\"y_test_pt\", y_test_pt)\n",
    "    ## Now get a list of word embeddings from the labels.\n",
    "#     y_train_labels = get_w2v_embeds_from_dict(y_train[0])\n",
    "#     y_test_labels = get_w2v_embeds_from_dict(y_train[1])\n",
    "#     y_test_t_labels = get_w2v_embeds_from_dict(y_test_t)\n",
    "#     y_test_pt_labels = get_w2v_embeds_from_dict(y_test_pt)\n",
    "#     print(y_train_labels)\n",
    "#     print(y_test_labels)\n",
    "#     break\n",
    "    \n",
    "    model = Ridge()\n",
    "    #model = SVC(gamma=.001, kernel = 'rbf', C = 100)\n",
    "\n",
    "\n",
    "    for j in range(num_sliding_windows):\n",
    "        \n",
    "        y_train_labels = get_w2v_embeds_from_dict(y_train[j])\n",
    "        y_test_labels = get_w2v_embeds_from_dict(y_test[j])\n",
    "        y_test_t_labels = get_w2v_embeds_from_dict(y_test_t[j])\n",
    "        y_test_pt_labels = get_w2v_embeds_from_dict(y_test_pt[j])\n",
    "        \n",
    "        model.fit(X_train[j], y_train_labels)\n",
    "\n",
    "        ## validation, predict raw\n",
    "        y_pred = model.predict(X_test[j])\n",
    "        points, total_points, testScore = two_vs_two(y_test_labels, y_pred)\n",
    "#         print(testScore)\n",
    "#         break\n",
    "\n",
    "        ## predict averaged across trials\n",
    "#         y_pred = model.predict(X_test_t[j])\n",
    "#         testScore = two_vs_two(y_test_t[j],y_pred)\n",
    "\n",
    "#         ## predict averaged across trials and ps\n",
    "#         y_pred = model.predict(X_test_pt[j])\n",
    "#         testScore = two_vs_two(y_test_pt[j],y_pred)\n",
    "\n",
    "\n",
    "        if j in results.keys(): \n",
    "            results[j].append(testScore)\n",
    "        else:\n",
    "            results[j]=[]\n",
    "            results[j].append(testScore)\n",
    "    print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train[0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537962962962963\n",
      "[0.4333333333333333, 0.4222222222222222, 0.6888888888888889, 0.6222222222222222, 0.5555555555555556, 0.4888888888888888, 0.6111111111111112, 0.5333333333333333, 0.6222222222222222, 0.5444444444444445, 0.4444444444444445, 0.4888888888888888]\n",
      "[0.06, 0.06, 0.07, 0.06, 0.05, 0.07, 0.05, 0.05, 0.06, 0.05, 0.04, 0.06]\n"
     ]
    }
   ],
   "source": [
    "scoreMean = []\n",
    "sem = []\n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    scoreMean.append(np.mean(results[i]))\n",
    "    sem.append(round(stats.sem(results[i]), 2))\n",
    "    #stdev.append(np.std(results[i]))\n",
    "\n",
    "print(np.mean(scoreMean))\n",
    "print(scoreMean)\n",
    "print(sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (13,) and (12,)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-7412593e8b43>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0msem\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msem\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msem\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'k-'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfill_between\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_graph\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_graph\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2761\u001B[0m     return gca().plot(\n\u001B[0;32m   2762\u001B[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001B[1;32m-> 2763\u001B[1;33m         is not None else {}), **kwargs)\n\u001B[0m\u001B[0;32m   2764\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2765\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1645\u001B[0m         \"\"\"\n\u001B[0;32m   1646\u001B[0m         \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcbook\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize_kwargs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmlines\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLine2D\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1647\u001B[1;33m         \u001B[0mlines\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_lines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1648\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlines\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1649\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_line\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    214\u001B[0m                 \u001B[0mthis\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    215\u001B[0m                 \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 216\u001B[1;33m             \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_plot_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    217\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    218\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_next_color\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m_plot_args\u001B[1;34m(self, tup, kwargs)\u001B[0m\n\u001B[0;32m    340\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    341\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 342\u001B[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001B[0m\u001B[0;32m    343\u001B[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001B[0;32m    344\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m2\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: x and y must have same first dimension, but have shapes (13,) and (12,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot results:\n",
    "\n",
    "x_graph = np.arange(-200,1000,length_per_window)\n",
    "y_graph = scoreMean\n",
    "sem = np.array(sem)\n",
    "error = sem\n",
    "plt.plot(x_graph, y_graph, 'k-')\n",
    "plt.fill_between(x_graph, y_graph-error, y_graph+error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get t-mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stats.ttest_1samp(results[i], .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pvalues = []\n",
    "tvalues = []\n",
    "for i in range(len(results)):\n",
    "    # change the second argument below for comparison\n",
    "    istat = stats.ttest_1samp(results[i], .5)\n",
    "    pvalues += [istat.pvalue] if istat.statistic > 0 else [1]\n",
    "    tvalues += [istat.statistic] if istat.statistic > 0 else [0]\n",
    "\n",
    "valid_window = [i for i,v in enumerate(pvalues) if v <= 0.025]\n",
    "print(\"Valid windows are: {0}\\n\".format(valid_window))\n",
    "\n",
    "# Obtain clusters (3 or more consecutive meaningful time)\n",
    "clusters = [list(group) for group in mit.consecutive_groups(valid_window)]\n",
    "clusters = [group for group in clusters if len(group) >= 3]\n",
    "\n",
    "adj_clusters = []\n",
    "for c in clusters: \n",
    "    new_list = [((x*10)-200) for x in c]\n",
    "    adj_clusters.append(new_list)\n",
    "print(\"Clusters are: {0}\\n\".format(adj_clusters))\n",
    "\n",
    "t_mass = [0]\n",
    "for c in clusters:\n",
    "    t_scores = 0\n",
    "    for time in c:\n",
    "        t_scores += tvalues[time]\n",
    "    t_mass += [t_scores]\n",
    "\n",
    "max_t_mass = max(t_mass)\n",
    "print(\"The max t mass is: {0}\\n\".format(max_t_mass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "num_iter = 10\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "for i in range(num_iter): \n",
    "\n",
    "    X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_average_labels\", length_per_window=length_per_window)\n",
    "    #remap x labels\n",
    "    \n",
    "    \n",
    "    X_train, y_train, X_test, y_test, X_test_t, y_test_t, X_test_pt, y_test_pt = prep_raw_pred_avg(X, participants, length_per_window, num_sliding_windows)\n",
    "\n",
    "    \n",
    "    model = LinearSVC(C=1e-9, max_iter=1000)\n",
    "    #model = SVC(gamma=.001, kernel = 'rbf', C = 100)\n",
    "\n",
    "\n",
    "    for j in range(num_sliding_windows):\n",
    "\n",
    "            model.fit(X_train[j], y_train[j])\n",
    "\n",
    "            # validation, predict raw\n",
    "    #         y_pred = model.predict(X_train[j])\n",
    "    #         testScore = accuracy_score(y_train[j],y_pred)\n",
    "\n",
    "            # predict averaged across trials\n",
    "#             y_pred = model.predict(X_test_t[j])\n",
    "#             testScore = accuracy_score(y_test_t[j],y_pred)\n",
    "\n",
    "            # predict averaged across trials and ps\n",
    "            y_pred = model.predict(X_test_pt[j])\n",
    "            testScore = accuracy_score(y_test_pt[j],y_pred)\n",
    "\n",
    "\n",
    "            if j in results.keys(): \n",
    "                results[j].append(testScore)\n",
    "            else:\n",
    "                results[j]=[]\n",
    "                results[j].append(testScore)\n",
    "                \n",
    "    print(i)\n",
    "\n",
    "pvalues = []\n",
    "for i in range(len(results)):\n",
    "    # change the second argument below for comparison\n",
    "    istat = stats.ttest_1samp(results[i], .5)\n",
    "    pvalues += [istat.pvalue] if istat.statistic > 0 else [1]\n",
    "\n",
    "valid_window = [i for i,v in enumerate(pvalues) if v <= 0.025]\n",
    "print(\"Valid windows are: {0}\\n\".format(valid_window))\n",
    "\n",
    "# Obtain clusters (3 or more consecutive meaningful time)\n",
    "clusters = [list(group) for group in mit.consecutive_groups(valid_window)]\n",
    "clusters = [group for group in clusters if len(group) >= 3]\n",
    "\n",
    "adj_clusters = []\n",
    "for c in clusters: \n",
    "    new_list = [((x*10)-200) for x in c]\n",
    "    adj_clusters.append(new_list)\n",
    "print(\"Clusters are: {0}\\n\".format(adj_clusters))\n",
    "\n",
    "t_mass = []\n",
    "for c in clusters:\n",
    "    t_scores = 0\n",
    "    for time in c:\n",
    "        t_scores += pvalues[time]\n",
    "    t_mass += [t_scores]\n",
    "\n",
    "max_t_mass = max(t_mass)\n",
    "print(\"The max t mass is: {0}\\n\".format(max_t_mass))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "For raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Randomized order of cross val, for raw data matrix\n",
    "\n",
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "num_iterations = 5\n",
    "num_folds = 5\n",
    "\n",
    "results = {}\n",
    "for i in range(num_iterations):\n",
    "    for j in range(num_sliding_windows):\n",
    "        Xfirst = X[j]\n",
    "        yfirst = y[j]\n",
    "        Xfirst['label'] = yfirst\n",
    "        Xfirst = Xfirst.sample(frac=1).reset_index(drop=True) #randomization\n",
    "        ys = Xfirst['label']\n",
    "        Xs = Xfirst.drop(columns=['label'])\n",
    "        \n",
    "        #model = SVC(gamma=.001, kernel = 'rbf', C=1)\n",
    "        model = LinearSVC(C=1, max_iter=5000)\n",
    "        cv_results = cross_validate(model, Xs, ys, cv=num_folds)\n",
    "        if j in results.keys(): \n",
    "            results[j] += cv_results['test_score'].tolist()\n",
    "        else:\n",
    "            results[j] = cv_results['test_score'].tolist()\n",
    "    print(i)\n",
    "\n",
    "    \n",
    "for i in range(num_sliding_windows):\n",
    "    assert len(results[i]) == num_iterations * num_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X[0].shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "For averaged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cross validation with RepeatedKFold for averaged matrices\n",
    "\n",
    "#Xwin, ywin, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\", length_per_window=length_per_window)\n",
    "#Xwin, ywin, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "num_iterations = 3\n",
    "num_folds = 5\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "\n",
    "\n",
    "\n",
    "results = {}\n",
    "for j in range(num_sliding_windows):\n",
    "    X = Xwin[j]\n",
    "    y = ywin[j]\n",
    "\n",
    "    #model = SVC(gamma=.001, kernel = 'rbf', C=1e-4)\n",
    "    model = LinearSVC(C=1, max_iter=5000)\n",
    "    rkf = RepeatedKFold(n_splits=num_folds, n_repeats=num_iterations, random_state=2652124)\n",
    "    for train_index, test_index in rkf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        testScore = accuracy_score(y_test,y_pred)\n",
    "\n",
    "        if j in results.keys(): \n",
    "            results[j].append(testScore)\n",
    "        else:\n",
    "            results[j]=[]\n",
    "            results[j].append(testScore)\n",
    "    \n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    assert len(results[i]) == num_iterations * num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoreMean = []\n",
    "stdev = []\n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    scoreMean.append(np.mean(results[i]))\n",
    "    stdev.append(np.std(results[i]))\n",
    "\n",
    "print( np.mean(scoreMean))\n",
    "print(scoreMean)\n",
    "print(stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# T-test\n",
    "accuracy_by_guessing = [0.5] * (num_iterations * num_folds)\n",
    "pvalues = []\n",
    "for i in range(num_sliding_windows):\n",
    "    istat = stats.ttest_1samp(results[i], .5)\n",
    "    pvalues += [istat.pvalue] if istat.statistic > 0 else [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Finding contiguous time cluster\n",
    "valid_window = [i for i,v in enumerate(pvalues) if v <= 0.025]\n",
    "print(valid_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\", length_per_window=length_per_window)\n",
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "\n",
    "for k in range(len(X)):\n",
    "    X[k] = pd.DataFrame(data=X[k][0:,0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Normalization \n",
    "\n",
    "\n",
    "#funcs = [np.mean, np.min, np.max, np.var, skew, kurtosis]\n",
    "funcs = [np.mean, np.min, np.max, np.var]\n",
    "\n",
    "df_feats_list = []\n",
    "\n",
    "for j in range(num_sliding_windows):  \n",
    "    df_feats = X[j].apply(funcs, axis=1)\n",
    "    \n",
    "    # calc skew\n",
    "    skew_j = skew(X[j], axis = 1)\n",
    "    df_feats['skew'] = skew_j\n",
    "\n",
    "    # calc kurtosis\n",
    "    kurt_j = kurtosis(X[j], axis = 1)\n",
    "    df_feats['kurtosis'] = kurt_j\n",
    "\n",
    "\n",
    "    \n",
    "    #normalize: (x-xmin)/(max-min)\n",
    "\n",
    "    # Get column names first\n",
    "    names = df_feats.columns\n",
    "\n",
    "    normalized_df = []\n",
    "    for i in names: \n",
    "        x_array = np.array(df_feats[i])\n",
    "        normalized_X = preprocessing.normalize([x_array])\n",
    "        normalized_df.append(normalized_X)\n",
    "    \n",
    "    \n",
    "    df_1 = pd.DataFrame(np.concatenate(normalized_df))\n",
    "    df = df_1.T #transpose\n",
    "    df.columns= ['mean', 'amin', 'amax', 'var', 'skew', 'kurtosis']\n",
    "\n",
    "    \n",
    "\n",
    "    #put all windows together into a list\n",
    "    df_feats_list.append(df)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Standarization: \n",
    "\n",
    "# #funcs = [np.mean, np.min, np.max, np.var, skew, kurtosis]\n",
    "# funcs = [np.mean, np.min, np.max, np.var]\n",
    "\n",
    "# df_feats_list = []\n",
    "\n",
    "# for j in range(num_sliding_windows):  \n",
    "#     df_feats = X[j].apply(funcs, axis=1)\n",
    "    \n",
    "#     # calc skew\n",
    "#     skew_j = skew(X[j], axis = 1)\n",
    "#     df_feats['skew'] = skew_j\n",
    "\n",
    "#     # calc kurtosis\n",
    "#     kurt_j = kurtosis(X[j], axis = 1)\n",
    "#     df_feats['kurtosis'] = kurt_j\n",
    "\n",
    "\n",
    "#     #standarized: (x-mean)/(stdev)\n",
    "\n",
    "#      # Get column names first\n",
    "#     names = df_feats.columns\n",
    "\n",
    "#     # Create the Scaler object\n",
    "#     scaler = preprocessing.StandardScaler()\n",
    "#     # Fit your data on the scaler object\n",
    "#     scaled_df = scaler.fit_transform(df_feats)\n",
    "#     scaled_df = pd.DataFrame(scaled_df, columns=names)\n",
    "\n",
    "#     #put all windows together into a list\n",
    "#     df_feats_list.append(scaled_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross val on extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "num_iterations = 5\n",
    "num_folds = 5\n",
    "\n",
    "results = {}\n",
    "for i in range(num_iterations):\n",
    "    for j in range(num_sliding_windows):\n",
    "        Xfirst = df_feats_list[j]\n",
    "        yfirst = y[j]\n",
    "        Xfirst['label'] = yfirst\n",
    "        Xfirst = Xfirst.sample(frac=1).reset_index(drop=True) #randomization\n",
    "        ys = Xfirst['label']\n",
    "        Xs = Xfirst.drop(columns=['label'])\n",
    "        \n",
    "        #model = SVC(gamma=.001, kernel = 'rbf', C=100)\n",
    "        model = LinearSVC(C=1e-3, max_iter=1000)\n",
    "        cv_results = cross_validate(model, Xs, ys, cv=num_folds)\n",
    "        if j in results.keys(): \n",
    "            results[j] += cv_results['test_score'].tolist()\n",
    "        else:\n",
    "            results[j] = cv_results['test_score'].tolist()\n",
    "    print(i)\n",
    "\n",
    "    \n",
    "for i in range(num_sliding_windows):\n",
    "    assert len(results[i]) == num_iterations * num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoreMean = []\n",
    "stdev = []\n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    scoreMean.append(np.mean(results[i]))\n",
    "    stdev.append(np.std(results[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoreMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max(scoreMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# T-test\n",
    "accuracy_by_guessing = [0.5] * (num_iterations * num_folds)\n",
    "pvalues = []\n",
    "for i in range(num_sliding_windows):\n",
    "    istat = stats.ttest_1samp(results[i], .5)\n",
    "    pvalues += [istat.pvalue] if istat.statistic > 0 else [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Finding contiguous time cluster\n",
    "valid_window = [i for i,v in enumerate(pvalues) if v <= 0.025]\n",
    "print(valid_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#plot results:\n",
    "\n",
    "x_graph = np.arange(-200,1000,length_per_window)\n",
    "y_graph = scoreMean\n",
    "stdev = np.array(stdev)\n",
    "error = stdev\n",
    "plt.plot(x_graph, y_graph, 'k-')\n",
    "plt.fill_between(x_graph, y_graph-error, y_graph+error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}