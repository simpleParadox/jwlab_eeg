{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analyses\n",
    "\n",
    "This code splits the df into windows of a specified length. \n",
    "The result is a list with each cell containing time_length X channels. \n",
    "The raw data contains 200ms of a prewindow and 1000ms of the test window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setup_jwlab\n",
    "from jwlab.constants import cleaned_data_filepath\n",
    "from jwlab.cluster_analysis import prep_cluster_analysis, prep_raw_pred_avg\n",
    "from jwlab.ml_prep import  average_trials_and_participants, average_trials\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from scipy import stats\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import kurtosis, skew\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_per_window = 10 #just change this, do not alter the prep files\n",
    "num_sliding_windows = int(1200/ length_per_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"904\", \"905\", \"906\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all 9m \n",
    "participants = [\"904\", \"905\", \"906\", \"908\", \"910\", \"909\", \"912\",\"913\", \"914\", \"916\", \"917\", \"919\",\\\n",
    "                \"920\",  \"923\",\"921\", \"924\", \"927\", \"928\", \"929\", \"930\", \"932\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #subset 9m\n",
    "# participants = [\"904\", \"905\", \"906\", \"908\", \"909\",\"910\", \"912\", \"913\", \"914\",  \"916\", \"917\", \"921\", \"923\", \"927\", \"929\", \"930\", \"932\"] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"106\", \"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"106\", \"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\",\\\n",
    "               \"904\", \"905\", \"906\", \"908\", \"909\", \"912\",\"913\", \"914\", \"916\", \"917\", \"919\",\\\n",
    "                \"920\", \"921\", \"923\", \"924\", \"927\", \"928\", \"929\", \"930\", \"932\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial count code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get trial counts\n",
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "for i in participants:\n",
    "    ps =[i]\n",
    "    X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, ps, downsample_num=1000, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "    y[0]\n",
    "    np.amax(y[0])\n",
    "    unique, counts = np.unique(y[0], return_counts=True)\n",
    "    \n",
    "    print(i)\n",
    "    print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train raw test avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4e07d5e52174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood_trial_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_cluster_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_data_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"no_average_labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_per_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength_per_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_pt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_raw_pred_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_per_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sliding_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Studies/Animates EEG/8_Github/jwlab_eeg/classification/notebooks/../code/jwlab/cluster_analysis.py\u001b[0m in \u001b[0;36mprep_cluster_analysis\u001b[0;34m(filepath, participants, downsample_num, averaging, length_per_window)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprep_cluster_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"average_trials_and_participants\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_per_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ml_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprep_cluster_analysis_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownsample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maveraging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_per_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength_per_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Studies/Animates EEG/8_Github/jwlab_eeg/classification/notebooks/../code/jwlab/cluster_analysis.py\u001b[0m in \u001b[0;36mload_ml_data\u001b[0;34m(filepath, participants)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# read all participant csvs, concat them into one dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     dfs = [pd.read_csv(\"%s%s_cleaned_ml.csv\" % (filepath, s))\n\u001b[0;32m---> 84\u001b[0;31m            for s in participants]\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Studies/Animates EEG/8_Github/jwlab_eeg/classification/notebooks/../code/jwlab/cluster_analysis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# read all participant csvs, concat them into one dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     dfs = [pd.read_csv(\"%s%s_cleaned_ml.csv\" % (filepath, s))\n\u001b[0;32m---> 84\u001b[0;31m            for s in participants]\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m     \"\"\"\n\u001b[1;32m    680\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_iter = 1\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "for i in range(num_iter): \n",
    "\n",
    "    X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_average_labels\", length_per_window=length_per_window)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, X_test_t, y_test_t, X_test_pt, y_test_pt = prep_raw_pred_avg(X, participants, length_per_window, num_sliding_windows)\n",
    "\n",
    "    \n",
    "    model = LinearSVC(C=1e-9, max_iter=1000)\n",
    "    #model = SVC(gamma=.001, kernel = 'rbf', C = 100)\n",
    "\n",
    "\n",
    "    for j in range(num_sliding_windows):\n",
    "\n",
    "            model.fit(X_train[j], y_train[j])\n",
    "\n",
    "            # validation, predict raw\n",
    "    #         y_pred = model.predict(X_train[j])\n",
    "    #         testScore = accuracy_score(y_train[j],y_pred)\n",
    "\n",
    "            # predict averaged across trials\n",
    "#             y_pred = model.predict(X_test_t[j])\n",
    "#             testScore = accuracy_score(y_test_t[j],y_pred)\n",
    "\n",
    "            # predict averaged across trials and ps\n",
    "            y_pred = model.predict(X_test_pt[j])\n",
    "            testScore = accuracy_score(y_test_pt[j],y_pred)\n",
    "\n",
    "\n",
    "            if j in results.keys(): \n",
    "                results[j].append(testScore)\n",
    "            else:\n",
    "                results[j]=[]\n",
    "                results[j].append(testScore)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train[0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMean = []\n",
    "stdev = []\n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    scoreMean.append(np.mean(results[i]))\n",
    "    stdev.append(np.std(results[i]))\n",
    "\n",
    "print(np.mean(scoreMean))\n",
    "print(scoreMean)\n",
    "print(stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results:\n",
    "\n",
    "x_graph = np.arange(-200,1000,length_per_window)\n",
    "y_graph = scoreMean\n",
    "stdev = np.array(stdev)\n",
    "error = stdev\n",
    "plt.plot(x_graph, y_graph, 'k-')\n",
    "plt.fill_between(x_graph, y_graph-error, y_graph+error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "For raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized order of cross val, for raw data matrix\n",
    "\n",
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "num_iterations = 5\n",
    "num_folds = 5\n",
    "\n",
    "results = {}\n",
    "for i in range(num_iterations):\n",
    "    for j in range(num_sliding_windows):\n",
    "        Xfirst = X[j]\n",
    "        yfirst = y[j]\n",
    "        Xfirst['label'] = yfirst\n",
    "        Xfirst = Xfirst.sample(frac=1).reset_index(drop=True) #randomization\n",
    "        ys = Xfirst['label']\n",
    "        Xs = Xfirst.drop(columns=['label'])\n",
    "        \n",
    "        #model = SVC(gamma=.001, kernel = 'rbf', C=1)\n",
    "        model = LinearSVC(C=1, max_iter=5000)\n",
    "        cv_results = cross_validate(model, Xs, ys, cv=num_folds)\n",
    "        if j in results.keys(): \n",
    "            results[j] += cv_results['test_score'].tolist()\n",
    "        else:\n",
    "            results[j] = cv_results['test_score'].tolist()\n",
    "    print(i)\n",
    "\n",
    "    \n",
    "for i in range(num_sliding_windows):\n",
    "    assert len(results[i]) == num_iterations * num_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "For averaged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation with RepeatedKFold for averaged matrices\n",
    "\n",
    "#Xwin, ywin, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\", length_per_window=length_per_window)\n",
    "#Xwin, ywin, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "num_iterations = 3\n",
    "num_folds = 5\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "\n",
    "\n",
    "\n",
    "results = {}\n",
    "for j in range(num_sliding_windows):\n",
    "    X = Xwin[j]\n",
    "    y = ywin[j]\n",
    "\n",
    "    #model = SVC(gamma=.001, kernel = 'rbf', C=1e-4)\n",
    "    model = LinearSVC(C=1, max_iter=5000)\n",
    "    rkf = RepeatedKFold(n_splits=num_folds, n_repeats=num_iterations, random_state=2652124)\n",
    "    for train_index, test_index in rkf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        testScore = accuracy_score(y_test,y_pred)\n",
    "\n",
    "        if j in results.keys(): \n",
    "            results[j].append(testScore)\n",
    "        else:\n",
    "            results[j]=[]\n",
    "            results[j].append(testScore)\n",
    "    \n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    assert len(results[i]) == num_iterations * num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMean = []\n",
    "stdev = []\n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    scoreMean.append(np.mean(results[i]))\n",
    "    stdev.append(np.std(results[i]))\n",
    "\n",
    "print( np.mean(scoreMean))\n",
    "print(scoreMean)\n",
    "print(stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test\n",
    "accuracy_by_guessing = [0.5] * (num_iterations * num_folds)\n",
    "pvalues = []\n",
    "for i in range(num_sliding_windows):\n",
    "    istat = stats.ttest_1samp(results[i], .5)\n",
    "    pvalues += [istat.pvalue] if istat.statistic > 0 else [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding contiguous time cluster\n",
    "valid_window = [i for i,v in enumerate(pvalues) if v <= 0.025]\n",
    "print(valid_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1200, averaging=\"no_averaging\", length_per_window=length_per_window)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\", length_per_window=length_per_window)\n",
    "X, y, good_trial_count = prep_cluster_analysis(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\", length_per_window=length_per_window)\n",
    "\n",
    "\n",
    "\n",
    "for k in range(len(X)):\n",
    "    X[k] = pd.DataFrame(data=X[k][0:,0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization \n",
    "\n",
    "\n",
    "#funcs = [np.mean, np.min, np.max, np.var, skew, kurtosis]\n",
    "funcs = [np.mean, np.min, np.max, np.var]\n",
    "\n",
    "df_feats_list = []\n",
    "\n",
    "for j in range(num_sliding_windows):  \n",
    "    df_feats = X[j].apply(funcs, axis=1)\n",
    "    \n",
    "    # calc skew\n",
    "    skew_j = skew(X[j], axis = 1)\n",
    "    df_feats['skew'] = skew_j\n",
    "\n",
    "    # calc kurtosis\n",
    "    kurt_j = kurtosis(X[j], axis = 1)\n",
    "    df_feats['kurtosis'] = kurt_j\n",
    "\n",
    "\n",
    "    \n",
    "    #normalize: (x-xmin)/(max-min)\n",
    "\n",
    "    # Get column names first\n",
    "    names = df_feats.columns\n",
    "\n",
    "    normalized_df = []\n",
    "    for i in names: \n",
    "        x_array = np.array(df_feats[i])\n",
    "        normalized_X = preprocessing.normalize([x_array])\n",
    "        normalized_df.append(normalized_X)\n",
    "    \n",
    "    \n",
    "    df_1 = pd.DataFrame(np.concatenate(normalized_df))\n",
    "    df = df_1.T #transpose\n",
    "    df.columns= ['mean', 'amin', 'amax', 'var', 'skew', 'kurtosis']\n",
    "\n",
    "    \n",
    "\n",
    "    #put all windows together into a list\n",
    "    df_feats_list.append(df)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standarization: \n",
    "\n",
    "# #funcs = [np.mean, np.min, np.max, np.var, skew, kurtosis]\n",
    "# funcs = [np.mean, np.min, np.max, np.var]\n",
    "\n",
    "# df_feats_list = []\n",
    "\n",
    "# for j in range(num_sliding_windows):  \n",
    "#     df_feats = X[j].apply(funcs, axis=1)\n",
    "    \n",
    "#     # calc skew\n",
    "#     skew_j = skew(X[j], axis = 1)\n",
    "#     df_feats['skew'] = skew_j\n",
    "\n",
    "#     # calc kurtosis\n",
    "#     kurt_j = kurtosis(X[j], axis = 1)\n",
    "#     df_feats['kurtosis'] = kurt_j\n",
    "\n",
    "\n",
    "#     #standarized: (x-mean)/(stdev)\n",
    "\n",
    "#      # Get column names first\n",
    "#     names = df_feats.columns\n",
    "\n",
    "#     # Create the Scaler object\n",
    "#     scaler = preprocessing.StandardScaler()\n",
    "#     # Fit your data on the scaler object\n",
    "#     scaled_df = scaler.fit_transform(df_feats)\n",
    "#     scaled_df = pd.DataFrame(scaled_df, columns=names)\n",
    "\n",
    "#     #put all windows together into a list\n",
    "#     df_feats_list.append(scaled_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross val on extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_iterations = 5\n",
    "num_folds = 5\n",
    "\n",
    "results = {}\n",
    "for i in range(num_iterations):\n",
    "    for j in range(num_sliding_windows):\n",
    "        Xfirst = df_feats_list[j]\n",
    "        yfirst = y[j]\n",
    "        Xfirst['label'] = yfirst\n",
    "        Xfirst = Xfirst.sample(frac=1).reset_index(drop=True) #randomization\n",
    "        ys = Xfirst['label']\n",
    "        Xs = Xfirst.drop(columns=['label'])\n",
    "        \n",
    "        #model = SVC(gamma=.001, kernel = 'rbf', C=100)\n",
    "        model = LinearSVC(C=1e-3, max_iter=1000)\n",
    "        cv_results = cross_validate(model, Xs, ys, cv=num_folds)\n",
    "        if j in results.keys(): \n",
    "            results[j] += cv_results['test_score'].tolist()\n",
    "        else:\n",
    "            results[j] = cv_results['test_score'].tolist()\n",
    "    print(i)\n",
    "\n",
    "    \n",
    "for i in range(num_sliding_windows):\n",
    "    assert len(results[i]) == num_iterations * num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMean = []\n",
    "stdev = []\n",
    "\n",
    "for i in range(num_sliding_windows):\n",
    "    scoreMean.append(np.mean(results[i]))\n",
    "    stdev.append(np.std(results[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(scoreMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test\n",
    "accuracy_by_guessing = [0.5] * (num_iterations * num_folds)\n",
    "pvalues = []\n",
    "for i in range(num_sliding_windows):\n",
    "    istat = stats.ttest_1samp(results[i], .5)\n",
    "    pvalues += [istat.pvalue] if istat.statistic > 0 else [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding contiguous time cluster\n",
    "valid_window = [i for i,v in enumerate(pvalues) if v <= 0.025]\n",
    "print(valid_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results:\n",
    "\n",
    "x_graph = np.arange(-200,1000,length_per_window)\n",
    "y_graph = scoreMean\n",
    "stdev = np.array(stdev)\n",
    "error = stdev\n",
    "plt.plot(x_graph, y_graph, 'k-')\n",
    "plt.fill_between(x_graph, y_graph-error, y_graph+error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
