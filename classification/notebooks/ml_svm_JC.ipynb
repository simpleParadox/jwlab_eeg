{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setup_jwlab\n",
    "from jwlab.constants import cleaned_data_filepath\n",
    "from jwlab.ml_prep import prep_ml, prep_ml_first20, save_ml_df, prep_ml_raw, average_trials_new, average_trials_and_participants_new\n",
    "from jwlab.ml_prep_multigroup import prep_ml_multigroup\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from jwlab.constants import word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Participants.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"904\", \"905\"]\n",
    "#participants = [\"904\", \"905\", \"906\", \"909\", \"910\", \"912\", \"908\", \"913\", \"914\", \"916\", \"917\", \"919\", \"920\", \"921\", \"923\", \"924\",\"927\", \"928\", \"929\", \"930\", \"932\"]\n",
    "\n",
    "#9m with >40 trials\n",
    "#participants = [ \"909\", \"912\", \"908\", \"913\", \"914\", \"916\", \"917\", \"919\", \"920\", \"921\", \"924\",\"927\", \"930\"]\n",
    "\n",
    "#12m all\n",
    "#participants = [ \"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\"]\n",
    "\n",
    "#12m with >40 trials\n",
    "#participants = [\"109\", \"111\", \"112\", \"115\", \"124\"]\n",
    "\n",
    "#all participants\n",
    "# participants = [\"904\", \"905\", \"906\", \"909\", \"910\", \"912\", \"908\", \"913\", \"914\", \"916\", \"917\", \"919\", \"920\", \"921\", \"923\", \"924\",\"927\", \"928\", \"929\", \"930\", \"932\",\n",
    "#               \"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set up averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "X, y, good_trial_count = prep_ml_raw(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize and split\n",
    "X[0][0] = X[0][0].sample(frac=1).reset_index(drop=True)\n",
    "len(X[0][0])\n",
    "fivefold_testsize = int(.20*len(X[0][0]))\n",
    "fivefold_trainsize = len(X[0][0])- fivefold_testsize\n",
    "df_train = X[0][0][:fivefold_trainsize]\n",
    "df_test = X[0][0][:fivefold_testsize]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[             0          1          2          3          4          5  \\\n",
       " 0     1.568287   0.258826   2.369213   0.539767  -1.858165  -0.647701   \n",
       " 1     1.253755   2.377808   5.996650   4.433384   6.518006   4.154214   \n",
       " 2    -1.043779  -8.096023  -8.190574  -7.923188  -7.043860  -8.094473   \n",
       " 3     3.224830  -5.427824  -8.399541 -11.078480 -10.747657  -8.991525   \n",
       " 4     3.966432  27.550192  25.235700  22.818636   9.502732  13.774457   \n",
       " ..         ...        ...        ...        ...        ...        ...   \n",
       " 189  -6.618451  22.140377  30.444341  25.635734  25.399753  20.738769   \n",
       " 190   7.294317  -6.102833 -22.045662 -25.298935 -25.680079 -17.646832   \n",
       " 192 -57.880028   4.193850  16.717931  20.435879   4.981079  23.077141   \n",
       " 195  20.327205   7.483005   6.199234   6.256866  -9.018277   1.643158   \n",
       " 197 -28.453903 -14.257771  -2.032366   5.626649   0.949348   6.495548   \n",
       " \n",
       "              6          7          8          9  ...      59992       59993  \\\n",
       " 0     0.846586   0.932043  10.934343  -0.451569  ...  28.679571   43.198454   \n",
       " 1     2.186334  -0.931411  -6.610870   8.973655  ... -33.157430  -53.762224   \n",
       " 2    -8.226414  -6.516820   4.097326  -7.925935  ...  48.897044   43.696448   \n",
       " 3    -9.088615  -7.793615  -3.684127  -4.330630  ...  54.510742   43.942421   \n",
       " 4    16.383470  17.957616  13.174182 -15.506595  ...   9.972523  -34.474639   \n",
       " ..         ...        ...        ...        ...  ...        ...         ...   \n",
       " 189  26.738737  16.111829  -4.362554  22.616009  ... -62.615671  -36.681865   \n",
       " 190 -19.725849  -7.086067  14.344000  -6.169660  ... -22.484757   66.699915   \n",
       " 192  25.446716  21.469389 -35.407444  -7.876455  ...  16.613680 -111.151211   \n",
       " 195   3.414067  10.418564  29.937666  -6.932333  ... -73.132092 -111.289073   \n",
       " 197  10.033596  23.613823 -12.418933  -7.671032  ...   6.051831  -38.512938   \n",
       " \n",
       "          59994       59995      59996       59997       59998       59999  \\\n",
       " 0    35.671584  -16.000382  -4.871585    4.142560  -27.919238   -6.759431   \n",
       " 1   -86.602799   11.826533 -32.164831   15.709168    9.975922   11.045932   \n",
       " 2    67.156872    3.891260  29.671853    2.688699   -1.548607    6.632657   \n",
       " 3    85.423925   -1.858690  17.133770   -7.166798   -1.380435   -4.485914   \n",
       " 4   -63.247728   -0.323379  13.773431    1.944230  -11.130785    1.832643   \n",
       " ..         ...         ...        ...         ...         ...         ...   \n",
       " 189 -76.656070  -10.368772  30.705221   26.221996  -38.477639   12.817577   \n",
       " 190  33.146282   13.948075  -6.220441  -50.336738   14.900340   -8.144847   \n",
       " 192 -30.727069   37.531512  30.105898  129.313648   12.344795   57.909454   \n",
       " 195  66.244716  130.236295  29.544709  121.091974  125.516753  130.152633   \n",
       " 197 -30.086829   58.447906  24.995036  122.809000   36.469941   82.155412   \n",
       " \n",
       "      label  participant  \n",
       " 0      1.0            0  \n",
       " 1     10.0            0  \n",
       " 2      7.0            0  \n",
       " 3      8.0            0  \n",
       " 4      6.0            0  \n",
       " ..     ...          ...  \n",
       " 189    5.0            1  \n",
       " 190   13.0            1  \n",
       " 192   12.0            1  \n",
       " 195    2.0            1  \n",
       " 197    5.0            1  \n",
       " \n",
       " [110 rows x 60002 columns]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 60002)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc averages for ps\n",
    "num_participants = len(participants)\n",
    "num_words = len(word_list)\n",
    "\n",
    "X_testp, y_testp, ps_p, words_p = average_trials_new(df_test, num_participants, num_words)\n",
    "        \n",
    "#new_data and new_y contains avg and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc averages for ps and trial\n",
    "num_participants = len(participants)\n",
    "num_words = len(word_list)\n",
    "\n",
    "X_testpt, y_testpt, ps_pt, words_pt = average_trials_and_participants_new(df_test, num_participants, num_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['label']\n",
    "\n",
    "X_train = df_train.drop(columns = ['label', 'participant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59991</th>\n",
       "      <th>59992</th>\n",
       "      <th>59993</th>\n",
       "      <th>59994</th>\n",
       "      <th>59995</th>\n",
       "      <th>59996</th>\n",
       "      <th>59997</th>\n",
       "      <th>59998</th>\n",
       "      <th>59999</th>\n",
       "      <th>participant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.025561</td>\n",
       "      <td>2.821668</td>\n",
       "      <td>1.354192</td>\n",
       "      <td>-2.142615</td>\n",
       "      <td>11.336155</td>\n",
       "      <td>-4.152444</td>\n",
       "      <td>-2.091002</td>\n",
       "      <td>-3.415384</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>3.663936</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.783891</td>\n",
       "      <td>-51.763780</td>\n",
       "      <td>-10.839019</td>\n",
       "      <td>-1.379785</td>\n",
       "      <td>-0.941817</td>\n",
       "      <td>2.423776</td>\n",
       "      <td>25.240828</td>\n",
       "      <td>16.091168</td>\n",
       "      <td>18.888030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.226106</td>\n",
       "      <td>-8.968997</td>\n",
       "      <td>-7.018534</td>\n",
       "      <td>-7.623764</td>\n",
       "      <td>-15.155371</td>\n",
       "      <td>-6.685738</td>\n",
       "      <td>-1.507917</td>\n",
       "      <td>1.371341</td>\n",
       "      <td>7.471295</td>\n",
       "      <td>3.562313</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.172329</td>\n",
       "      <td>-9.658216</td>\n",
       "      <td>-18.955927</td>\n",
       "      <td>-22.915535</td>\n",
       "      <td>-26.130806</td>\n",
       "      <td>-21.348746</td>\n",
       "      <td>-21.570639</td>\n",
       "      <td>-28.130672</td>\n",
       "      <td>-23.931409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-21.440239</td>\n",
       "      <td>-11.394920</td>\n",
       "      <td>6.691976</td>\n",
       "      <td>19.928586</td>\n",
       "      <td>6.939685</td>\n",
       "      <td>35.958892</td>\n",
       "      <td>25.973378</td>\n",
       "      <td>30.300085</td>\n",
       "      <td>-30.329784</td>\n",
       "      <td>-9.361191</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.792358</td>\n",
       "      <td>-13.124541</td>\n",
       "      <td>-105.154893</td>\n",
       "      <td>-75.082496</td>\n",
       "      <td>-25.566505</td>\n",
       "      <td>20.426337</td>\n",
       "      <td>128.182099</td>\n",
       "      <td>-45.518128</td>\n",
       "      <td>24.477999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.662455</td>\n",
       "      <td>15.114633</td>\n",
       "      <td>-3.685214</td>\n",
       "      <td>-10.098062</td>\n",
       "      <td>-31.630879</td>\n",
       "      <td>-9.824709</td>\n",
       "      <td>-9.289262</td>\n",
       "      <td>-1.059709</td>\n",
       "      <td>-3.211483</td>\n",
       "      <td>-16.467025</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.633615</td>\n",
       "      <td>-25.227271</td>\n",
       "      <td>-13.470614</td>\n",
       "      <td>-19.928415</td>\n",
       "      <td>-5.038135</td>\n",
       "      <td>-18.635382</td>\n",
       "      <td>0.838223</td>\n",
       "      <td>-5.185655</td>\n",
       "      <td>-8.765579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.464834</td>\n",
       "      <td>-15.767405</td>\n",
       "      <td>-15.879229</td>\n",
       "      <td>-14.033575</td>\n",
       "      <td>-13.525173</td>\n",
       "      <td>-11.415341</td>\n",
       "      <td>-9.476569</td>\n",
       "      <td>-6.431889</td>\n",
       "      <td>6.891097</td>\n",
       "      <td>-2.698541</td>\n",
       "      <td>...</td>\n",
       "      <td>40.235585</td>\n",
       "      <td>79.385104</td>\n",
       "      <td>78.691800</td>\n",
       "      <td>71.961547</td>\n",
       "      <td>-18.500822</td>\n",
       "      <td>23.234891</td>\n",
       "      <td>-19.802306</td>\n",
       "      <td>-48.267835</td>\n",
       "      <td>-5.302885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.011107</td>\n",
       "      <td>-0.425666</td>\n",
       "      <td>4.587227</td>\n",
       "      <td>11.496941</td>\n",
       "      <td>0.599010</td>\n",
       "      <td>7.097873</td>\n",
       "      <td>10.544865</td>\n",
       "      <td>11.428293</td>\n",
       "      <td>-10.432805</td>\n",
       "      <td>-14.142159</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.445938</td>\n",
       "      <td>1.555545</td>\n",
       "      <td>-4.700431</td>\n",
       "      <td>-7.531514</td>\n",
       "      <td>5.121854</td>\n",
       "      <td>8.324526</td>\n",
       "      <td>24.742058</td>\n",
       "      <td>-2.644727</td>\n",
       "      <td>5.680951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>9.999920</td>\n",
       "      <td>-6.363606</td>\n",
       "      <td>-3.636014</td>\n",
       "      <td>-2.824049</td>\n",
       "      <td>-3.502189</td>\n",
       "      <td>-2.205377</td>\n",
       "      <td>-0.452135</td>\n",
       "      <td>0.080261</td>\n",
       "      <td>-0.182014</td>\n",
       "      <td>-4.367211</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.428820</td>\n",
       "      <td>-46.723771</td>\n",
       "      <td>51.654913</td>\n",
       "      <td>14.039964</td>\n",
       "      <td>-39.187296</td>\n",
       "      <td>-25.556754</td>\n",
       "      <td>-11.960428</td>\n",
       "      <td>-75.563740</td>\n",
       "      <td>-28.008781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>-4.167489</td>\n",
       "      <td>-4.783387</td>\n",
       "      <td>-0.143864</td>\n",
       "      <td>1.803748</td>\n",
       "      <td>4.888226</td>\n",
       "      <td>1.685998</td>\n",
       "      <td>11.039969</td>\n",
       "      <td>13.169111</td>\n",
       "      <td>1.777397</td>\n",
       "      <td>4.557585</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.918173</td>\n",
       "      <td>22.553037</td>\n",
       "      <td>-27.569104</td>\n",
       "      <td>-41.604561</td>\n",
       "      <td>30.247673</td>\n",
       "      <td>9.502596</td>\n",
       "      <td>108.050071</td>\n",
       "      <td>15.358838</td>\n",
       "      <td>47.472026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>-2.415063</td>\n",
       "      <td>-12.980877</td>\n",
       "      <td>0.472723</td>\n",
       "      <td>6.273451</td>\n",
       "      <td>17.825636</td>\n",
       "      <td>4.640987</td>\n",
       "      <td>6.232900</td>\n",
       "      <td>6.746609</td>\n",
       "      <td>-10.626613</td>\n",
       "      <td>0.339670</td>\n",
       "      <td>...</td>\n",
       "      <td>8.698651</td>\n",
       "      <td>4.078425</td>\n",
       "      <td>10.629541</td>\n",
       "      <td>24.343760</td>\n",
       "      <td>-14.279415</td>\n",
       "      <td>-4.556163</td>\n",
       "      <td>6.566625</td>\n",
       "      <td>-11.057235</td>\n",
       "      <td>0.446281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>-10.218673</td>\n",
       "      <td>13.403876</td>\n",
       "      <td>1.085590</td>\n",
       "      <td>0.102002</td>\n",
       "      <td>28.846980</td>\n",
       "      <td>-6.435735</td>\n",
       "      <td>-7.467639</td>\n",
       "      <td>10.330390</td>\n",
       "      <td>-3.590952</td>\n",
       "      <td>-2.230511</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.971901</td>\n",
       "      <td>-48.167837</td>\n",
       "      <td>11.828383</td>\n",
       "      <td>45.972760</td>\n",
       "      <td>39.797488</td>\n",
       "      <td>3.813437</td>\n",
       "      <td>70.650378</td>\n",
       "      <td>37.780972</td>\n",
       "      <td>22.462005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 60001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5  \\\n",
       "0    5.025561   2.821668   1.354192  -2.142615  11.336155  -4.152444   \n",
       "1    1.226106  -8.968997  -7.018534  -7.623764 -15.155371  -6.685738   \n",
       "2  -21.440239 -11.394920   6.691976  19.928586   6.939685  35.958892   \n",
       "3   10.662455  15.114633  -3.685214 -10.098062 -31.630879  -9.824709   \n",
       "4   13.464834 -15.767405 -15.879229 -14.033575 -13.525173 -11.415341   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "83   1.011107  -0.425666   4.587227  11.496941   0.599010   7.097873   \n",
       "84   9.999920  -6.363606  -3.636014  -2.824049  -3.502189  -2.205377   \n",
       "85  -4.167489  -4.783387  -0.143864   1.803748   4.888226   1.685998   \n",
       "86  -2.415063 -12.980877   0.472723   6.273451  17.825636   4.640987   \n",
       "87 -10.218673  13.403876   1.085590   0.102002  28.846980  -6.435735   \n",
       "\n",
       "            6          7          8          9  ...      59991      59992  \\\n",
       "0   -2.091002  -3.415384   0.031801   3.663936  ... -36.783891 -51.763780   \n",
       "1   -1.507917   1.371341   7.471295   3.562313  ... -11.172329  -9.658216   \n",
       "2   25.973378  30.300085 -30.329784  -9.361191  ... -36.792358 -13.124541   \n",
       "3   -9.289262  -1.059709  -3.211483 -16.467025  ... -15.633615 -25.227271   \n",
       "4   -9.476569  -6.431889   6.891097  -2.698541  ...  40.235585  79.385104   \n",
       "..        ...        ...        ...        ...  ...        ...        ...   \n",
       "83  10.544865  11.428293 -10.432805 -14.142159  ... -12.445938   1.555545   \n",
       "84  -0.452135   0.080261  -0.182014  -4.367211  ... -17.428820 -46.723771   \n",
       "85  11.039969  13.169111   1.777397   4.557585  ...  -8.918173  22.553037   \n",
       "86   6.232900   6.746609 -10.626613   0.339670  ...   8.698651   4.078425   \n",
       "87  -7.467639  10.330390  -3.590952  -2.230511  ... -33.971901 -48.167837   \n",
       "\n",
       "         59993      59994      59995      59996       59997      59998  \\\n",
       "0   -10.839019  -1.379785  -0.941817   2.423776   25.240828  16.091168   \n",
       "1   -18.955927 -22.915535 -26.130806 -21.348746  -21.570639 -28.130672   \n",
       "2  -105.154893 -75.082496 -25.566505  20.426337  128.182099 -45.518128   \n",
       "3   -13.470614 -19.928415  -5.038135 -18.635382    0.838223  -5.185655   \n",
       "4    78.691800  71.961547 -18.500822  23.234891  -19.802306 -48.267835   \n",
       "..         ...        ...        ...        ...         ...        ...   \n",
       "83   -4.700431  -7.531514   5.121854   8.324526   24.742058  -2.644727   \n",
       "84   51.654913  14.039964 -39.187296 -25.556754  -11.960428 -75.563740   \n",
       "85  -27.569104 -41.604561  30.247673   9.502596  108.050071  15.358838   \n",
       "86   10.629541  24.343760 -14.279415  -4.556163    6.566625 -11.057235   \n",
       "87   11.828383  45.972760  39.797488   3.813437   70.650378  37.780972   \n",
       "\n",
       "        59999  participant  \n",
       "0   18.888030            1  \n",
       "1  -23.931409            1  \n",
       "2   24.477999            1  \n",
       "3   -8.765579            1  \n",
       "4   -5.302885            0  \n",
       "..        ...          ...  \n",
       "83   5.680951            1  \n",
       "84 -28.008781            0  \n",
       "85  47.472026            1  \n",
       "86   0.446281            1  \n",
       "87  22.462005            1  \n",
       "\n",
       "[88 rows x 60001 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 60000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testpt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.45, 0.69, 0.53, 0.67, 0.25, 0.55, 0.76, 0.86, 0.7 , 0.75, 0.94,\n",
       "        0.79, 0.67, 0.8 , 0.73, 0.71, 0.8 , 0.5 , 0.57, 0.87, 0.63]), [cell\n",
       "  1    15\n",
       "  2    13\n",
       "  3    12\n",
       "  4    13\n",
       "  dtype: int64, cell\n",
       "  1    16\n",
       "  2    17\n",
       "  3    15\n",
       "  4    10\n",
       "  dtype: int64, cell\n",
       "  1     9\n",
       "  2     7\n",
       "  3     8\n",
       "  4    10\n",
       "  dtype: int64, 1     0\n",
       "  2     2\n",
       "  3     1\n",
       "  4     1\n",
       "  5     1\n",
       "  6     2\n",
       "  7     2\n",
       "  8     1\n",
       "  9     2\n",
       "  10    2\n",
       "  11    1\n",
       "  12    1\n",
       "  13    1\n",
       "  14    2\n",
       "  15    1\n",
       "  16    0\n",
       "  17    1\n",
       "  18    1\n",
       "  19    1\n",
       "  20    1\n",
       "  21    1\n",
       "  22    1\n",
       "  23    2\n",
       "  24    2\n",
       "  25    2\n",
       "  26    1\n",
       "  27    1\n",
       "  28    2\n",
       "  29    2\n",
       "  30    2\n",
       "  31    1\n",
       "  32    1\n",
       "  dtype: int64, 1     1\n",
       "  2     1\n",
       "  3     0\n",
       "  4     0\n",
       "  5     1\n",
       "  6     0\n",
       "  7     1\n",
       "  8     1\n",
       "  9     1\n",
       "  10    0\n",
       "  11    0\n",
       "  12    0\n",
       "  13    0\n",
       "  14    0\n",
       "  15    0\n",
       "  16    1\n",
       "  17    0\n",
       "  18    1\n",
       "  19    1\n",
       "  20    0\n",
       "  21    1\n",
       "  22    0\n",
       "  23    1\n",
       "  24    1\n",
       "  25    1\n",
       "  26    0\n",
       "  27    0\n",
       "  28    0\n",
       "  29    0\n",
       "  30    0\n",
       "  31    0\n",
       "  32    0\n",
       "  dtype: int64, 1     1\n",
       "  2     1\n",
       "  3     1\n",
       "  4     0\n",
       "  5     1\n",
       "  6     0\n",
       "  7     2\n",
       "  8     2\n",
       "  9     2\n",
       "  10    1\n",
       "  11    2\n",
       "  12    1\n",
       "  13    2\n",
       "  14    1\n",
       "  15    1\n",
       "  16    1\n",
       "  17    1\n",
       "  18    1\n",
       "  19    2\n",
       "  20    2\n",
       "  21    1\n",
       "  22    2\n",
       "  23    2\n",
       "  24    1\n",
       "  25    1\n",
       "  26    1\n",
       "  27    2\n",
       "  28    1\n",
       "  29    2\n",
       "  30    2\n",
       "  31    1\n",
       "  32    1\n",
       "  dtype: int64, 1     2\n",
       "  2     1\n",
       "  3     3\n",
       "  4     3\n",
       "  5     1\n",
       "  6     1\n",
       "  7     2\n",
       "  8     2\n",
       "  9     2\n",
       "  10    3\n",
       "  11    3\n",
       "  12    1\n",
       "  13    2\n",
       "  14    2\n",
       "  15    1\n",
       "  16    2\n",
       "  17    2\n",
       "  18    1\n",
       "  19    2\n",
       "  20    2\n",
       "  21    2\n",
       "  22    1\n",
       "  23    2\n",
       "  24    1\n",
       "  25    1\n",
       "  26    2\n",
       "  27    2\n",
       "  28    1\n",
       "  29    2\n",
       "  30    2\n",
       "  31    2\n",
       "  32    2\n",
       "  dtype: int64, 1     2\n",
       "  2     2\n",
       "  3     4\n",
       "  4     1\n",
       "  5     3\n",
       "  6     3\n",
       "  7     4\n",
       "  8     3\n",
       "  9     4\n",
       "  10    2\n",
       "  11    4\n",
       "  12    3\n",
       "  13    4\n",
       "  14    3\n",
       "  15    3\n",
       "  16    2\n",
       "  17    3\n",
       "  18    4\n",
       "  19    2\n",
       "  20    4\n",
       "  21    2\n",
       "  22    2\n",
       "  23    4\n",
       "  24    2\n",
       "  25    3\n",
       "  26    4\n",
       "  27    3\n",
       "  28    3\n",
       "  29    4\n",
       "  30    3\n",
       "  31    3\n",
       "  32    3\n",
       "  dtype: int64, 1     0\n",
       "  2     2\n",
       "  3     0\n",
       "  4     1\n",
       "  5     2\n",
       "  6     2\n",
       "  7     2\n",
       "  8     2\n",
       "  9     0\n",
       "  10    1\n",
       "  11    2\n",
       "  12    1\n",
       "  13    2\n",
       "  14    1\n",
       "  15    1\n",
       "  16    2\n",
       "  17    1\n",
       "  18    2\n",
       "  19    2\n",
       "  20    1\n",
       "  21    2\n",
       "  22    1\n",
       "  23    1\n",
       "  24    2\n",
       "  25    2\n",
       "  26    1\n",
       "  27    1\n",
       "  28    1\n",
       "  29    2\n",
       "  30    1\n",
       "  31    2\n",
       "  32    2\n",
       "  dtype: int64, 1     2\n",
       "  2     2\n",
       "  3     1\n",
       "  4     2\n",
       "  5     2\n",
       "  6     1\n",
       "  7     1\n",
       "  8     1\n",
       "  9     2\n",
       "  10    2\n",
       "  11    2\n",
       "  12    0\n",
       "  13    2\n",
       "  14    1\n",
       "  15    0\n",
       "  16    1\n",
       "  17    2\n",
       "  18    1\n",
       "  19    1\n",
       "  20    2\n",
       "  21    2\n",
       "  22    1\n",
       "  23    2\n",
       "  24    2\n",
       "  25    2\n",
       "  26    2\n",
       "  27    1\n",
       "  28    2\n",
       "  29    1\n",
       "  30    2\n",
       "  31    2\n",
       "  32    0\n",
       "  dtype: int64, 1     2\n",
       "  2     2\n",
       "  3     2\n",
       "  4     2\n",
       "  5     1\n",
       "  6     2\n",
       "  7     2\n",
       "  8     2\n",
       "  9     2\n",
       "  10    2\n",
       "  11    2\n",
       "  12    2\n",
       "  13    2\n",
       "  14    2\n",
       "  15    2\n",
       "  16    2\n",
       "  17    2\n",
       "  18    1\n",
       "  19    2\n",
       "  20    2\n",
       "  21    2\n",
       "  22    2\n",
       "  23    2\n",
       "  24    1\n",
       "  25    2\n",
       "  26    2\n",
       "  27    2\n",
       "  28    2\n",
       "  29    2\n",
       "  30    1\n",
       "  31    2\n",
       "  32    2\n",
       "  dtype: int64, 1     2\n",
       "  2     2\n",
       "  3     3\n",
       "  4     2\n",
       "  5     2\n",
       "  6     3\n",
       "  7     3\n",
       "  8     2\n",
       "  9     3\n",
       "  10    3\n",
       "  11    2\n",
       "  12    4\n",
       "  13    3\n",
       "  14    3\n",
       "  15    3\n",
       "  16    2\n",
       "  17    2\n",
       "  18    2\n",
       "  19    3\n",
       "  20    3\n",
       "  21    2\n",
       "  22    2\n",
       "  23    2\n",
       "  24    3\n",
       "  25    2\n",
       "  26    2\n",
       "  27    2\n",
       "  28    4\n",
       "  29    1\n",
       "  30    2\n",
       "  31    2\n",
       "  32    3\n",
       "  dtype: int64, 1     1\n",
       "  2     0\n",
       "  3     1\n",
       "  4     1\n",
       "  5     2\n",
       "  6     1\n",
       "  7     1\n",
       "  8     2\n",
       "  9     2\n",
       "  10    2\n",
       "  11    1\n",
       "  12    2\n",
       "  13    2\n",
       "  14    2\n",
       "  15    1\n",
       "  16    2\n",
       "  17    0\n",
       "  18    1\n",
       "  19    2\n",
       "  20    0\n",
       "  21    2\n",
       "  22    2\n",
       "  23    1\n",
       "  24    1\n",
       "  25    2\n",
       "  26    1\n",
       "  27    2\n",
       "  28    1\n",
       "  29    2\n",
       "  30    1\n",
       "  31    2\n",
       "  32    2\n",
       "  dtype: int64, 1     1\n",
       "  2     1\n",
       "  3     2\n",
       "  4     2\n",
       "  5     3\n",
       "  6     1\n",
       "  7     1\n",
       "  8     1\n",
       "  9     1\n",
       "  10    2\n",
       "  11    2\n",
       "  12    2\n",
       "  13    1\n",
       "  14    2\n",
       "  15    1\n",
       "  16    2\n",
       "  17    2\n",
       "  18    1\n",
       "  19    2\n",
       "  20    0\n",
       "  21    2\n",
       "  22    2\n",
       "  23    2\n",
       "  24    1\n",
       "  25    2\n",
       "  26    2\n",
       "  27    2\n",
       "  28    2\n",
       "  29    2\n",
       "  30    2\n",
       "  31    1\n",
       "  32    2\n",
       "  dtype: int64, 1     1\n",
       "  2     1\n",
       "  3     1\n",
       "  4     1\n",
       "  5     0\n",
       "  6     1\n",
       "  7     1\n",
       "  8     1\n",
       "  9     2\n",
       "  10    1\n",
       "  11    2\n",
       "  12    1\n",
       "  13    1\n",
       "  14    1\n",
       "  15    0\n",
       "  16    1\n",
       "  17    1\n",
       "  18    1\n",
       "  19    1\n",
       "  20    1\n",
       "  21    1\n",
       "  22    0\n",
       "  23    1\n",
       "  24    2\n",
       "  25    1\n",
       "  26    1\n",
       "  27    1\n",
       "  28    1\n",
       "  29    1\n",
       "  30    1\n",
       "  31    1\n",
       "  32    1\n",
       "  dtype: int64, 1     1\n",
       "  2     2\n",
       "  3     3\n",
       "  4     2\n",
       "  5     2\n",
       "  6     1\n",
       "  7     1\n",
       "  8     2\n",
       "  9     1\n",
       "  10    1\n",
       "  11    2\n",
       "  12    1\n",
       "  13    1\n",
       "  14    1\n",
       "  15    2\n",
       "  16    2\n",
       "  17    2\n",
       "  18    0\n",
       "  19    2\n",
       "  20    2\n",
       "  21    2\n",
       "  22    2\n",
       "  23    2\n",
       "  24    1\n",
       "  25    1\n",
       "  26    2\n",
       "  27    1\n",
       "  28    2\n",
       "  29    2\n",
       "  30    1\n",
       "  31    2\n",
       "  32    2\n",
       "  dtype: int64, 1     3\n",
       "  2     3\n",
       "  3     2\n",
       "  4     3\n",
       "  5     3\n",
       "  6     2\n",
       "  7     4\n",
       "  8     3\n",
       "  9     2\n",
       "  10    3\n",
       "  11    3\n",
       "  12    2\n",
       "  13    2\n",
       "  14    3\n",
       "  15    4\n",
       "  16    3\n",
       "  17    2\n",
       "  18    1\n",
       "  19    3\n",
       "  20    3\n",
       "  21    3\n",
       "  22    3\n",
       "  23    2\n",
       "  24    2\n",
       "  25    3\n",
       "  26    2\n",
       "  27    2\n",
       "  28    2\n",
       "  29    3\n",
       "  30    3\n",
       "  31    3\n",
       "  32    4\n",
       "  dtype: int64, 1     1\n",
       "  2     2\n",
       "  3     1\n",
       "  4     0\n",
       "  5     1\n",
       "  6     1\n",
       "  7     1\n",
       "  8     1\n",
       "  9     1\n",
       "  10    0\n",
       "  11    1\n",
       "  12    1\n",
       "  13    1\n",
       "  14    0\n",
       "  15    0\n",
       "  16    2\n",
       "  17    1\n",
       "  18    0\n",
       "  19    0\n",
       "  20    1\n",
       "  21    2\n",
       "  22    1\n",
       "  23    1\n",
       "  24    1\n",
       "  25    1\n",
       "  26    1\n",
       "  27    1\n",
       "  28    2\n",
       "  29    1\n",
       "  30    1\n",
       "  31    0\n",
       "  32    1\n",
       "  dtype: int64, 1     1\n",
       "  2     2\n",
       "  3     0\n",
       "  4     1\n",
       "  5     2\n",
       "  6     1\n",
       "  7     1\n",
       "  8     1\n",
       "  9     0\n",
       "  10    1\n",
       "  11    0\n",
       "  12    0\n",
       "  13    0\n",
       "  14    0\n",
       "  15    1\n",
       "  16    1\n",
       "  17    1\n",
       "  18    1\n",
       "  19    1\n",
       "  20    1\n",
       "  21    1\n",
       "  22    0\n",
       "  23    0\n",
       "  24    1\n",
       "  25    1\n",
       "  26    1\n",
       "  27    1\n",
       "  28    0\n",
       "  29    0\n",
       "  30    1\n",
       "  31    0\n",
       "  32    1\n",
       "  dtype: int64, 1     3\n",
       "  2     3\n",
       "  3     3\n",
       "  4     2\n",
       "  5     2\n",
       "  6     2\n",
       "  7     1\n",
       "  8     3\n",
       "  9     2\n",
       "  10    2\n",
       "  11    3\n",
       "  12    2\n",
       "  13    2\n",
       "  14    3\n",
       "  15    1\n",
       "  16    2\n",
       "  17    2\n",
       "  18    2\n",
       "  19    2\n",
       "  20    2\n",
       "  21    3\n",
       "  22    2\n",
       "  23    3\n",
       "  24    2\n",
       "  25    2\n",
       "  26    2\n",
       "  27    3\n",
       "  28    2\n",
       "  29    2\n",
       "  30    3\n",
       "  31    2\n",
       "  32    2\n",
       "  dtype: int64, 1     1\n",
       "  2     1\n",
       "  3     1\n",
       "  4     1\n",
       "  5     1\n",
       "  6     2\n",
       "  7     0\n",
       "  8     1\n",
       "  9     2\n",
       "  10    0\n",
       "  11    0\n",
       "  12    2\n",
       "  13    1\n",
       "  14    1\n",
       "  15    1\n",
       "  16    0\n",
       "  17    1\n",
       "  18    1\n",
       "  19    1\n",
       "  20    0\n",
       "  21    1\n",
       "  22    0\n",
       "  23    1\n",
       "  24    1\n",
       "  25    0\n",
       "  26    2\n",
       "  27    2\n",
       "  28    1\n",
       "  29    1\n",
       "  30    0\n",
       "  31    1\n",
       "  32    1\n",
       "  dtype: int64]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_trial_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "         1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "         0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "         0.])]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_ml_df(X[0][0], \"/Users/JennMacBook/Desktop/Studies/Animates EEG/7_Data/runningOffline/june17data12m.pkl\")\n",
    "np.savetxt('y12m.out', y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_trial_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. b) Different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, good_trial_count = prep_ml_multigroup(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")\n",
    "Xt, yt, good_trial_count_t = prep_ml_multigroup(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\")\n",
    "Xa, ya, good_trial_count_a = prep_ml_multigroup(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_trial_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X[0][0].shape\n",
    "assert n == y[0][0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y[0][0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = Xt[0][0].shape\n",
    "assert n == yt[0][0].shape[0]\n",
    "\n",
    "\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(yt[0][0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = Xa[0][0].shape\n",
    "assert n == ya[0][0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(ya[0][0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. c) First 20 trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, good_trial_count = prep_ml_first20(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")\n",
    "Xt, yt, good_trial_count_t = prep_ml_first20(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\")\n",
    "Xa, ya, good_trial_count_a = prep_ml_first20(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X[0][0].shape\n",
    "assert n == y[0][0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting up the SVM model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "#model = SVC(gamma=.001, kernel = 'rbf', C = 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and testing the model ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Train on raw, test on raw (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.475"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X,Xp = scaler.transform(X), scaler.transform(Xp)\n",
    "model.fit(X_train, y_train)\n",
    "np.mean(model.predict(X_train) != y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Train on raw, test on avg by trial (word repetition) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X,Xp = scaler.transform(X), scaler.transform(Xp)\n",
    "model.fit(X_train, y_train)\n",
    "np.mean(model.predict(X_testp) != y_testp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Train on raw, test on avg by word and ps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X,Xp = scaler.transform(X), scaler.transform(Xp)\n",
    "model.fit(X_train, y_train)\n",
    "np.mean(model.predict(X_testpt) != y_testpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Subset analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Generating random subsets of the chosen participant list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_train, participants_test = train_test_split(participants,test_size=0.2)\n",
    "print(len(participants_train), len(participants_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Create train and test sets: animates/inanimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "#X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Create train and test sets - multi group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, good_trial_count_train = prep_ml_multigroup(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_multigroup(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "#X_train, y_train, good_trial_count_train = prep_ml_multigroup(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_multigroup(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "X_train, y_train, good_trial_count_train = prep_ml_multigroup(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "X_test, y_test, good_trial_count_test = prep_ml_multigroup(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Create train and test sets - first 20 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "#X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X_train[0][0].shape\n",
    "assert n == y_test[0][0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SVC(gamma=.001, kernel = 'rbf', C=1e-6)\n",
    "model = SVC(kernel = 'rbf')\n",
    "model.fit(X_train[0][0], y_train[0][0])\n",
    "np.mean(model.predict(X_test[0][0]) != y_test[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Monte Carlo Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "errorScores = []\n",
    "\n",
    "# r iterations of a 5 fold\n",
    "for r in range(2):\n",
    "    kgp = np.array_split(participants, 5)\n",
    "\n",
    "    for i in range(5):\n",
    "        participants_test = kgp[i]\n",
    "        participants_train = np.concatenate((kgp[(i+1)%5], kgp[(i+2)%5],kgp[(i+3)%5],kgp[(i+4)%5] ), axis=0)\n",
    "        \n",
    "        #X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "        #X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "        X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "        X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "\n",
    "        #X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "        #X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "\n",
    "    \n",
    "        #model = SVC(gamma=.001, kernel = 'rbf', C=1e-06)\n",
    "        model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "        model.fit(X_train[0][0], y_train[0][0])\n",
    "        errorScore = np.mean(model.predict(X_test[0][0]) != y_test[0][0])\n",
    "        errorScores.append(errorScore)\n",
    "    \n",
    "errorScores\n",
    "\n",
    "\n",
    "\n",
    "errorScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(errorScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(errorScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Alternate accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_pred = model.predict(X_test[0][0])\n",
    "\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test[0][0],y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test[0][0],y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test[0][0],y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test[0][0],y_pred)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test[0][0],y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]}\n",
    "svc = SVC()\n",
    "model = GridSearchCV(svc, parameters, verbose=True)\n",
    "model.fit(X_train[0][0], y_train[0][0])\n",
    "\n",
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation (5 fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfirst = X[0][0]\n",
    "yfirst = y[0][0]\n",
    "# Xfirst = Xt[0][0]\n",
    "# yfirst = yt[0][0]\n",
    "# Xfirst = Xa[0][0]\n",
    "# yfirst = ya[0][0]\n",
    "\n",
    "Xfirst['label'] = yfirst\n",
    "Xfirst = Xfirst.sample(frac=1).reset_index(drop=True)\n",
    "ys = Xfirst['label']\n",
    "Xs = Xfirst.drop(columns=['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LinearSVC(max_iter=5000, C=1e-9)\n",
    "#model = SVC(gamma=.001, kernel = 'rbf', C = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X[0][0], y[0][0], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, Xs, ys, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated N-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "\n",
    "testScores = []\n",
    "\n",
    "X = X[0][0]\n",
    "y = y[0][0]\n",
    "\n",
    "# X = Xt[0][0]\n",
    "# y = yt[0][0]\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=2652124)\n",
    "for train_index, test_index in rkf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    testScore = accuracy_score(y_test,y_pred)\n",
    "    testScores.append(testScore)\n",
    "\n",
    "\n",
    "testScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(testScores))\n",
    "print(np.std(testScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
