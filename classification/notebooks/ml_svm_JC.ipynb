{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setup_jwlab\n",
    "from jwlab.constants import cleaned_data_filepath\n",
    "from jwlab.ml_prep import prep_ml, prep_ml_first20\n",
    "from jwlab.ml_prep_multigroup import prep_ml_multigroup\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Participants.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "participants = [\"904\", \"905\", \"906\", \"909\", \"910\", \"912\", \"908\", \"913\", \"914\", \"916\", \"917\", \"919\", \"920\", \"921\", \"923\", \"924\",\"927\", \"928\", \"929\", \"930\", \"932\"]\n",
    "\n",
    "#9m with >40 trials\n",
    "#participants = [ \"909\", \"912\", \"908\", \"913\", \"914\", \"916\", \"917\", \"919\", \"920\", \"921\", \"924\",\"927\", \"930\"]\n",
    "\n",
    "#12m all\n",
    "#participants = [\"105\", \"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\"]\n",
    "\n",
    "#12m with >40 trials\n",
    "#participants = [\"109\", \"111\", \"112\", \"115\", \"124\"]\n",
    "\n",
    "#all participants\n",
    "#participants = [ \"909\", \"910\", \"912\", \"908\", \"913\", \"914\", \"916\", \"917\", \"919\", \"920\", \"921\", \"923\", \"924\",\"927\", \"928\", \"929\", \"930\", \"932\",\n",
    "#               \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set up averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y, good_trial_count = prep_ml(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")\n",
    "Xt, yt, good_trial_count_t = prep_ml(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\")\n",
    "Xa, ya, good_trial_count_a = prep_ml(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. b) Different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, good_trial_count = prep_ml_multigroup(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")\n",
    "Xt, yt, good_trial_count_t = prep_ml_multigroup(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\")\n",
    "Xa, ya, good_trial_count_a = prep_ml_multigroup(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_trial_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X[0][0].shape\n",
    "assert n == y[0][0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y[0][0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = Xt[0][0].shape\n",
    "assert n == yt[0][0].shape[0]\n",
    "\n",
    "\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(yt[0][0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = Xa[0][0].shape\n",
    "assert n == ya[0][0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(ya[0][0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. c) First 20 trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, good_trial_count = prep_ml_first20(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")\n",
    "Xt, yt, good_trial_count_t = prep_ml_first20(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\")\n",
    "Xa, ya, good_trial_count_a = prep_ml_first20(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X[0][0].shape\n",
    "assert n == y[0][0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting up the SVM model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "model = SVC(gamma=.001, kernel = 'rbf', C = 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and testing the model ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Train on raw, test on raw (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X,Xp = scaler.transform(X), scaler.transform(Xp)\n",
    "model.fit(X[0][0], y[0][0])\n",
    "np.mean(model.predict(X[0][0]) != y[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Train on raw, test on avg by trial (word repetition) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X,Xp = scaler.transform(X), scaler.transform(Xp)\n",
    "model.fit(X[0][0], y[0][0])\n",
    "np.mean(model.predict(Xt[0][0]) != yt[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Train on raw, test on avg by word and ps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X,Xp = scaler.transform(X), scaler.transform(Xp)\n",
    "model.fit(X[0][0], y[0][0])\n",
    "np.mean(model.predict(Xa[0][0]) != ya[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Subset analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Generating random subsets of the chosen participant list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_train, participants_test = train_test_split(participants,test_size=0.2)\n",
    "print(len(participants_train), len(participants_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Create train and test sets: animates/inanimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "#X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Create train and test sets - multi group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, good_trial_count_train = prep_ml_multigroup(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_multigroup(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "#X_train, y_train, good_trial_count_train = prep_ml_multigroup(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_multigroup(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "X_train, y_train, good_trial_count_train = prep_ml_multigroup(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "X_test, y_test, good_trial_count_test = prep_ml_multigroup(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Create train and test sets - first 20 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "#X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X_train[0][0].shape\n",
    "assert n == y_test[0][0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SVC(gamma=.001, kernel = 'rbf', C=1e-6)\n",
    "model = SVC(kernel = 'rbf')\n",
    "model.fit(X_train[0][0], y_train[0][0])\n",
    "np.mean(model.predict(X_test[0][0]) != y_test[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Loop Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['910', '914', '927', '930', '924', '920', '909', '905', '912', '913', '921', '923', '904', '919', '928', '917'] ['932', '916', '906', '929', '908']\n",
      "loaded\n",
      "loaded\n",
      "['908', '913', '917', '927', '928', '906', '930', '914', '924', '932', '904', '923', '919', '929', '920', '905'] ['910', '912', '921', '916', '909']\n",
      "loaded\n",
      "loaded\n",
      "['912', '910', '930', '920', '905', '923', '914', '928', '932', '904', '921', '908', '929', '927', '913', '917'] ['919', '909', '916', '924', '906']\n",
      "loaded\n",
      "loaded\n",
      "['912', '910', '914', '905', '906', '919', '928', '924', '921', '920', '923', '916', '932', '930', '927', '908'] ['929', '913', '904', '917', '909']\n",
      "loaded\n",
      "loaded\n",
      "['923', '932', '929', '917', '908', '913', '914', '930', '920', '921', '910', '927', '924', '916', '919', '904'] ['909', '906', '912', '905', '928']\n",
      "loaded\n",
      "loaded\n",
      "['917', '932', '905', '919', '921', '909', '924', '910', '929', '913', '916', '914', '920', '904', '928', '912'] ['923', '908', '927', '906', '930']\n",
      "loaded\n",
      "loaded\n",
      "['908', '905', '929', '919', '920', '923', '927', '928', '932', '909', '912', '921', '917', '906', '904', '914'] ['916', '930', '910', '924', '913']\n",
      "loaded\n",
      "loaded\n",
      "['920', '927', '914', '912', '923', '921', '906', '930', '908', '904', '919', '916', '928', '913', '910', '929'] ['932', '917', '905', '924', '909']\n",
      "loaded\n",
      "loaded\n",
      "['929', '917', '906', '921', '908', '914', '930', '905', '910', '912', '932', '924', '916', '909', '919', '927'] ['913', '923', '920', '928', '904']\n",
      "loaded\n",
      "loaded\n",
      "['910', '920', '929', '930', '908', '932', '924', '906', '917', '927', '904', '914', '912', '923', '909', '919'] ['905', '916', '928', '913', '921']\n",
      "loaded\n",
      "loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5625, 0.5, 0.5, 0.4375, 0.3125, 0.4375, 0.5, 0.375, 0.5, 0.3125]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorScores = []\n",
    "\n",
    "for x in range(10):\n",
    "\n",
    "    participants_train, participants_test = train_test_split(participants,test_size=0.2)\n",
    "    print(participants_train, participants_test)\n",
    "\n",
    "    #X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "    #X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "#     X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "#     X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "    \n",
    "    #X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "    #X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "\n",
    "    X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=600, averaging=\"average_trials_and_participants\")\n",
    "    X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=600, averaging=\"average_trials_and_participants\")\n",
    "\n",
    "    #model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "    model = SVC(gamma=.001, kernel = 'rbf', C=1e-06)\n",
    "    model.fit(X_train[0][0], y_train[0][0])\n",
    "    errorScore = np.mean(model.predict(X_test[0][0]) != y_test[0][0])\n",
    "    \n",
    "    errorScores.append(errorScore)\n",
    "errorScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44375"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errorScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(errorScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Alternate accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_pred = model.predict(X_test[0][0])\n",
    "\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test[0][0],y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test[0][0],y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test[0][0],y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test[0][0],y_pred)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test[0][0],y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]}\n",
    "svc = SVC()\n",
    "model = GridSearchCV(svc, parameters, verbose=True)\n",
    "model.fit(X_train[0][0], y_train[0][0])\n",
    "\n",
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation (5 fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = LinearSVC(max_iter=5000, C=1e-9)\n",
    "model = SVC(gamma=.001, kernel = 'rbf', C = 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X[0][0], y[0][0], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, Xt[0][0], yt[0][0], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, Xa[0][0], ya[0][0], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
