{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setup_jwlab\n",
    "from jwlab.constants import cleaned_data_filepath\n",
    "from jwlab.ml_prep import prep_ml, prep_ml_first20\n",
    "from jwlab.ml_prep_multigroup import prep_ml_multigroup\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Participants.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "participants = [\"904\", \"905\", \"906\", \"909\", \"910\", \"912\", \"908\", \"913\", \"914\", \"916\", \"917\", \"919\", \"920\", \"921\", \"923\", \"924\",\"927\", \"928\", \"929\", \"930\", \"932\"]\n",
    "\n",
    "#9m with >40 trials\n",
    "#participants = [ \"909\", \"912\", \"908\", \"913\", \"914\", \"916\", \"917\", \"919\", \"920\", \"921\", \"924\",\"927\", \"930\"]\n",
    "\n",
    "#12m all\n",
    "#participants = [\"105\", \"107\", \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\"]\n",
    "\n",
    "#12m with >40 trials\n",
    "#participants = [\"109\", \"111\", \"112\", \"115\", \"124\"]\n",
    "\n",
    "#all participants\n",
    "#participants = [ \"909\", \"910\", \"912\", \"908\", \"913\", \"914\", \"916\", \"917\", \"919\", \"920\", \"921\", \"923\", \"924\",\"927\", \"928\", \"929\", \"930\", \"932\",\n",
    "#               \"109\", \"111\", \"112\", \"115\", \"116\", \"117\", \"119\", \"121\", \"122\", \"120\", \"124\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set up averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X, y, good_trial_count = prep_ml(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")\n",
    "Xt, yt, good_trial_count_t = prep_ml(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\")\n",
    "#Xa, ya, good_trial_count_a = prep_ml(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. b) Different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, good_trial_count = prep_ml_multigroup(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")\n",
    "Xt, yt, good_trial_count_t = prep_ml_multigroup(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\")\n",
    "Xa, ya, good_trial_count_a = prep_ml_multigroup(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_trial_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X[0][0].shape\n",
    "assert n == y[0][0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y[0][0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = Xt[0][0].shape\n",
    "assert n == yt[0][0].shape[0]\n",
    "\n",
    "\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(yt[0][0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = Xa[0][0].shape\n",
    "assert n == ya[0][0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(ya[0][0], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. c) First 20 trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, good_trial_count = prep_ml_first20(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")\n",
    "Xt, yt, good_trial_count_t = prep_ml_first20(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials\")\n",
    "Xa, ya, good_trial_count_a = prep_ml_first20(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X[0][0].shape\n",
    "assert n == y[0][0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting up the SVM model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "#model = SVC(gamma=.001, kernel = 'rbf', C = 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and testing the model ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Train on raw, test on raw (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X,Xp = scaler.transform(X), scaler.transform(Xp)\n",
    "model.fit(X[0][0], y[0][0])\n",
    "np.mean(model.predict(X[0][0]) != y[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Train on raw, test on avg by trial (word repetition) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X,Xp = scaler.transform(X), scaler.transform(Xp)\n",
    "model.fit(X[0][0], y[0][0])\n",
    "np.mean(model.predict(Xt[0][0]) != yt[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Train on raw, test on avg by word and ps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X,Xp = scaler.transform(X), scaler.transform(Xp)\n",
    "model.fit(X[0][0], y[0][0])\n",
    "np.mean(model.predict(Xa[0][0]) != ya[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Subset analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Generating random subsets of the chosen participant list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 5\n"
     ]
    }
   ],
   "source": [
    "participants_train, participants_test = train_test_split(participants,test_size=0.2)\n",
    "print(len(participants_train), len(participants_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Create train and test sets: animates/inanimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "#X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "#X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Create train and test sets - multi group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, good_trial_count_train = prep_ml_multigroup(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_multigroup(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "#X_train, y_train, good_trial_count_train = prep_ml_multigroup(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_multigroup(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "X_train, y_train, good_trial_count_train = prep_ml_multigroup(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "X_test, y_test, good_trial_count_test = prep_ml_multigroup(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Create train and test sets - first 20 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "#X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "#X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "X_train, y_train, good_trial_count_train = prep_ml_first20(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "X_test, y_test, good_trial_count_test = prep_ml_first20(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X_train[0][0].shape\n",
    "assert n == y_test[0][0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SVC(gamma=.001, kernel = 'rbf', C=1e-6)\n",
    "model = SVC(kernel = 'rbf')\n",
    "model.fit(X_train[0][0], y_train[0][0])\n",
    "np.mean(model.predict(X_test[0][0]) != y_test[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Monte Carlo Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45, 0.5, 0.5, 0.5, 0.453125, 0.45, 0.5, 0.5, 0.5, 0.453125]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "errorScores = []\n",
    "\n",
    "# r iterations of a 5 fold\n",
    "for r in range(2):\n",
    "    kgp = np.array_split(participants, 5)\n",
    "\n",
    "    for i in range(5):\n",
    "        participants_test = kgp[i]\n",
    "        participants_train = np.concatenate((kgp[(i+1)%5], kgp[(i+2)%5],kgp[(i+3)%5],kgp[(i+4)%5] ), axis=0)\n",
    "        \n",
    "        #X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "        #X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "        X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "        X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "\n",
    "        #X_train, y_train, good_trial_count_train = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "        #X_test, y_test, good_trial_count_test = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "\n",
    "    \n",
    "        #model = SVC(gamma=.001, kernel = 'rbf', C=1e-06)\n",
    "        model = LinearSVC(C=1e-9, max_iter=5000)\n",
    "        model.fit(X_train[0][0], y_train[0][0])\n",
    "        errorScore = np.mean(model.predict(X_test[0][0]) != y_test[0][0])\n",
    "        errorScores.append(errorScore)\n",
    "    \n",
    "errorScores\n",
    "\n",
    "\n",
    "\n",
    "errorScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.480625"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errorScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023749999999999997"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(errorScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Alternate accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_pred = model.predict(X_test[0][0])\n",
    "\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test[0][0],y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test[0][0],y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test[0][0],y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test[0][0],y_pred)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test[0][0],y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JennMacBook/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.71558158, 1.69301597, 1.68312248, 1.68113852, 1.67484728,\n",
       "        1.68243567, 1.6922791 , 1.69538959, 2.09652607, 1.72376362,\n",
       "        1.68204371, 1.68758361, 1.65074229, 1.74859643, 1.67088763,\n",
       "        1.68281364, 1.6609563 , 1.64684963, 1.64465523, 1.65129813]),\n",
       " 'std_fit_time': array([0.03751927, 0.00702697, 0.03640471, 0.01567326, 0.02144352,\n",
       "        0.017798  , 0.02944943, 0.0292979 , 0.54283841, 0.03836018,\n",
       "        0.01809517, 0.01996322, 0.03245078, 0.10108557, 0.02647493,\n",
       "        0.04991716, 0.03683357, 0.03570394, 0.04036237, 0.04520995]),\n",
       " 'mean_score_time': array([0.81676777, 0.82233437, 0.82439462, 0.82102013, 0.81838131,\n",
       "        0.82399758, 0.82557178, 0.818036  , 0.85413297, 0.8264877 ,\n",
       "        0.8150266 , 0.82922141, 0.80273708, 0.8544391 , 0.81759469,\n",
       "        0.81219506, 0.79816937, 0.79831235, 0.79641509, 0.81030647]),\n",
       " 'std_score_time': array([0.00220026, 0.00771936, 0.0134347 , 0.00102965, 0.00977086,\n",
       "        0.00860134, 0.00178957, 0.00485237, 0.02253076, 0.01456613,\n",
       "        0.00171474, 0.01022128, 0.00283367, 0.05560096, 0.02061076,\n",
       "        0.0205044 , 0.00780131, 0.00981685, 0.00620991, 0.01922205]),\n",
       " 'param_C': masked_array(data=[1e-06, 1e-06, 1e-05, 1e-05, 0.0001, 0.0001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100, 100,\n",
       "                    1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.001, 0.0001, 0.001, 0.0001, 0.001, 0.0001, 0.001,\n",
       "                    0.0001, 0.001, 0.0001, 0.001, 0.0001, 0.001, 0.0001,\n",
       "                    0.001, 0.0001, 0.001, 0.0001, 0.001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1e-06, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1e-06, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1e-05, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1e-05, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.0001, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.0001, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.51162791, 0.51162791, 0.51162791, 0.51162791, 0.51162791,\n",
       "        0.51162791, 0.51162791, 0.51162791, 0.51162791, 0.51162791,\n",
       "        0.51162791, 0.51162791, 0.51162791, 0.51162791, 0.51162791,\n",
       "        0.51162791, 0.51162791, 0.51162791, 0.51162791, 0.51162791]),\n",
       " 'split1_test_score': array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       " 'split2_test_score': array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       " 'mean_test_score': array([0.50390625, 0.50390625, 0.50390625, 0.50390625, 0.50390625,\n",
       "        0.50390625, 0.50390625, 0.50390625, 0.50390625, 0.50390625,\n",
       "        0.50390625, 0.50390625, 0.50390625, 0.50390625, 0.50390625,\n",
       "        0.50390625, 0.50390625, 0.50390625, 0.50390625, 0.50390625]),\n",
       " 'std_test_score': array([0.00549206, 0.00549206, 0.00549206, 0.00549206, 0.00549206,\n",
       "        0.00549206, 0.00549206, 0.00549206, 0.00549206, 0.00549206,\n",
       "        0.00549206, 0.00549206, 0.00549206, 0.00549206, 0.00549206,\n",
       "        0.00549206, 0.00549206, 0.00549206, 0.00549206, 0.00549206]),\n",
       " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]}\n",
    "svc = SVC()\n",
    "model = GridSearchCV(svc, parameters, verbose=True)\n",
    "model.fit(X_train[0][0], y_train[0][0])\n",
    "\n",
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50390625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1e-06, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation (5 fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LinearSVC(max_iter=5000, C=1e-9)\n",
    "#model = SVC(gamma=.001, kernel = 'rbf', C = 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49282297 0.50239234 0.45192308 0.45192308 0.53846154]\n",
      "Accuracy: 0.49 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, X[0][0], y[0][0], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44117647 0.47058824 0.41176471 0.36363636 0.51515152]\n",
      "Accuracy: 0.44 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, Xt[0][0], yt[0][0], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5  0.25 1.   0.   0.5 ]\n",
      "Accuracy: 0.45 (+/- 0.66)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, Xa[0][0], ya[0][0], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
