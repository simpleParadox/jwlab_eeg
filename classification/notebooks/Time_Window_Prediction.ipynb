{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setup_jwlab\n",
    "import random\n",
    "from jwlab.constants import cleaned_data_filepath\n",
    "\n",
    "from jwlab.cluster_analysis_perm import cluster_analysis_procedure\n",
    "from jwlab.ml_prep_perm import prep_ml, slide_df, init, load_ml_data, get_bad_trials, map_participants,average_trials_and_participants\n",
    "from jwlab.bad_trials import get_bad_trials, get_left_trial_each_word\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import cross_validate, RepeatedKFold\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = 11\n",
    "useRandomizedLabel = False\n",
    "averaging = \"permutation_with_labels\"\n",
    "sliding_window_config = [-200, 1000, [100], 10]\n",
    "downsample_num=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-34ccd264e210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                         \u001b[0mtestScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_win\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_win\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_res\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#set up variable inputs\n",
    "matrix_build = 20 # change\n",
    "split_itr = 15 # change\n",
    "fold = 3\n",
    "fold_fac= 1/fold\n",
    "\n",
    "#set up table \n",
    "win_size= sliding_window_config[2][0]\n",
    "step_size = sliding_window_config[3]\n",
    "res = {}\n",
    "temp_res ={}\n",
    "\n",
    "\n",
    "for m in range(matrix_build):\n",
    "    X, y, good_trial_count, num_win = prep_ml(age_group, useRandomizedLabel, averaging, sliding_window_config, downsample_num=1000)\n",
    "    \n",
    "    num_indices = len(X[0][0])\n",
    "    #split say 15 times? \n",
    "    for s in range(split_itr):\n",
    "        for f in range(fold):\n",
    "            ind_key = []\n",
    "            for i in range(0, num_indices-1, 1):\n",
    "                ind_key.append(i)\n",
    "            random.shuffle(ind_key)\n",
    "            fold_testsize = int(fold_fac*num_indices)\n",
    "            if f == 0:\n",
    "                test_indices = ind_key[:fold_testsize]\n",
    "            elif f == 1:\n",
    "                test_indices = ind_key[fold_testsize:(num_indices-fold_testsize)]\n",
    "            elif f == 2:\n",
    "                test_indices = ind_key[(num_indices-fold_testsize):]\n",
    "            else:\n",
    "                print('Code currently only current supports 3 folds')\n",
    "            \n",
    "            num_sliding_windows = len(X[0])\n",
    "\n",
    "            df_test = []\n",
    "            df_train = []\n",
    "\n",
    "            X_train =[]\n",
    "            y_train =[]\n",
    "            X_test = [] \n",
    "            y_test = [] \n",
    "\n",
    "            for i in range(int(num_sliding_windows)):\n",
    "                ## will need each window\n",
    "                if 'level_0' in X[0][i].columns: \n",
    "                    X[0][i] = X[0][i].drop(columns = ['level_0'], axis = 1)\n",
    "                X[0][i] = X[0][i].reset_index()   \n",
    "                # #create new df with these indices and removing from orig\n",
    "                df_test.append(X[0][i].iloc[test_indices])\n",
    "                df_train.append(X[0][i].drop(X[0][i].index[test_indices]))\n",
    "                assert(len(df_train[i]) + len(df_test[i]) == len(X[0][i]))\n",
    "                df_test[i] = df_test[i].drop(columns=['index'], axis=1) \n",
    "                df_train[i] = df_train[i].drop(columns=['index'], axis=1)\n",
    "\n",
    "                y_train.append(df_train[i].label.values)\n",
    "                X_train.append(df_train[i].drop(columns = ['label', 'participant'], axis = 1))\n",
    "                if 'level_0' in X_train[i].columns: \n",
    "                    X_train[i] = X_train[i].drop(columns = ['level_0'], axis = 1)\n",
    "                y_test.append(df_test[i].label.values)\n",
    "                X_test.append(df_test[i].drop(columns = ['label', 'participant'], axis = 1))\n",
    "                if 'level_0' in X_test[i].columns: \n",
    "                    X_test[i] = X_test[i].drop(columns = ['level_0'], axis = 1)\n",
    "\n",
    "                y_train[i][y_train[i] < 8] = 0\n",
    "                y_train[i][y_train[i] >= 8] = 1\n",
    "                y_test[i][y_test[i] < 8] = 0\n",
    "                y_test[i][y_test[i] >= 8] = 1\n",
    "                \n",
    "                \n",
    "\n",
    "            if len(num_win) > 1:\n",
    "                print(\"Error: Function not supported for mutliple window lengths.\")\n",
    "            else: \n",
    "                for i in range(num_win[0]):\n",
    "                     for j in range(num_win[0]):\n",
    "# for debugging                    j = i\n",
    "                        train_win = (i * step_size) - 200\n",
    "                        test_win = (j * step_size) - 200\n",
    "\n",
    "                        model = LinearSVC(C=1e-9, max_iter=1000)\n",
    "                        model.fit(X_train[i], y_train[i])\n",
    "                        y_pred = model.predict(X_test[j])\n",
    "                        testScore = accuracy_score(y_test[j],y_pred)\n",
    "\n",
    "                        if (train_win,test_win) in temp_res:\n",
    "                            temp_res[train_win, test_win].append(testScore)\n",
    "                        else:\n",
    "                            temp_res[train_win, test_win] = [testScore]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(-200, 1000, step_size).tolist()\n",
    "cols = np.arange(-200, 1000, step_size).tolist()\n",
    "\n",
    "time_table = pd.DataFrame(index=ind, columns=cols)       \n",
    "for i in range(num_win[0]):\n",
    "        for j in range(num_win[0]):   \n",
    "            train_win = (i * step_size) - 200\n",
    "            test_win = (j * step_size) - 200\n",
    "            avg = sum(temp_res[train_win, test_win])/len(temp_res[train_win, test_win])\n",
    "            time_table.loc[train_win, test_win]=avg\n",
    "            \n",
    "print(time_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for debugging\n",
    "\n",
    "# res={}\n",
    "# for i in range(num_win[0]):   \n",
    "#         train_win = (i * step_size) - 200\n",
    "#         test_win = (i * step_size) - 200\n",
    "#         res[train_win, test_win]= sum(temp_res[train_win, test_win])/len(temp_res[train_win, test_win])\n",
    "        \n",
    "#  res.values()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table.to_csv('12m_100ms_10msSteps_verification3.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and predict windows between age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_age_group = 9\n",
    "test_age_group = 11\n",
    "useRandomizedLabel = False\n",
    "averaging = \"permutation_with_labels\"\n",
    "sliding_window_config = [-200, 1000, [100], 50]\n",
    "downsample_num=1000\n",
    "\n",
    "#set up variable inputs\n",
    "matrix_build = 20 # change\n",
    "split_itr = 15 # change\n",
    "fold = 3\n",
    "fold_fac= 1/fold\n",
    "\n",
    "#set up table \n",
    "win_size= sliding_window_config[2][0]\n",
    "step_size = sliding_window_config[3]\n",
    "res = {}\n",
    "temp_res ={}\n",
    "\n",
    "\n",
    "for m in range(matrix_build):\n",
    "    X_train_all, y_train_all, good_trial_count_train, num_win_train = prep_ml(train_age_group, useRandomizedLabel, averaging, sliding_window_config, downsample_num=1000)\n",
    "    X_test_all, y_test_all, good_trial_count_test, num_win_test = prep_ml(test_age_group, useRandomizedLabel, averaging, sliding_window_config, downsample_num=1000)\n",
    "\n",
    "\n",
    "    num_indices_train = len(X_train_all[0][0])\n",
    "    num_indices_test = len(X_test_all[0][0])\n",
    "    \n",
    "     \n",
    "    for s in range(split_itr):\n",
    "        for f in range(fold):\n",
    "            \n",
    "            ind_key_train = []\n",
    "            for i in range(0, num_indices_train-1, 1):\n",
    "                ind_key_train.append(i)\n",
    "            random.shuffle(ind_key_train)\n",
    "            fold_testsize_trainingSet = int(fold_fac*num_indices_train)\n",
    "            if f == 0:\n",
    "                test_indices_trainingSet = ind_key_train[:fold_testsize_trainingSet]\n",
    "            elif f == 1:\n",
    "                test_indices_trainingSet = ind_key_train[fold_testsize_trainingSet:(num_indices_train-fold_testsize_trainingSet)]\n",
    "            elif f == 2:\n",
    "                test_indices_trainingSet = ind_key_train[(num_indices_train-fold_testsize_trainingSet):]\n",
    "            else:\n",
    "                print('Code currently only current supports 3 folds')\n",
    "            \n",
    "            ind_key_test = []\n",
    "            for i in range(0, num_indices_test-1, 1):\n",
    "                ind_key_test.append(i)\n",
    "            random.shuffle(ind_key_test)\n",
    "            fold_testsize_testingSet = int(fold_fac*num_indices_test)\n",
    "            if f == 0:\n",
    "                test_indices_testingSet = ind_key_test[:fold_testsize_testingSet]\n",
    "            elif f == 1:\n",
    "                test_indices_testingSet = ind_key_test[fold_testsize_testingSet:(num_indices_test-fold_testsize_testingSet)]\n",
    "            elif f == 2:\n",
    "                test_indices_testingSet = ind_key_test[(num_indices_test-fold_testsize_testingSet):]\n",
    "            else:\n",
    "                print('Code currently only current supports 3 folds')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            num_sliding_windows = len(X_train_all[0])\n",
    "\n",
    "            df_test = []\n",
    "            df_train = []\n",
    "\n",
    "            X_train =[]\n",
    "            y_train =[]\n",
    "            X_test = [] \n",
    "            y_test = [] \n",
    "\n",
    "            for i in range(int(num_sliding_windows)):\n",
    "                ## will need each window\n",
    "                if 'level_0' in X_train_all[0][i].columns: \n",
    "                    X_train_all[0][i] = X_train_all[0][i].drop(columns = ['level_0'], axis = 1)\n",
    "                if 'level_0' in X_test_all[0][i].columns: \n",
    "                    X_test_all[0][i] = X_test_all[0][i].drop(columns = ['level_0'], axis = 1)\n",
    "                X_train_all[0][i] = X_train_all[0][i].reset_index()   \n",
    "                X_test_all[0][i] = X_test_all[0][i].reset_index() \n",
    "                # #create new df with these indices and removing from orig\n",
    "                df_test.append(X_test_all[0][i].iloc[test_indices_testingSet])\n",
    "                df_train.append(X_train_all[0][i].drop(X_train_all[0][i].index[test_indices_trainingSet]))\n",
    "#                 assert(len(df_train[i]) + len(df_test[i]) == len(X_train_all[0][i]) + len(X_test_all[0][i]))\n",
    "                assert(num_win_train == num_win_test)\n",
    "                df_test[i] = df_test[i].drop(columns=['index'], axis=1) \n",
    "                df_train[i] = df_train[i].drop(columns=['index'], axis=1)\n",
    "\n",
    "                y_train.append(df_train[i].label.values)\n",
    "                X_train.append(df_train[i].drop(columns = ['label', 'participant'], axis = 1))\n",
    "                if 'level_0' in X_train[i].columns: \n",
    "                    X_train[i] = X_train[i].drop(columns = ['level_0'], axis = 1)\n",
    "                y_test.append(df_test[i].label.values)\n",
    "                X_test.append(df_test[i].drop(columns = ['label', 'participant'], axis = 1))\n",
    "                if 'level_0' in X_test[i].columns: \n",
    "                    X_test[i] = X_test[i].drop(columns = ['level_0'], axis = 1)\n",
    "\n",
    "                y_train[i][y_train[i] < 8] = 0\n",
    "                y_train[i][y_train[i] >= 8] = 1\n",
    "                y_test[i][y_test[i] < 8] = 0\n",
    "                y_test[i][y_test[i] >= 8] = 1\n",
    "                \n",
    "                \n",
    "\n",
    "            if len(num_win_train) > 1:\n",
    "                print(\"Error: Function not supported for mutliple window lengths.\")\n",
    "            else: \n",
    "                for i in range(num_win_train[0]):\n",
    "                    for j in range(num_win_train[0]):\n",
    "                        train_win = (i * step_size) - 200\n",
    "                        test_win = (j * step_size) - 200\n",
    "\n",
    "                        model = LinearSVC(C=1e-9, max_iter=1000)\n",
    "                        model.fit(X_train[i], y_train[i])\n",
    "                        y_pred = model.predict(X_test[j])\n",
    "                        testScore = accuracy_score(y_test[j],y_pred)\n",
    "\n",
    "                        if (train_win,test_win) in temp_res:\n",
    "                            temp_res[train_win, test_win].append(testScore)\n",
    "                        else:\n",
    "                            temp_res[train_win, test_win] = [testScore]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          -200      -150      -100      -50        0         50        100  \\\n",
      "-200  0.513232  0.521283  0.452939  0.463505  0.480677  0.498293  0.473889   \n",
      "-150  0.490465  0.554929  0.529222  0.452909  0.458343  0.495758  0.486636   \n",
      "-100  0.467697  0.471475  0.540455  0.529616  0.504273  0.509343  0.519242   \n",
      "-50   0.509414  0.497414  0.511818  0.515606  0.511919  0.512232  0.544949   \n",
      " 0    0.496859  0.513939   0.55297   0.52597  0.528495     0.501  0.535101   \n",
      " 50   0.495354  0.530253  0.523455   0.53203  0.522455  0.500343  0.513515   \n",
      " 100  0.490444  0.520475  0.518455  0.533414  0.533343  0.500202  0.505606   \n",
      " 150  0.470869  0.492929  0.538657  0.538475   0.52996  0.505919  0.510737   \n",
      " 200  0.477525  0.466899  0.529788  0.556323  0.545273  0.518657  0.523798   \n",
      " 250  0.470707  0.461707  0.535606  0.565242  0.559242  0.532848  0.536222   \n",
      " 300  0.473131  0.473545  0.527313  0.558707  0.559253  0.528455  0.537263   \n",
      " 350  0.455818  0.471293  0.553697   0.56101  0.556525  0.536606  0.526051   \n",
      " 400  0.459414  0.464424  0.547768  0.565081  0.561636  0.550737  0.543545   \n",
      " 450  0.460525  0.467222  0.539788  0.559455  0.559798  0.540919  0.541596   \n",
      " 500  0.465414  0.475232  0.542859   0.54403  0.552222  0.527657  0.527495   \n",
      " 550  0.490253  0.490242  0.500879   0.51604  0.513798  0.506293  0.507586   \n",
      " 600  0.494667  0.522071  0.500596  0.500263  0.496121  0.475465  0.471434   \n",
      " 650  0.479848  0.552657  0.520859  0.497444   0.48704  0.463444  0.461455   \n",
      " 700  0.484848  0.536818  0.512828  0.496101   0.47304  0.461343  0.454848   \n",
      " 750  0.486626  0.537727  0.507364  0.490747  0.480818  0.466879  0.451616   \n",
      " 800  0.493556  0.544071  0.512222  0.480667  0.477404  0.461869  0.451172   \n",
      " 850  0.471293  0.560364  0.523101  0.498939  0.492808  0.485404   0.46598   \n",
      " 900  0.446253  0.532424  0.556909  0.520283  0.506283  0.505677  0.479626   \n",
      " 950       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "           150       200       250  ...       500       550       600  \\\n",
      "-200  0.457061  0.432515  0.444141  ...  0.388323  0.373111  0.371616   \n",
      "-150  0.526667  0.501455  0.489303  ...  0.530404  0.562889  0.577909   \n",
      "-100  0.536929  0.558838  0.568152  ...  0.608323  0.623758  0.629848   \n",
      "-50    0.53404  0.534859  0.547899  ...  0.550232  0.537051  0.536707   \n",
      " 0    0.531343  0.521737  0.538737  ...  0.531303  0.507707  0.502909   \n",
      " 50   0.522172  0.514091  0.521475  ...  0.548121  0.533495  0.520202   \n",
      " 100  0.514091  0.511929  0.522586  ...  0.556404  0.557697  0.541515   \n",
      " 150  0.525626  0.529374  0.536091  ...  0.577071  0.572162  0.565414   \n",
      " 200  0.533162  0.553939  0.564576  ...  0.600505  0.591626  0.580566   \n",
      " 250  0.554707  0.567768  0.574212  ...  0.614242  0.602232   0.59501   \n",
      " 300  0.540384   0.55701   0.57803  ...  0.623667  0.603121  0.600384   \n",
      " 350  0.543616  0.559848  0.578646  ...  0.618737  0.617687  0.600343   \n",
      " 400  0.559667  0.567687  0.587414  ...  0.620313  0.610333  0.595768   \n",
      " 450  0.558081  0.561091  0.596081  ...  0.621475  0.633838  0.606101   \n",
      " 500  0.542949  0.549939  0.575606  ...  0.599737  0.608242  0.580263   \n",
      " 550  0.518273  0.528061     0.549  ...  0.592162  0.587465  0.565859   \n",
      " 600  0.489929  0.500929  0.514869  ...  0.542636  0.544313  0.526657   \n",
      " 650  0.478919  0.476253  0.483081  ...  0.501081  0.512626   0.49004   \n",
      " 700  0.467556  0.466374  0.481687  ...  0.490586  0.498899  0.475697   \n",
      " 750  0.465697  0.466576  0.480687  ...  0.494576  0.508152  0.484717   \n",
      " 800  0.459051  0.462798  0.469566  ...  0.482051  0.497707  0.471909   \n",
      " 850   0.48298  0.484081  0.487525  ...  0.526152  0.541414     0.525   \n",
      " 900  0.506646  0.518172  0.524222  ...  0.561384  0.591202  0.580313   \n",
      " 950       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "\n",
      "           650       700       750       800       850       900  950  \n",
      "-200  0.347879  0.342616  0.373636  0.364798  0.386354  0.381303  NaN  \n",
      "-150  0.590333  0.570242  0.528667  0.554505  0.566879  0.582051  NaN  \n",
      "-100  0.658727  0.654727  0.630232  0.624222   0.61503  0.618818  NaN  \n",
      "-50   0.538424  0.549263  0.554404  0.539758     0.525  0.522596  NaN  \n",
      " 0    0.491828  0.507515  0.511687  0.498899  0.484768  0.482182  NaN  \n",
      " 50   0.502354  0.505859   0.50696  0.507909  0.491333  0.484697  NaN  \n",
      " 100  0.531596  0.531495  0.522727  0.524293  0.512071  0.508747  NaN  \n",
      " 150  0.558566  0.557859  0.547081  0.548768  0.528737  0.537727  NaN  \n",
      " 200  0.578455   0.57296  0.564788  0.553717  0.544586  0.545354  NaN  \n",
      " 250  0.595101  0.596717  0.585253  0.561505  0.548273  0.555152  NaN  \n",
      " 300  0.597485  0.597323  0.594535  0.574788  0.554354  0.553101  NaN  \n",
      " 350  0.595828  0.588687  0.583707  0.576848  0.559434     0.557  NaN  \n",
      " 400  0.585253  0.575556  0.576727  0.561394  0.552182  0.548747  NaN  \n",
      " 450  0.587889  0.576929  0.578192  0.571192  0.551495  0.543303  NaN  \n",
      " 500   0.56403  0.551556  0.554606   0.54903  0.526576  0.520424  NaN  \n",
      " 550  0.549899  0.536202  0.545677  0.532808  0.507697  0.495707  NaN  \n",
      " 600  0.505162  0.496515  0.511202  0.497879  0.481283  0.461788  NaN  \n",
      " 650   0.47096  0.459343  0.475253   0.46498  0.452121  0.429737  NaN  \n",
      " 700  0.453162  0.449667  0.458212  0.455152  0.441586  0.419303  NaN  \n",
      " 750  0.464121  0.460576  0.467444  0.466333  0.447687  0.426869  NaN  \n",
      " 800  0.455909  0.452061  0.457444   0.45598  0.442535  0.417263  NaN  \n",
      " 850  0.500424  0.485081  0.491677  0.488606  0.470949  0.456333  NaN  \n",
      " 900  0.559707  0.541949  0.535182  0.536384  0.522646  0.505061  NaN  \n",
      " 950       NaN       NaN       NaN       NaN       NaN       NaN  NaN  \n",
      "\n",
      "[24 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "ind = np.arange(-200, 1000, step_size).tolist()\n",
    "cols = np.arange(-200, 1000, step_size).tolist()\n",
    "\n",
    "time_table = pd.DataFrame(index=ind, columns=cols)       \n",
    "for i in range(num_win_train[0]):\n",
    "        for j in range(num_win_train[0]):   \n",
    "            train_win = (i * step_size) - 200\n",
    "            test_win = (j * step_size) - 200\n",
    "            avg = sum(temp_res[train_win, test_win])/len(temp_res[train_win, test_win])\n",
    "            time_table.loc[train_win, test_win]=avg\n",
    "            \n",
    "print(time_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table.to_csv('9mTrain_12mTest_100ms_50msSteps.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and predict windows between age groups OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9m training windows\n",
    "age_group = 9\n",
    "useRandomizedLabel = False\n",
    "averaging = \"permutation\"\n",
    "sliding_window_config = [-200, 1000, [100], 100]\n",
    "downsample_num=1000\n",
    "\n",
    "X, y, good_trial_count, num_win = prep_ml(age_group, useRandomizedLabel, averaging, sliding_window_config, downsample_num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12m testing windows\n",
    "age_group = 11\n",
    "useRandomizedLabel = False\n",
    "averaging = \"permutation\"\n",
    "sliding_window_config = [-200, 1000, [100], 100]\n",
    "downsample_num=1000\n",
    "\n",
    "X_test, y_test, good_trial_count, num_win = prep_ml(age_group, useRandomizedLabel, averaging, sliding_window_config, downsample_num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time val\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "win_size= 100\n",
    "res = {}\n",
    "ind = np.arange(-200, 1000, win_size).tolist()\n",
    "cols = np.arange(-200, 1000, win_size).tolist()\n",
    "time_table = pd.DataFrame(index=ind, columns=cols)\n",
    "if len(num_win) > 1:\n",
    "    print(\"Error: Function not supported for mutliple window lengths.\")\n",
    "else: \n",
    "    for i in range(num_win[0]):\n",
    "        for j in range(num_win[0]): \n",
    "            train_win = (i * win_size) - 200\n",
    "            test_win = (j * win_size) - 200\n",
    "            X_train_i = X_train[0][i]\n",
    "            y_train_i = y_train[0][i]\n",
    "            X_test_j = X_test[0][j]\n",
    "            y_test_j = y_test[0][j]\n",
    "            \n",
    "            model = LinearSVC(C=1e-9, max_iter=1000)\n",
    "            model.fit(X_train_i, y_train_i)\n",
    "            y_pred = model.predict(X_test_j)\n",
    "            testScore = accuracy_score(y_test_j,y_pred) \n",
    "            \n",
    "            res[train_win, test_win] = testScore\n",
    "            time_table.loc[train_win, test_win]=testScore\n",
    "            \n",
    "time_table.to_csv('9mSubsetTrain_12mTest_Timewin_Pred_100ms.csv')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-200</th>\n",
       "      <th>-100</th>\n",
       "      <th>0</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "      <th>400</th>\n",
       "      <th>500</th>\n",
       "      <th>600</th>\n",
       "      <th>700</th>\n",
       "      <th>800</th>\n",
       "      <th>900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>-200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     -200 -100  0    100  200  300  400  500  600  700  800  900\n",
       "-200  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "-100  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       " 0    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       " 100  NaN  NaN  NaN  NaN  NaN  NaN   99  NaN  NaN  NaN  NaN  NaN\n",
       " 200  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       " 300  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       " 400  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       " 500  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       " 600  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       " 700  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       " 800  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       " 900  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.arange(-200, 1000, win_size).tolist()\n",
    "cols = np.arange(-200, 1000, win_size).tolist()\n",
    "time_table = pd.DataFrame(index=ind, columns=cols)\n",
    "time_table.loc[100, 400]=99\n",
    "time_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
