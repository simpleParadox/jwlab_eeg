{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setup_jwlab\n",
    "from jwlab.constants import cleaned_data_filepath\n",
    "from jwlab.ml_prep import prep_ml\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Participants data set ...\n",
    "Note: choose only one of the data set below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 All participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"105\", \"106\", \"107\", \"109\", \"111\", \"904\", \"905\", \"906\", \"112\", \"909\", \"910\", \"115\", \"116\", \"912\", \"908\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>111</th>\n",
       "      <th>904</th>\n",
       "      <th>905</th>\n",
       "      <th>906</th>\n",
       "      <th>112</th>\n",
       "      <th>909</th>\n",
       "      <th>910</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>912</th>\n",
       "      <th>908</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   105 106 107  109  111 904 905 906  112  909  910  115  116  912  908\n",
       "1    9   7  20    1    3  15  16   5    2    0    1    3    2    1    2\n",
       "2    9   4  22    3    1  13  15   4    2    2    1    4    0    1    1\n",
       "3    8   5  24    3    1  12  15   3    1    1    0    4    0    1    3\n",
       "4    9   6  18    3    2  13  12   6    3    1    0    4    1    0    3\n",
       "5    -   -   -    3    1   -   -   -    2    1    1    3    0    1    1\n",
       "6    -   -   -    3    3   -   -   -    3    2    0    5    1    0    1\n",
       "7    -   -   -    3    2   -   -   -    3    2    1    4    1    1    2\n",
       "8    -   -   -    2    1   -   -   -    2    1    1    4    1    2    2\n",
       "9    -   -   -    3    2   -   -   -    1    2    1    4    1    2    2\n",
       "10   -   -   -    4    3   -   -   -    2    2    0    4    1    1    3\n",
       "11   -   -   -    1    3   -   -   -    1    1    0    5    1    2    3\n",
       "12   -   -   -    3    1   -   -   -    1    1    0    4    2    1    1\n",
       "13   -   -   -    3    2   -   -   -    2    1    0    4    2    2    2\n",
       "14   -   -   -    3    0   -   -   -    3    2    0    3    2    1    2\n",
       "15   -   -   -    2    2   -   -   -    2    1    0    3    0    1    1\n",
       "16   -   -   -    2    1   -   -   -    1    0    1    5    1    1    2\n",
       "17   -   -   -    3    3   -   -   -    3    1    0    3    1    1    2\n",
       "18   -   -   -    2    3   -   -   -    3    1    1    5    1    1    1\n",
       "19   -   -   -    2    2   -   -   -    3    1    1    3    1    2    2\n",
       "20   -   -   -    4    1   -   -   -    2    1    0    4    1    2    2\n",
       "21   -   -   -    3    1   -   -   -    2    1    1    4    1    1    2\n",
       "22   -   -   -    2    2   -   -   -    3    1    0    2    1    2    1\n",
       "23   -   -   -    3    3   -   -   -    2    2    1    3    1    2    2\n",
       "24   -   -   -    1    1   -   -   -    1    2    1    4    1    1    1\n",
       "25   -   -   -    2    1   -   -   -    3    2    1    5    1    1    2\n",
       "26   -   -   -    3    2   -   -   -    2    1    0    3    1    1    2\n",
       "27   -   -   -    2    2   -   -   -    2    1    0    4    0    1    2\n",
       "28   -   -   -    4    1   -   -   -    3    2    0    4    2    1    1\n",
       "29   -   -   -    2    2   -   -   -    2    2    0    4    1    2    2\n",
       "30   -   -   -    3    2   -   -   -    2    2    0    4    1    2    2\n",
       "31   -   -   -    4    0   -   -   -    3    1    0    3    1    1    2\n",
       "32   -   -   -    3    3   -   -   -    2    1    0    4    1    1    2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f2dd747d1015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_data_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"no_averaging\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/jwlab_eeg/classification/notebooks/../code/jwlab/ml_prep.py\u001b[0m in \u001b[0;36mprep_ml\u001b[0;34m(filepath, participants, downsample_num, averaging)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprep_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"average_trials\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ml_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprep_ml_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownsample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maveraging\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/jwlab_eeg/classification/notebooks/../code/jwlab/ml_prep.py\u001b[0m in \u001b[0;36mprep_ml_internal\u001b[0;34m(df, ys, participants, downsample_num, averaging)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0msw_list_for_all_time_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtime_length\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msliding_window_time_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0msw_list_for_all_time_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliding_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mX_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msliding_window_time_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliding_window_time_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/jwlab_eeg/classification/notebooks/../code/jwlab/ml_prep.py\u001b[0m in \u001b[0;36msliding_window\u001b[0;34m(df, time_length)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTime\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtime_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTime\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2984\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3038\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3603\u001b[0m         new_data = self._data.take(\n\u001b[0;32m-> 3604\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3605\u001b[0m         )\n\u001b[1;32m   3606\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         return self.reindex_indexer(\n\u001b[0;32m-> 1397\u001b[0;31m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m         )\n\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1265\u001b[0m                     ),\n\u001b[1;32m   1266\u001b[0m                 )\n\u001b[0;32m-> 1267\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m             ]\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1265\u001b[0m                     ),\n\u001b[1;32m   1266\u001b[0m                 )\n\u001b[0;32m-> 1267\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m             ]\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         new_values = algos.take_nd(\n\u001b[0;32m-> 1313\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m         )\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m     )\n\u001b[0;32m-> 1721\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y = prep_ml(cleaned_data_filepath, participants, downsample_num=1000, averaging=\"no_averaging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 All 13-month participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"105\", \"106\", \"107\", \"109\", \"111\", \"112\", \"115\", \"116\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 All 9-month participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"904\", \"905\", \"906\", \"909\", \"910\", \"912\", \"908\", \"913\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating random subsets of the chosen participant list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 3\n"
     ]
    }
   ],
   "source": [
    "participants_train, participants_test = train_test_split(participants,test_size=0.2)\n",
    "print(len(participants_train), len(participants_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing the data set for the ML model ...\n",
    "Note: the dimensions are also verified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 No_averaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Printing data for participant - [115] ------ \n",
      "\n",
      "The number of BAD trials is - [14].\n",
      "\n",
      "The number of GOOD trials left is - [122].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     3\n",
      "2     4\n",
      "3     4\n",
      "4     4\n",
      "5     3\n",
      "6     5\n",
      "7     4\n",
      "8     4\n",
      "9     4\n",
      "10    4\n",
      "11    5\n",
      "12    4\n",
      "13    4\n",
      "14    3\n",
      "15    3\n",
      "16    5\n",
      "17    3\n",
      "18    5\n",
      "19    3\n",
      "20    4\n",
      "21    4\n",
      "22    2\n",
      "23    3\n",
      "24    4\n",
      "25    5\n",
      "26    3\n",
      "27    4\n",
      "28    4\n",
      "29    4\n",
      "30    4\n",
      "31    3\n",
      "32    4\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [107] ------ \n",
      "\n",
      "The number of BAD trials is - [25].\n",
      "\n",
      "The number of GOOD trials left is - [84].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "cell\n",
      "1    20\n",
      "2    22\n",
      "3    24\n",
      "4    18\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [904] ------ \n",
      "\n",
      "The number of BAD trials is - [64].\n",
      "\n",
      "The number of GOOD trials left is - [53].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "cell\n",
      "1    15\n",
      "2    13\n",
      "3    12\n",
      "4    13\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [112] ------ \n",
      "\n",
      "The number of BAD trials is - [33].\n",
      "\n",
      "The number of GOOD trials left is - [69].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     2\n",
      "2     2\n",
      "3     1\n",
      "4     3\n",
      "5     2\n",
      "6     3\n",
      "7     3\n",
      "8     2\n",
      "9     1\n",
      "10    2\n",
      "11    1\n",
      "12    1\n",
      "13    2\n",
      "14    3\n",
      "15    2\n",
      "16    1\n",
      "17    3\n",
      "18    3\n",
      "19    3\n",
      "20    2\n",
      "21    2\n",
      "22    3\n",
      "23    2\n",
      "24    1\n",
      "25    3\n",
      "26    2\n",
      "27    2\n",
      "28    3\n",
      "29    2\n",
      "30    2\n",
      "31    3\n",
      "32    2\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [905] ------ \n",
      "\n",
      "The number of BAD trials is - [26].\n",
      "\n",
      "The number of GOOD trials left is - [58].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "cell\n",
      "1    16\n",
      "2    15\n",
      "3    15\n",
      "4    12\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [106] ------ \n",
      "\n",
      "The number of BAD trials is - [10].\n",
      "\n",
      "The number of GOOD trials left is - [22].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "cell\n",
      "1    7\n",
      "2    4\n",
      "3    5\n",
      "4    6\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [111] ------ \n",
      "\n",
      "The number of BAD trials is - [52].\n",
      "\n",
      "The number of GOOD trials left is - [57].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     3\n",
      "2     1\n",
      "3     1\n",
      "4     2\n",
      "5     1\n",
      "6     3\n",
      "7     2\n",
      "8     1\n",
      "9     2\n",
      "10    3\n",
      "11    3\n",
      "12    1\n",
      "13    2\n",
      "14    0\n",
      "15    2\n",
      "16    1\n",
      "17    3\n",
      "18    3\n",
      "19    2\n",
      "20    1\n",
      "21    1\n",
      "22    2\n",
      "23    3\n",
      "24    1\n",
      "25    1\n",
      "26    2\n",
      "27    2\n",
      "28    1\n",
      "29    2\n",
      "30    2\n",
      "31    0\n",
      "32    3\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [912] ------ \n",
      "\n",
      "The number of BAD trials is - [35].\n",
      "\n",
      "The number of GOOD trials left is - [34].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     0\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     2\n",
      "9     2\n",
      "10    1\n",
      "11    2\n",
      "12    1\n",
      "13    2\n",
      "14    1\n",
      "15    1\n",
      "16    1\n",
      "17    1\n",
      "18    1\n",
      "19    2\n",
      "20    2\n",
      "21    1\n",
      "22    2\n",
      "23    2\n",
      "24    1\n",
      "25    1\n",
      "26    1\n",
      "27    1\n",
      "28    1\n",
      "29    2\n",
      "30    2\n",
      "31    1\n",
      "32    1\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [116] ------ \n",
      "\n",
      "The number of BAD trials is - [19].\n",
      "\n",
      "The number of GOOD trials left is - [32].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     2\n",
      "2     0\n",
      "3     0\n",
      "4     1\n",
      "5     0\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    2\n",
      "13    2\n",
      "14    2\n",
      "15    0\n",
      "16    1\n",
      "17    1\n",
      "18    1\n",
      "19    1\n",
      "20    1\n",
      "21    1\n",
      "22    1\n",
      "23    1\n",
      "24    1\n",
      "25    1\n",
      "26    1\n",
      "27    0\n",
      "28    2\n",
      "29    1\n",
      "30    1\n",
      "31    1\n",
      "32    1\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [909] ------ \n",
      "\n",
      "The number of BAD trials is - [21].\n",
      "\n",
      "The number of GOOD trials left is - [42].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     0\n",
      "2     2\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     2\n",
      "7     2\n",
      "8     1\n",
      "9     2\n",
      "10    2\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    2\n",
      "15    1\n",
      "16    0\n",
      "17    1\n",
      "18    1\n",
      "19    1\n",
      "20    1\n",
      "21    1\n",
      "22    1\n",
      "23    2\n",
      "24    2\n",
      "25    2\n",
      "26    1\n",
      "27    1\n",
      "28    2\n",
      "29    2\n",
      "30    2\n",
      "31    1\n",
      "32    1\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [910] ------ \n",
      "\n",
      "The number of BAD trials is - [40].\n",
      "\n",
      "The number of GOOD trials left is - [13].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     0\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    1\n",
      "17    0\n",
      "18    1\n",
      "19    1\n",
      "20    0\n",
      "21    1\n",
      "22    0\n",
      "23    1\n",
      "24    1\n",
      "25    1\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [908] ------ \n",
      "\n",
      "The number of BAD trials is - [19].\n",
      "\n",
      "The number of GOOD trials left is - [59].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     2\n",
      "2     1\n",
      "3     3\n",
      "4     3\n",
      "5     1\n",
      "6     1\n",
      "7     2\n",
      "8     2\n",
      "9     2\n",
      "10    3\n",
      "11    3\n",
      "12    1\n",
      "13    2\n",
      "14    2\n",
      "15    1\n",
      "16    2\n",
      "17    2\n",
      "18    1\n",
      "19    2\n",
      "20    2\n",
      "21    2\n",
      "22    1\n",
      "23    2\n",
      "24    1\n",
      "25    2\n",
      "26    2\n",
      "27    2\n",
      "28    1\n",
      "29    2\n",
      "30    2\n",
      "31    2\n",
      "32    2\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cb06cab39edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_data_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"no_averaging\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_data_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"no_averaging\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# (n_train, d_train) = X_train_n.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# assert n_train == y_train_n.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/jwlab_eeg/classification/notebooks/../code/jwlab/ml_prep.py\u001b[0m in \u001b[0;36mprep_ml\u001b[0;34m(filepath, participants, downsample_num, averaging)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprep_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"average_trials\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ml_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprep_ml_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownsample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maveraging\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/jwlab_eeg/classification/notebooks/../code/jwlab/ml_prep.py\u001b[0m in \u001b[0;36mprep_ml_internal\u001b[0;34m(df, ys, participants, downsample_num, averaging)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0msw_list_for_all_time_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtime_length\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msliding_window_time_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0msw_list_for_all_time_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliding_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mX_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msliding_window_time_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliding_window_time_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/jwlab_eeg/classification/notebooks/../code/jwlab/ml_prep.py\u001b[0m in \u001b[0;36msliding_window\u001b[0;34m(df, time_length)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTime\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtime_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTime\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2984\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3038\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3603\u001b[0m         new_data = self._data.take(\n\u001b[0;32m-> 3604\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3605\u001b[0m         )\n\u001b[1;32m   3606\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         return self.reindex_indexer(\n\u001b[0;32m-> 1397\u001b[0;31m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m         )\n\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1265\u001b[0m                     ),\n\u001b[1;32m   1266\u001b[0m                 )\n\u001b[0;32m-> 1267\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m             ]\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1265\u001b[0m                     ),\n\u001b[1;32m   1266\u001b[0m                 )\n\u001b[0;32m-> 1267\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m             ]\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         new_values = algos.take_nd(\n\u001b[0;32m-> 1313\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m         )\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m     )\n\u001b[0;32m-> 1721\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_n,y_train_n = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"no_averaging\")\n",
    "X_test_n, y_test_n = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"no_averaging\")\n",
    "\n",
    "# (n_train, d_train) = X_train_n.shape\n",
    "# assert n_train == y_train_n.shape[0]\n",
    "\n",
    "# (n_test, d_test) = X_test_n.shape\n",
    "# assert n_test == y_test_n.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Average_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "\n",
      " ----- Printing data for participant - [109] ------ \n",
      "\n",
      "The number of BAD trials is - [25].\n",
      "\n",
      "The number of GOOD trials left is - [85].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     1\n",
      "2     3\n",
      "3     3\n",
      "4     3\n",
      "5     3\n",
      "6     3\n",
      "7     3\n",
      "8     2\n",
      "9     3\n",
      "10    4\n",
      "11    1\n",
      "12    3\n",
      "13    3\n",
      "14    3\n",
      "15    2\n",
      "16    2\n",
      "17    3\n",
      "18    2\n",
      "19    2\n",
      "20    4\n",
      "21    3\n",
      "22    2\n",
      "23    3\n",
      "24    1\n",
      "25    2\n",
      "26    3\n",
      "27    2\n",
      "28    4\n",
      "29    2\n",
      "30    3\n",
      "31    4\n",
      "32    3\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [112] ------ \n",
      "\n",
      "The number of BAD trials is - [33].\n",
      "\n",
      "The number of GOOD trials left is - [69].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     2\n",
      "2     2\n",
      "3     1\n",
      "4     3\n",
      "5     2\n",
      "6     3\n",
      "7     3\n",
      "8     2\n",
      "9     1\n",
      "10    2\n",
      "11    1\n",
      "12    1\n",
      "13    2\n",
      "14    3\n",
      "15    2\n",
      "16    1\n",
      "17    3\n",
      "18    3\n",
      "19    3\n",
      "20    2\n",
      "21    2\n",
      "22    3\n",
      "23    2\n",
      "24    1\n",
      "25    3\n",
      "26    2\n",
      "27    2\n",
      "28    3\n",
      "29    2\n",
      "30    2\n",
      "31    3\n",
      "32    2\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [909] ------ \n",
      "\n",
      "The number of BAD trials is - [21].\n",
      "\n",
      "The number of GOOD trials left is - [42].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     0\n",
      "2     2\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     2\n",
      "7     2\n",
      "8     1\n",
      "9     2\n",
      "10    2\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    2\n",
      "15    1\n",
      "16    0\n",
      "17    1\n",
      "18    1\n",
      "19    1\n",
      "20    1\n",
      "21    1\n",
      "22    1\n",
      "23    2\n",
      "24    2\n",
      "25    2\n",
      "26    1\n",
      "27    1\n",
      "28    2\n",
      "29    2\n",
      "30    2\n",
      "31    1\n",
      "32    1\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [904] ------ \n",
      "\n",
      "The number of BAD trials is - [64].\n",
      "\n",
      "The number of GOOD trials left is - [53].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "cell\n",
      "1    15\n",
      "2    13\n",
      "3    12\n",
      "4    13\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [912] ------ \n",
      "\n",
      "The number of BAD trials is - [35].\n",
      "\n",
      "The number of GOOD trials left is - [34].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     0\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     2\n",
      "9     2\n",
      "10    1\n",
      "11    2\n",
      "12    1\n",
      "13    2\n",
      "14    1\n",
      "15    1\n",
      "16    1\n",
      "17    1\n",
      "18    1\n",
      "19    2\n",
      "20    2\n",
      "21    1\n",
      "22    2\n",
      "23    2\n",
      "24    1\n",
      "25    1\n",
      "26    1\n",
      "27    1\n",
      "28    1\n",
      "29    2\n",
      "30    2\n",
      "31    1\n",
      "32    1\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [105] ------ \n",
      "\n",
      "The number of BAD trials is - [11].\n",
      "\n",
      "The number of GOOD trials left is - [35].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "cell\n",
      "1    9\n",
      "2    9\n",
      "3    8\n",
      "4    9\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [106] ------ \n",
      "\n",
      "The number of BAD trials is - [10].\n",
      "\n",
      "The number of GOOD trials left is - [22].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "cell\n",
      "1    7\n",
      "2    4\n",
      "3    5\n",
      "4    6\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [107] ------ \n",
      "\n",
      "The number of BAD trials is - [25].\n",
      "\n",
      "The number of GOOD trials left is - [84].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "cell\n",
      "1    20\n",
      "2    22\n",
      "3    24\n",
      "4    18\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [115] ------ \n",
      "\n",
      "The number of BAD trials is - [14].\n",
      "\n",
      "The number of GOOD trials left is - [122].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     3\n",
      "2     4\n",
      "3     4\n",
      "4     4\n",
      "5     3\n",
      "6     5\n",
      "7     4\n",
      "8     4\n",
      "9     4\n",
      "10    4\n",
      "11    5\n",
      "12    4\n",
      "13    4\n",
      "14    3\n",
      "15    3\n",
      "16    5\n",
      "17    3\n",
      "18    5\n",
      "19    3\n",
      "20    4\n",
      "21    4\n",
      "22    2\n",
      "23    3\n",
      "24    4\n",
      "25    5\n",
      "26    3\n",
      "27    4\n",
      "28    4\n",
      "29    4\n",
      "30    4\n",
      "31    3\n",
      "32    4\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [116] ------ \n",
      "\n",
      "The number of BAD trials is - [19].\n",
      "\n",
      "The number of GOOD trials left is - [32].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     2\n",
      "2     0\n",
      "3     0\n",
      "4     1\n",
      "5     0\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    2\n",
      "13    2\n",
      "14    2\n",
      "15    0\n",
      "16    1\n",
      "17    1\n",
      "18    1\n",
      "19    1\n",
      "20    1\n",
      "21    1\n",
      "22    1\n",
      "23    1\n",
      "24    1\n",
      "25    1\n",
      "26    1\n",
      "27    0\n",
      "28    2\n",
      "29    1\n",
      "30    1\n",
      "31    1\n",
      "32    1\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [910] ------ \n",
      "\n",
      "The number of BAD trials is - [40].\n",
      "\n",
      "The number of GOOD trials left is - [13].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     0\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    1\n",
      "17    0\n",
      "18    1\n",
      "19    1\n",
      "20    0\n",
      "21    1\n",
      "22    0\n",
      "23    1\n",
      "24    1\n",
      "25    1\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "dtype: int64\n",
      "\n",
      " ----- Printing data for participant - [908] ------ \n",
      "\n",
      "The number of BAD trials is - [19].\n",
      "\n",
      "The number of GOOD trials left is - [59].\n",
      "\n",
      "The number of GOOD trials left for each WORD is - \n",
      "1     2\n",
      "2     1\n",
      "3     3\n",
      "4     3\n",
      "5     1\n",
      "6     1\n",
      "7     2\n",
      "8     2\n",
      "9     2\n",
      "10    3\n",
      "11    3\n",
      "12    1\n",
      "13    2\n",
      "14    2\n",
      "15    1\n",
      "16    2\n",
      "17    2\n",
      "18    1\n",
      "19    2\n",
      "20    2\n",
      "21    2\n",
      "22    1\n",
      "23    2\n",
      "24    1\n",
      "25    2\n",
      "26    2\n",
      "27    2\n",
      "28    1\n",
      "29    2\n",
      "30    2\n",
      "31    2\n",
      "32    2\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-139099e92300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_data_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"average_trials\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_data_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"average_trials\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/jwlab_eeg/classification/notebooks/../code/jwlab/ml_prep.py\u001b[0m in \u001b[0;36mprep_ml\u001b[0;34m(filepath, participants, downsample_num, averaging)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprep_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"average_trials\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ml_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprep_ml_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownsample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maveraging\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/jwlab_eeg/classification/notebooks/../code/jwlab/ml_prep.py\u001b[0m in \u001b[0;36mprep_ml_internal\u001b[0;34m(df, ys, participants, downsample_num, averaging)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0maveraging\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"average_trials\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0maveraging\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"average_trials_and_participants\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_trials_and_participants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/jwlab_eeg/classification/notebooks/../code/jwlab/ml_prep.py\u001b[0m in \u001b[0;36maverage_trials\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maverage_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mnum_participants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticipant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_participants\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11616\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11617\u001b[0m         return self._reduce(\n\u001b[0;32m> 11618\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11619\u001b[0m         )\n\u001b[1;32m  11620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4088\u001b[0m                 )\n\u001b[1;32m   4089\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4090\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4092\u001b[0m         \u001b[0;31m# TODO(EA) dispatch to Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0m_na_for_min_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0m_USE_BOTTLENECK\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mskipna\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_bn_ok_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbn_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_t, y_train_t = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials\")\n",
    "X_test_t, y_test_t = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials\")\n",
    "\n",
    "(n_train, d_train) = X_train_t.shape\n",
    "assert n_train == y_train_t.shape[0]\n",
    "\n",
    "(n_test, d_test) = X_test_t.shape\n",
    "assert n_test == y_test_t.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Average_trials_and_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tp, y_train_tp = prep_ml(cleaned_data_filepath, participants_train, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "X_test_tp, y_test_tp = prep_ml(cleaned_data_filepath, participants_test, downsample_num=1000, averaging=\"average_trials_and_participants\")\n",
    "#(n_train, d_train) = X_train_tp.shape\n",
    "#assert n_train == y_train_tp.shape[0]\n",
    "\n",
    "#(n_test, d_test) = X_test_tp.shape\n",
    "#assert n_test == y_test_tp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0fcde81e2e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_n' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_n[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 60000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_tp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8eaa1d4c8faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_tp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_tp' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_tp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setting up the SVM model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(C=1e-9, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training and testing the model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([             0          1          2          3          4          5  \\\n",
      "0   -30.365461 -10.150289 -11.331446 -16.552408 -28.335586 -10.571514   \n",
      "1    43.485099  -3.251348   0.411060 -11.423566   9.771688  -7.470434   \n",
      "2    22.185692  18.354441  21.518878  36.510817  23.690786  36.522364   \n",
      "3     3.209257 -13.511627 -11.127122   0.041750  17.467095  -7.070573   \n",
      "4    -3.288182  16.429079  14.399019  -3.482504  37.663264  -5.540013   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243 -46.450927  10.339660  28.288188  16.023199  -0.675248  31.862300   \n",
      "245  22.770258  40.397485  31.916157   3.617571  14.506172  26.020750   \n",
      "246  -3.562276 -12.069647 -12.560687 -20.477227 -15.336691 -19.125369   \n",
      "250 -16.281545 -16.987810   8.139501  40.923125 -27.232067  21.754002   \n",
      "253  -3.148964  -8.760440  -5.535199   2.862506  -0.207912  -5.235384   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -16.420266 -12.748386  -6.911270 -28.697455  ...  11.542787   6.136566   \n",
      "1   -21.357981  19.547690  -9.643892  16.478038  ...  17.029140  25.452431   \n",
      "2    27.819429  31.650188  33.191985  20.500177  ... -15.058554 -11.654922   \n",
      "3     7.063086  -0.106122  -7.046502  -3.922165  ...  30.018742   7.802777   \n",
      "4    -8.951588   4.724392  -5.397571  -0.004893  ...  30.553857  28.055308   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243  18.813316  33.285080  38.411850  59.507290  ... -12.070109 -21.018422   \n",
      "245  -2.386791  28.864946  22.715142   3.128895  ...  -1.185436  -7.878887   \n",
      "246 -17.330326 -20.348678 -21.781630 -19.057552  ... -12.073243   1.780307   \n",
      "250  49.639829  11.842247  21.196039 -26.567335  ...  -0.625588 -21.888361   \n",
      "253  12.076359  -5.621329  -4.161992  -2.885535  ...  12.010073  -0.129963   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    17.541435  15.698724   5.791363   8.092618   0.206817  -0.634856    0.0   \n",
      "1    -3.687204  15.807909  21.042183  31.851772  21.114626  20.349917   10.0   \n",
      "2    -1.161166 -34.869264 -28.353118 -16.918095 -33.254536 -15.254924    5.0   \n",
      "3    11.486099  84.329554  37.780771  56.425496  40.487708  19.978197   12.0   \n",
      "4    22.489808  27.299621  23.065329  19.317335  19.502350  24.515661    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  27.192918   7.093772 -22.111937  38.821729  -4.524833 -10.287173    0.0   \n",
      "245  -2.043356   3.578135   3.442044  -5.112819   9.809145  -8.837108    5.0   \n",
      "246  19.372068  15.436083 -15.321436  22.679333  -1.238009   4.469245   13.0   \n",
      "250 -13.569748  -3.172773  -5.957531   1.779223  -6.700278 -17.543231   14.0   \n",
      "253  -5.556463   5.018926  -3.415558   8.534638 -28.258801  -3.618837    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0     1.156869  -2.449895  -5.886379 -16.528439 -66.641327  -6.012829   \n",
      "1     3.527469  -4.452251   3.006054   8.259597  -6.441568   1.101110   \n",
      "2    10.245288  -0.301576   4.461788  13.543453  14.435807  15.996798   \n",
      "3    51.223252 -16.750240 -17.177588  -2.543640  45.504954 -14.700503   \n",
      "4   -59.125610  13.795985  14.015739   2.652609  -9.418975   2.806600   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243 -35.736135   2.337416  18.399362  16.349109 -20.092956  23.652996   \n",
      "245  41.247571  35.974175  25.327676  10.548953  23.097050  29.120897   \n",
      "246  20.886049 -18.937338 -13.026832   3.696222  18.189193 -15.670652   \n",
      "250  -0.774435  23.597398  15.273521  42.935291  -3.941147  25.377553   \n",
      "253  24.190792   8.409979   7.431145  10.859155  21.462894  10.778683   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -24.858889  -3.477535  -3.812908 -31.209049  ...   1.670916  11.307080   \n",
      "1    -4.286275  12.037424   7.720124  29.988888  ...   1.009820   3.351135   \n",
      "2     9.803195  23.055512  17.574435  14.984021  ...   3.808228  -9.874136   \n",
      "3    -1.724612  -1.078351 -17.473959   7.499649  ...  23.936105   8.043212   \n",
      "4    -3.773600  -2.561641   4.975391 -32.964097  ...  24.239909  35.489828   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243  20.009043  32.667678  31.375275  39.500170  ... -13.216769 -24.011217   \n",
      "245   7.584981  36.081250  28.828229  22.691226  ...  -9.216813  -7.003797   \n",
      "246   3.365531 -17.308000 -20.912836  -6.541864  ... -15.072507 -13.579971   \n",
      "250  39.808456  18.880873  20.159135   0.922685  ...   1.243681 -26.990212   \n",
      "253  22.943573  11.064979  11.544279  11.719785  ...  15.528593  17.431461   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0   -15.330021 -10.553310  -2.692455 -31.486052  -3.069423  -1.478407    0.0   \n",
      "1    -0.151514  -4.481861   3.544631  19.137164   5.337672  -2.586164   10.0   \n",
      "2    26.140617  12.675628  -8.826831  63.336647 -17.407605 -12.478327    5.0   \n",
      "3   -17.453297  54.645560  34.969225  21.814103  45.558438  19.624531   12.0   \n",
      "4    38.193390  11.031997  12.794178  41.082442  10.636542  32.958210    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243 -10.819779  -8.919347   6.588134  17.350067   9.307130 -26.617843    0.0   \n",
      "245   7.577277 -18.369391 -21.454055  -7.865334 -15.972222 -19.482717    5.0   \n",
      "246  18.629781  13.485510 -25.494851  21.362300 -22.977538 -11.786572   13.0   \n",
      "250 -16.156112  -7.334999  -4.513172 -21.311950  -7.350719 -17.318867   14.0   \n",
      "253 -25.618572  -1.007170  11.774403 -12.541516 -21.308512   9.834155    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0    -5.056129   8.482432   5.390734   0.690385 -13.201880   3.757192   \n",
      "1   -15.037153  -2.189093   3.402159  17.133372 -11.021756   8.303516   \n",
      "2    15.019014   7.056049  12.963931  22.190694  17.717682  15.994974   \n",
      "3    25.718569  14.806540   2.237779 -16.877448  16.434200 -20.337782   \n",
      "4   -38.867607  41.090571  50.341304  27.656215  49.315972  49.841713   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243 -12.347863   8.969151  10.724810   9.724225 -18.679727   5.715886   \n",
      "245  44.682341  16.109265  15.286328  21.812121  16.124218  25.172325   \n",
      "246  16.300115  -5.082118  -9.355369   0.323576 -10.037450 -17.189472   \n",
      "250  28.222472   4.714425   7.537889  44.173894  12.930566  22.652361   \n",
      "253  10.022286   9.000085   2.914244  -2.429621  -5.096885   4.402272   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0    -8.592201  -1.137213   2.697915 -14.775067  ...  -0.092425  11.272747   \n",
      "1     3.909636   9.018064  15.324024  23.276978  ...   3.901095  10.616406   \n",
      "2    19.811848  19.222279  10.046739   5.463810  ...  12.195159 -13.691333   \n",
      "3   -18.942255  -7.846862  -9.396037   6.212340  ...  22.005262  29.263234   \n",
      "4    11.658510  59.209328  56.544164  48.658905  ...   9.393453  11.273343   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243  19.901275   9.442867  11.832366  -0.897005  ...  -2.505866  20.001583   \n",
      "245  10.564258  32.085943  24.073473  17.399093  ...   0.822897   0.607108   \n",
      "246  -4.827390 -16.263294 -20.435379  16.013788  ...   0.293205   2.388946   \n",
      "250  24.889105  17.504125  16.936939   4.103629  ...  10.100466  15.657987   \n",
      "253   6.704962   9.242510   8.495014  10.901914  ...  19.193729  20.407244   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0   -11.922515  -9.902540  -2.854490 -37.205459  -3.083508   0.121334    0.0   \n",
      "1    17.883461  -0.554748  12.085495  28.394887  17.931953   5.379190   10.0   \n",
      "2    15.943550  50.449758  10.081774  41.371097   9.005907   8.708318    5.0   \n",
      "3     0.767410  36.648684  33.791186  39.360757  46.528380  35.901825   12.0   \n",
      "4     7.193905  18.001084   0.386487  14.511141  -1.378543  17.105369    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  -0.294799 -10.691103  18.781023   8.365180  14.686422 -45.534038    0.0   \n",
      "245  23.652562   3.468499  -7.578779   7.550250 -16.354706 -15.922138    5.0   \n",
      "246  -1.661316  20.035084 -10.400783  29.414736   6.971354  12.240696   13.0   \n",
      "250  -4.687865  -0.637296   7.660606 -18.322182  -7.404660 -10.151121   14.0   \n",
      "253  -6.357639   8.772897  20.522175  -1.716308  17.661548   7.154151    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0    -9.678749  -5.623320  -9.795320 -13.344297 -25.533029  -9.676516   \n",
      "1   -38.214031  -6.619640  -0.497944  23.609950 -25.446077   7.861495   \n",
      "2   -35.260326  -3.662701   1.056041   9.400193 -24.591382  -4.726268   \n",
      "3     5.010018  31.926415  16.039667 -11.916654  48.514080  -5.035620   \n",
      "4   -77.508807   8.823458  21.518690  27.652983  16.167082  33.524430   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243 -68.746748 -11.922760  -4.973986   9.483905 -34.619072   0.274996   \n",
      "245 -18.073465   9.779280   3.016351  15.599116  14.413085  13.186332   \n",
      "246  22.457278 -13.309528 -24.618338 -22.633204  -5.688392 -32.987574   \n",
      "250  10.346186  36.522756  25.668204  52.750261  93.438110  45.924455   \n",
      "253  15.788331  31.944828  27.288309  15.117755  20.199488  30.850715   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -25.295692   0.379275  -9.868433   8.915428  ...   3.925660  12.321903   \n",
      "1     9.614839   5.894099  13.658656  -2.638808  ...  -3.577067   4.875553   \n",
      "2     7.634760 -10.295128  -9.157694 -16.232522  ...  29.714635  -1.061976   \n",
      "3   -27.385610  12.910894   6.122263  25.078720  ...  16.030633  20.687767   \n",
      "4    32.975607  28.754862  40.429807  25.352545  ...  12.431513  17.315263   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243  11.501846   2.680656  10.145907  -5.145081  ...   8.103613  22.138772   \n",
      "245   2.364179  19.639119  19.556649  15.186485  ... -12.182777 -17.434750   \n",
      "246 -33.810695 -29.210484 -41.875907 -18.098603  ...  -9.715464  -9.911906   \n",
      "250  26.769579  45.959464  32.640649  76.297099  ...  16.408607  17.302633   \n",
      "253   8.562276  35.885745  29.775613  34.293388  ...  21.732650  26.111879   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0   -30.056375  -9.582153  -0.830296 -42.435943  -3.216613  -2.691940    0.0   \n",
      "1     1.624888 -19.161191   1.740257   3.393758   8.918941  -1.451703   10.0   \n",
      "2    23.377319  60.665932  27.537024  50.882914  34.627671  26.481362    5.0   \n",
      "3     9.709256  10.130552  17.235514  31.158820  18.491450  11.068150   12.0   \n",
      "4    -6.003413  48.949285   5.961434   0.721548   5.200756  30.848909    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  22.945328  17.996205  41.225280  45.374305  35.991719 -30.915363    0.0   \n",
      "245  21.340274   7.852488 -16.167390  17.210441  -2.768190 -18.893696    5.0   \n",
      "246  17.741819  13.566647 -14.873988  37.752265   8.085984   2.017499   13.0   \n",
      "250   5.956049   9.603254  14.016561   5.553677  -7.243251 -12.680238   14.0   \n",
      "253  17.581312   8.898582  26.215507  11.007979  21.013567   7.089638    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],               0          1          2          3          4          5  \\\n",
      "0    -34.029318 -32.114535 -32.586026 -18.314403 -39.049087 -28.217714   \n",
      "1     -6.406481 -39.051048 -33.579185   5.703713 -70.711900 -11.573658   \n",
      "2    -27.012814  -2.023427  -0.229758  -5.479194  -2.057137  -8.652238   \n",
      "3    -39.875447  46.901996  36.555578   0.819149  51.349689  20.375218   \n",
      "4   -107.576116  14.053641  21.076034  26.299490 -20.434705  22.086519   \n",
      "..          ...        ...        ...        ...        ...        ...   \n",
      "243  -46.760966   6.988207  13.515779  -1.816619 -15.750518   7.392137   \n",
      "245 -104.563904 -30.828394 -25.750869   3.796610 -66.493572 -16.883159   \n",
      "246   27.918159 -15.926670 -16.846429 -10.630123 -14.679608 -19.287962   \n",
      "250   99.272606  40.913167  24.513908  46.903890  65.539512  29.749558   \n",
      "253   25.167523  42.006590  33.581939  11.440658  45.481061  36.289345   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -23.937691 -30.122204 -25.321320 -26.640018  ...  -9.676475 -12.627042   \n",
      "1   -15.511333 -26.821291 -13.177013 -49.577416  ... -11.207278  -6.462743   \n",
      "2    -9.886743  -2.225675  -2.645901   9.195029  ...  34.336486  15.319367   \n",
      "3    -8.564142  28.116168  34.257510  32.017872  ...  19.857549  22.805084   \n",
      "4    33.754361   4.852044  27.056754 -12.578091  ...   4.784449   6.321523   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243   3.341523  11.932439  10.913339  -1.479063  ...   3.971752  18.757464   \n",
      "245 -10.955117 -15.777598  -5.465228 -26.815431  ... -12.716532  -9.386712   \n",
      "246 -22.552398 -18.327120 -25.608809  -3.558075  ...  -0.227879  -8.040492   \n",
      "250  23.074144  28.374514   8.171853  20.121100  ...  18.890024  18.370139   \n",
      "253   4.218689  41.517289  36.972495  46.651971  ...  12.610266  18.937581   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    24.485049   8.131914 -13.474632  -5.172824 -22.214008 -35.828682    0.0   \n",
      "1     3.641575 -18.104759   0.275172 -11.511921  11.798301  -2.788040   10.0   \n",
      "2     5.815089  67.466481  30.483697  28.479680  41.320313  42.451789    5.0   \n",
      "3    13.108918  10.845519  23.894974  24.538890  26.213843  16.318185   12.0   \n",
      "4   -19.849897  40.127373  -5.159918 -26.201628 -11.651724  17.926990    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  37.900221  -1.343099  31.428570  42.802618  48.381592 -31.410497    0.0   \n",
      "245   7.278962   2.084745 -11.378481   4.802166   4.582631 -13.570177    5.0   \n",
      "246  12.291975  13.469752   6.950851  26.685195  16.523905  22.980783   13.0   \n",
      "250  11.486042   4.847146   9.942607  -0.721719 -24.063451 -16.506455   14.0   \n",
      "253   9.387434  -5.754090  14.464816   2.734897  22.223513 -11.984525    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],               0          1          2          3          4          5  \\\n",
      "0    -19.954811 -16.433606 -17.487851  -8.719210 -20.632442 -10.905085   \n",
      "1     28.900714  31.227422  30.577476  17.976368  -7.058029  33.209740   \n",
      "2    -35.041594   0.628815  -0.122737   6.056098 -12.544546  -4.402132   \n",
      "3    -39.514557  46.293597  42.575213   6.118125  62.854101  22.594540   \n",
      "4   -113.581022   3.391581   8.474042  28.997430  -5.619309  21.549717   \n",
      "..          ...        ...        ...        ...        ...        ...   \n",
      "243   -6.712360  12.963389   8.843803 -18.006257  -9.396992 -15.107708   \n",
      "245  -73.456612 -17.584128  -9.663870   1.689608 -43.210794  -9.749313   \n",
      "246   27.660469  -9.318739 -17.391506 -30.064854   0.204422 -14.498571   \n",
      "250  119.314210  32.367513  18.789901  40.270078  72.373915  20.820256   \n",
      "253   29.126384  30.757641  36.496639  14.198640  36.477676  29.784075   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -11.486981 -11.028392 -11.023154 -12.867178  ...  25.031145  31.719245   \n",
      "1    27.135295  38.039566  29.890376  16.627168  ... -14.383827  -5.766642   \n",
      "2     1.986156 -13.295517   0.096029 -12.243754  ...  35.670812  19.774078   \n",
      "3   -12.866115  33.869351  31.589855  35.666383  ...   6.697016  17.864063   \n",
      "4    28.130275   1.921800  26.316930 -29.040311  ...  21.339538  16.646064   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243  -3.576171 -17.863826 -10.512558 -20.131302  ...  13.195242  17.761566   \n",
      "245  -4.493090 -12.445818   3.361688 -12.195440  ... -16.840721 -12.884377   \n",
      "246 -23.635671 -10.284373 -14.578836   8.069114  ...  -8.126764   0.222530   \n",
      "250   7.059523  21.254651   4.343799  44.425187  ...   9.944586  17.976315   \n",
      "253   1.486429  35.456007  18.771004  36.426424  ...  14.639291  16.540678   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    10.928560  28.620705  29.854719  15.793008  26.721806  23.914965    0.0   \n",
      "1   -14.216485 -25.957101  -3.970059 -27.173134   9.558855  -4.271128   10.0   \n",
      "2    44.684279  65.385626  34.623359  52.000793  39.514474  53.061455    5.0   \n",
      "3   -30.271621 -17.540227   3.100155 -26.174114   8.056166   0.827187   12.0   \n",
      "4    -8.651366  51.023258  13.098105 -26.593317   5.401302  33.128036    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  12.464072   5.632871  37.670784  11.366810  48.509949 -28.000544    0.0   \n",
      "245  -5.816416 -26.108859 -28.501465  -3.127632 -15.459757 -20.525296    5.0   \n",
      "246  28.909204  22.323168  -1.107355  15.894655   6.498919   2.531956   13.0   \n",
      "250  -1.741199  -5.238884  -6.538672 -13.160838 -29.921342 -24.581996   14.0   \n",
      "253 -21.786372 -10.118350  10.560584 -10.653639   4.026802 -20.001598    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],               0          1          2          3          4          5  \\\n",
      "0     21.478704 -16.202043 -17.625566 -12.872748 -27.500777 -12.933619   \n",
      "1     14.741623  12.263899   9.722502  -5.752114  -9.317083  -8.870565   \n",
      "2     -1.933746  -3.375267  -2.098542  10.272670   9.605979  11.215095   \n",
      "3   -117.385904  26.261928  25.477936   9.544183  18.451670   6.388503   \n",
      "4   -123.356399  16.475277  17.383186  24.007238  -7.261548  33.538990   \n",
      "..          ...        ...        ...        ...        ...        ...   \n",
      "243  -26.293329  16.676845  18.989822  -9.565849 -30.420635   5.573042   \n",
      "245  -39.266342  -5.123061   4.527222   0.090926 -27.301131  -2.769994   \n",
      "246   17.224453  12.520049   4.872676  -3.161062   1.867133   1.535458   \n",
      "250   72.614311  22.121054  -1.896369  18.768637  32.501136   9.623000   \n",
      "253   28.046510  20.882377  30.802285  21.123269  30.619512  27.478312   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -17.615367 -13.799542 -16.026324 -14.578970  ...   8.455918  14.805498   \n",
      "1     1.455703  -2.778013 -11.682047  -0.476836  ... -22.037011  -8.784935   \n",
      "2    14.088627  14.391938  19.773601  19.021450  ...  45.411489  24.071734   \n",
      "3     2.440808  -4.169923  11.924557 -24.258628  ... -19.058607   4.378044   \n",
      "4    26.115557  14.692712  43.778206  -0.049694  ...  13.967957  19.866698   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243   2.594034   3.402232   1.071030 -11.340324  ...   0.114090   1.003528   \n",
      "245   5.175607  -6.605544   5.307296   1.964453  ...   2.212396  -1.388602   \n",
      "246  -3.514529   5.122530  -0.255599  13.990217  ... -20.059630 -15.082265   \n",
      "250  -6.979111  15.057104  -6.264083  32.574971  ...  18.092417  15.976358   \n",
      "253  15.949123  32.661970  19.428727  22.610566  ...   5.240049  15.219369   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0     0.731753  -3.703545  14.095652  14.328890  17.058552   9.952460    0.0   \n",
      "1   -19.485919 -47.008013 -17.238258 -39.236682  -8.152806  -9.848530   10.0   \n",
      "2    47.462615  83.612465  39.805326  27.173829  41.627646  37.826744    5.0   \n",
      "3   -59.044564 -55.225871 -19.490473 -37.326957  -9.328630   1.343811   12.0   \n",
      "4    -5.183041  34.087568  16.079238   5.620999  14.658565  43.335238    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  -6.938831  -8.910062   9.968385   1.458111  24.069594 -50.992961    0.0   \n",
      "245   8.597477   3.407875   2.229693  18.224139  28.096581  11.520535    5.0   \n",
      "246  11.030517   8.540619 -12.368480   5.644885  -7.796014 -17.143823   13.0   \n",
      "250   5.074967  -0.886835  11.109396 -14.355395 -12.542413  -8.990780   14.0   \n",
      "253 -28.892801 -22.413836  -8.607247 -10.344703 -17.759924 -32.824620    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns]])\n",
      " list([             0          1          2          3          4          5  \\\n",
      "0   -30.365461 -10.150289 -11.331446 -16.552408 -28.335586 -10.571514   \n",
      "1    23.624220  11.831870   5.135747   6.564256  -7.420072   4.063886   \n",
      "2     0.596842   6.993564  13.558812  24.759899  15.203109  33.033023   \n",
      "3     9.624738  22.980475  20.510046  -0.112892   2.694442   4.563533   \n",
      "4    -0.093478   7.874365   8.941963   9.599172 -15.142835   0.956802   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  32.290203  13.804853   6.567158 -16.888996  16.373949   1.851255   \n",
      "245  22.807585 -27.749473 -21.819516 -20.986326   8.938446  -6.525144   \n",
      "246 -11.159860  -7.479614   3.894676  17.279051 -24.289297   4.900202   \n",
      "250 -26.305747 -17.531733  -0.120229  36.068786 -29.993599   4.795179   \n",
      "253   1.626116  19.422400  20.105210  47.460014  34.332303  30.806939   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -16.420266 -12.748386  -6.911270 -28.697455  ...   7.025501   3.178941   \n",
      "1     5.161748  12.974830   7.154433  10.320645  ...   3.968651  12.611927   \n",
      "2    23.032495  30.918262  36.889863  28.481361  ...   0.974345   4.158013   \n",
      "3     9.290486  22.107604  14.009967  49.428449  ...  21.942847  11.208775   \n",
      "4     7.691760  -6.709760 -14.049231 -58.130674  ...  37.221951  38.538733   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -21.283096   3.414427  -6.684961  13.028431  ...   9.465910 -10.483453   \n",
      "245 -16.463391   5.404552   7.059470   2.106066  ...   5.928201   6.379203   \n",
      "246   8.027345   6.657196  -1.704551  -0.003780  ... -12.442791   0.679465   \n",
      "250  44.746957  -4.685046   7.090620  -1.910830  ...   2.524146  -5.937050   \n",
      "253  40.983660  35.619308  35.529947  25.687377  ...   6.017946  21.363418   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    12.057495   0.054056  -4.745035 -13.430576   2.272185   8.381643    0.0   \n",
      "1    -2.456948   1.464037   8.974128   7.867166  10.909743   5.925265   10.0   \n",
      "2    -9.424890  -0.253636  11.987716  14.718498  16.810298  16.851235    5.0   \n",
      "3    23.870935  42.440862  16.615408   8.992701   9.573602   8.632203   12.0   \n",
      "4    27.992279  40.935141  32.387948  61.068751  38.704768  49.398778    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  -6.142045   7.140348 -10.562173  14.466638 -15.822424  -2.549355    0.0   \n",
      "245  -3.757623   8.951619   9.126490  -4.906587  28.397243  26.755157    5.0   \n",
      "246  13.901573  11.455357 -20.080144   8.920567 -12.017759   5.371846   13.0   \n",
      "250   1.075928 -10.455566  -3.402385 -19.500686  29.273314  -0.908972   14.0   \n",
      "253 -17.625122  -0.414299   4.684177   2.167272   3.808020  12.130783    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0     1.156869  -2.449895  -5.886379 -16.528439 -66.641327  -6.012828   \n",
      "1    47.908505  14.280598  11.092288  -6.399181   7.088176  -0.595095   \n",
      "2     2.557235  -5.477106  -1.330979  12.259891  -5.843000   8.630153   \n",
      "3   -27.480597 -26.548787 -16.787130   2.890299  33.798543   2.987322   \n",
      "4     5.807539  18.745351  18.831584   9.579997  -7.088643   4.052930   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  44.590145  31.114084  18.918310 -25.679995  39.339924  24.492588   \n",
      "245  81.482617   6.859803 -19.619049 -11.579531  66.765001  -3.731703   \n",
      "246  15.073562  -7.930376 -12.904310  14.361826  10.088646 -14.678979   \n",
      "250 -11.847069 -20.612547   2.049407  36.018956   5.656389  12.746917   \n",
      "253  10.350007  13.430969   9.220408  44.159660  55.806194  11.776739   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -24.858889  -3.477535  -3.812908 -31.209049  ...  17.179639  11.401466   \n",
      "1   -21.762225  21.005547  -2.714815  13.776952  ...   2.932395   4.889784   \n",
      "2    10.348635  13.846501   7.789859  11.449255  ...  -9.277889 -15.457648   \n",
      "3    15.371343  13.164289  13.608935  34.257875  ...  33.321406  12.420408   \n",
      "4     7.991792   7.064236  -1.429118 -23.306972  ...   9.136981  16.802345   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -22.678947  34.718235  21.764145  39.997356  ...  11.181592  -2.744533   \n",
      "245 -13.169378   6.300294   6.719192  19.530870  ...  -3.460743  -1.794727   \n",
      "246   1.212302 -14.102680 -21.530166  -9.831257  ...  -7.486104   6.832269   \n",
      "250  46.326959   9.973948  11.028670 -14.938412  ...  -7.147620  15.518906   \n",
      "253  26.248824  17.742591  16.597823  51.200610  ...   7.075181  18.965175   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    25.918617  18.894441   8.378657   4.689518  11.071903  14.152029    0.0   \n",
      "1     3.633544   7.145615   8.290950  11.878678   6.353404  -5.657011   10.0   \n",
      "2    -3.164598 -11.996293 -10.842950  22.881252 -14.726719 -27.445745    5.0   \n",
      "3    17.134769  70.026621  30.287332  27.209750  27.273654  18.569944   12.0   \n",
      "4    30.772119   2.996681   3.989563  91.733423   5.585574  30.516161    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243 -16.240546 -11.363343  -4.339351  12.343639  -8.950239 -12.637199    0.0   \n",
      "245  26.398114   3.345598 -12.813801  -0.289419  -6.240348  -7.179845    5.0   \n",
      "246  -0.363153   9.004366   1.119952 -10.757647  13.291090   5.421205   13.0   \n",
      "250 -23.303309 -32.986740 -27.361712 -19.573514 -18.193362 -29.880312   14.0   \n",
      "253  -6.305856   2.779801   1.935980   8.274946 -11.255836   6.067304    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0    -5.056129   8.482432   5.390734   0.690385 -13.201880   3.757192   \n",
      "1    -1.646931  -2.293585  -3.032438  10.929570  -9.732370   1.328374   \n",
      "2    -9.634888  15.491758  23.695395  33.206847  -9.274997  20.880513   \n",
      "3   -35.306825   9.119303  10.974781 -10.051784 -11.634253  -3.730101   \n",
      "4    25.353911  34.412875  36.535675  32.521406  21.131808  27.657800   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  44.602810  15.978108  10.583978 -34.825909  42.291382  17.293104   \n",
      "245  23.532953 -16.665975 -24.118598  14.843607  18.713335   0.712591   \n",
      "246  -4.833972 -21.648416 -13.809937  -6.805375 -20.235112 -23.717247   \n",
      "250 -18.450750  14.218558  22.083595  42.951286  26.189226  28.845478   \n",
      "253   9.991076  13.800396  12.032556  41.603819  11.817385  13.079245   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0    -8.592201  -1.137213   2.697915 -14.775067  ...   6.001164  11.083920   \n",
      "1    -0.336464   3.490742   5.444286  17.613427  ...  11.484198  27.650105   \n",
      "2    13.864860  10.027201  16.531474  -4.365091  ...   2.655833  -7.934818   \n",
      "3   -10.672436  14.422185  18.787930  52.014087  ...  41.820275  29.623994   \n",
      "4    26.594827  27.401421  25.788242 -19.382969  ...  12.127892  21.456892   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -36.998695  27.865292  14.000935  47.391926  ...  27.123673  42.488636   \n",
      "245   1.124445   9.665943  10.108427  17.251412  ...  -8.390788  -9.420490   \n",
      "246 -13.242370 -21.205750 -31.014713 -12.580131  ... -18.924104   0.792890   \n",
      "250  33.444361  25.069566  23.251646  11.685341  ...   5.223858  12.731944   \n",
      "253  23.897695  20.614131  13.993663  17.252508  ...  14.992244  24.712173   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0     3.162940  -2.525452  -3.294142 -35.632292  -5.182436  -1.405352    0.0   \n",
      "1     1.276606   0.937555  21.045375  16.237691  24.530127  15.339622   10.0   \n",
      "2    -2.653484  16.484236  16.604420  25.111312  26.403952   6.403869    5.0   \n",
      "3    32.244237  82.838487  38.975130  65.452216  35.585436  31.784749   12.0   \n",
      "4     3.693005   1.559348   6.727805  15.468086  19.908519  42.063466    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243 -19.034599   3.363127  15.936500 -14.080034  -3.062113  -5.825524    0.0   \n",
      "245  17.937781   7.294614   1.002972  -7.482992  13.388067  -5.573639    5.0   \n",
      "246 -24.173814 -22.801146 -23.895025 -45.425083  -7.172086 -21.071388   13.0   \n",
      "250  18.280897  -0.001103   6.032674  32.411737  32.961350  -0.862775   14.0   \n",
      "253   1.099656  14.850794  12.675245  15.469641  20.112826  16.018065    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0    -9.678749  -5.623320  -9.795320 -13.344297 -25.533029  -9.676516   \n",
      "1    -3.044511  14.324110  17.189136  24.456237  -1.813895  18.636221   \n",
      "2     1.770599 -24.920670 -16.309776  13.776919 -17.082761  -1.410643   \n",
      "3   -38.700022  -9.873421  -9.668798 -22.379858   4.931121 -25.193770   \n",
      "4    15.410767  32.353104  36.130491  40.496804   8.231250  47.358675   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  50.820190   4.015958   8.962578 -41.029442  60.895775   3.787923   \n",
      "245   6.582407   3.255070 -19.340696  11.840232  -3.788995  -7.583689   \n",
      "246  -0.345721 -22.913759 -14.132976 -18.458878 -27.304213 -23.400555   \n",
      "250 -60.857481  -1.366191   6.445515  37.113252  16.798472  30.034475   \n",
      "253  15.571224  21.671375  16.215540   5.163935  -0.211976  20.105683   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -25.295692   0.379275  -9.868433   8.915428  ...  10.976902  20.989431   \n",
      "1     3.695612  15.497472  21.594481  19.367252  ... -16.846823  -5.636259   \n",
      "2    -4.784161 -14.799872  -3.055347 -10.167543  ...  10.385463 -15.799705   \n",
      "3   -34.324107   2.245830  -8.851719  25.651382  ...  12.593412  17.457556   \n",
      "4    38.546571  43.545487  50.191833  -0.973229  ...  11.635734  10.338900   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -39.004158  15.448275  -1.290894  28.927305  ...  16.779193  33.316436   \n",
      "245  -3.477960  -0.855044  -3.934327   2.720719  ... -16.602723  -9.675112   \n",
      "246 -19.633260 -22.841585 -23.997050  -1.133939  ...   0.567295  18.748924   \n",
      "250  23.538805  24.832668  28.314477  34.364821  ...   1.483816   6.741782   \n",
      "253  17.092618  22.257504  16.581532  27.778867  ...  13.029028  13.801409   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    18.255104   7.619779   7.868019  -7.657091  12.003349  14.750878    0.0   \n",
      "1    10.213462 -22.753310 -11.549430  -0.286574 -12.928075 -22.323799   10.0   \n",
      "2     2.010027  24.439698   8.897278  35.579603   6.687373  -8.010532    5.0   \n",
      "3    15.527979  42.289518  13.053911  35.712905  14.387640  22.845570   12.0   \n",
      "4    18.293420  31.983510   3.288688 -10.310279   5.912444  26.487973    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  -9.144116  11.406427  11.051749  -2.471048   9.413591 -11.877855    0.0   \n",
      "245  32.140407   2.037593  -4.492382   0.833664  12.602494  -1.779730    5.0   \n",
      "246 -17.257554 -12.024859   5.314737 -21.800090  18.798954   8.545219   13.0   \n",
      "250  40.141503  -2.798040   4.065164  40.565559  12.772316  -7.881515   14.0   \n",
      "253  -6.192685   6.045756  -0.723926   1.928591  -9.800232  -9.388394    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],               0          1          2          3          4          5  \\\n",
      "0    -34.029318 -32.114535 -32.586026 -18.314403 -39.049087 -28.217714   \n",
      "1    -22.785813   2.241787   8.531159  20.160682 -16.136334  10.790910   \n",
      "2    -13.092126  -9.190998  -6.097360   8.879535 -21.603762  -0.101712   \n",
      "3   -110.861689   6.516440   5.323282  -6.595617  11.689735  -8.268841   \n",
      "4     35.802036  48.160780  51.741108  40.190632  17.104308  58.678548   \n",
      "..          ...        ...        ...        ...        ...        ...   \n",
      "243   27.786451  22.958116  12.439381 -33.960613  19.023544   1.433799   \n",
      "245   -7.003606   6.509600 -12.210197  -0.067309 -22.689695  -7.597755   \n",
      "246   -6.341077 -26.100594 -15.647713 -27.644827  -3.230834 -12.563698   \n",
      "250  -19.292666   4.702004  10.515608  53.081080  38.583763  36.909610   \n",
      "253   14.888115  31.609478  25.387462  -6.575702  -0.234045  24.187728   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -23.937691 -30.122204 -25.321320 -26.640018  ...   9.885566  14.134367   \n",
      "1     0.068801  11.910341  15.608458   3.938721  ... -14.451150  -5.831522   \n",
      "2    15.926010  -8.472137   0.335165 -11.207736  ...  25.305251   6.197281   \n",
      "3    -4.176525  -8.028220   5.826460 -14.746679  ...  19.808163  27.117186   \n",
      "4    31.319956  67.074786  67.157844  40.834056  ...   6.685411   5.867785   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -29.297342   9.764014  -7.912505  11.312757  ...  25.989894  46.507268   \n",
      "245  -5.683920  -0.774688   3.206447   8.121409  ...  -5.125141  -1.716678   \n",
      "246 -23.068829  -9.450614 -11.852621  18.908694  ... -11.571480   4.682463   \n",
      "250  32.960900  33.699310  26.477320  43.476971  ...  -5.375921  25.649103   \n",
      "253   1.955134  24.276210  12.759909  19.120638  ...   0.767820   2.932225   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0     3.150734  12.175516   9.113260 -12.930442  10.476242   9.041724    0.0   \n",
      "1   -18.824314 -31.015646  -8.270531 -33.452264  -7.486437 -14.864407   10.0   \n",
      "2    -3.316850  20.348059  18.624680  23.855342  27.671568   4.939473    5.0   \n",
      "3    28.209496  52.970486  24.574405  56.357516  27.390280  38.618516   12.0   \n",
      "4   -13.224289  33.585687   4.522592 -28.413571   3.741117  25.236761    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243 -11.550310   3.856570  11.449336   1.242600  -0.948336   1.410022    0.0   \n",
      "245   4.617481  -3.394182 -10.733400  -8.871251 -10.646661 -15.643896    5.0   \n",
      "246   9.859246   2.310643  -1.924380  -6.528079   9.587500 -13.655547   13.0   \n",
      "250  22.277942   7.415541  -3.082643  20.889098  11.943745 -28.262216   14.0   \n",
      "253  -8.027494  -4.996279  -1.915830   2.694181  -4.797858   0.072265    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],               0          1          2          3          4          5  \\\n",
      "0    -19.954811 -16.433606 -17.487852  -8.719210 -20.632442 -10.905085   \n",
      "1     -9.508157 -26.955185 -21.083977   6.907172 -59.341134  -4.286610   \n",
      "2      0.809929  10.144052   9.228088   5.665635  12.362444   3.973779   \n",
      "3   -123.508385  18.913526  17.348528  -2.455991 -15.565873  -4.767169   \n",
      "4    -20.731190  34.914525  35.485768  36.177857   6.072711  42.933581   \n",
      "..          ...        ...        ...        ...        ...        ...   \n",
      "243   18.312351  12.566338   5.515637 -27.348667  15.448262   7.275888   \n",
      "245   -1.148262   8.467049  -0.114455 -10.414778  12.716688  -2.676313   \n",
      "246   13.466629 -13.702735 -13.987631 -13.901399   7.169808 -10.081230   \n",
      "250  139.310603   3.281438   5.459505  52.726456  44.286717  24.954014   \n",
      "253   26.520680  16.860032  19.141055 -22.625055  -3.983444   9.649441   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -11.486981 -11.028392 -11.023154 -12.867178  ...  -4.541427  -9.366458   \n",
      "1   -14.239269 -14.783737  -5.678222 -31.718479  ... -10.612662   2.114715   \n",
      "2    15.873451   7.062213   7.157007   9.976019  ...  24.189439  16.445837   \n",
      "3    -6.696298  -9.834737  11.485956  -8.200685  ...  22.482563  24.285719   \n",
      "4    27.004574  35.401475  42.297357  -4.025806  ...   0.695303  -4.561413   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -21.978455  16.353342   2.368865  18.001862  ...  19.807374  28.514496   \n",
      "245  -9.194104   3.724670   1.203904   2.011676  ...  -6.961750  -3.996084   \n",
      "246 -17.381295  -7.914818  -9.848694  15.833604  ...  -8.812935   5.344334   \n",
      "250  26.390760  24.043264   2.734916  -7.343359  ... -21.384871   7.099813   \n",
      "253 -25.978306  12.068099  -5.919177   1.965251  ...  15.225644  16.466456   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    50.309784  26.434513  -6.801213  13.013144 -20.335909 -21.521987    0.0   \n",
      "1   -28.163942 -45.635385  -0.690950 -32.822353   8.625378   2.422162   10.0   \n",
      "2   -13.914543  15.055778  18.895564   7.963521  30.752062  19.846606    5.0   \n",
      "3     9.935359  33.942635  19.931861  16.401888  22.526468  30.206736   12.0   \n",
      "4    12.071444  36.673774   7.157727 -28.108585   8.785660  23.234664    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  -7.132987   3.418105  16.906555   1.366985  29.494475   9.015524    0.0   \n",
      "245  18.176577  10.826444  -7.748817  22.869448  -0.945015 -14.261166    5.0   \n",
      "246   1.846139  10.759173  -1.072289   4.317995  16.164728 -13.722173   13.0   \n",
      "250  -4.293618 -23.410877 -22.046427 -18.250770 -27.148912 -36.497113   14.0   \n",
      "253 -11.009552   4.843347  11.752879   0.610784   4.483507  13.499742    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns]])\n",
      " list([             0          1          2          3          4          5  \\\n",
      "0   -30.365461 -10.150289 -11.331446 -16.552408 -28.335586 -10.571514   \n",
      "1     9.619197   5.503914  -7.074965  -3.140734 -27.178023 -12.145564   \n",
      "2   -10.744765   6.124968   2.344856  16.922647  10.645652  18.920972   \n",
      "3     5.535054  -4.611588  -7.457842   7.283246  30.775917  -6.707535   \n",
      "4   -46.863993  36.192333  26.598260  -3.781843   7.625529  -0.983167   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  -6.956343   4.427302  21.880992  12.054623  14.863074  21.063484   \n",
      "245  40.459901   1.701246  -5.947764 -10.960779  26.891543   4.978756   \n",
      "246 -33.568456  13.277961  -6.619828   9.398019   8.835226  -4.324007   \n",
      "250 -34.021610  20.977728  13.129922  40.966629 -12.199793  20.991135   \n",
      "253  -6.948300   3.662450   0.128751   4.072000  12.572381  -2.755316   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -16.420266 -12.748386  -6.911270 -28.697455  ...  16.348630  10.183579   \n",
      "1    -2.586205 -14.734001 -12.227551  11.702215  ...   2.300221   5.201400   \n",
      "2    10.638796  21.701198  21.068120  21.731325  ... -12.258449  -4.195392   \n",
      "3    10.326189  -4.120860 -12.003317 -12.554638  ...  31.412484  14.526739   \n",
      "4   -10.539357   0.064942   5.773398  -3.777487  ...  18.809380  33.373275   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243  19.299437  25.872273  25.178795  39.493114  ...  19.307933 -13.639820   \n",
      "245 -10.106285  13.278570  12.014700  26.515074  ...   5.674248  12.155385   \n",
      "246   6.757713   1.263918  -0.353903  12.978219  ... -13.051855   9.127246   \n",
      "250  44.647514  16.358145  26.088160  -0.993432  ...  -7.778364 -10.187515   \n",
      "253  15.073170  -1.983752  -3.874926  -3.052807  ...  17.019331   5.036755   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0   -40.219347  22.486112  10.231475 -16.956457  17.001007   5.944967    0.0   \n",
      "1   -22.691958  14.126497   0.307737  -6.076287   1.545354   1.731212   10.0   \n",
      "2    -2.193991  -8.997109 -13.033725   7.496970  -5.475560  -1.797212    5.0   \n",
      "3     1.402709  66.527083  26.137423  20.230482  35.743580  31.180137   12.0   \n",
      "4    23.818586  36.941419  23.234925  53.333803  28.249598  39.900291    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243   6.109234   7.386477   4.175835  13.013605   4.819658  20.717031    0.0   \n",
      "245  -5.532591   0.541200   2.567786 -11.014168   3.685620  -0.444140    5.0   \n",
      "246  12.089462   0.848404  -8.785393  11.275307  10.645737   3.104064   13.0   \n",
      "250  -9.779676 -10.114383 -11.395138 -10.442610  -1.518751 -10.801710   14.0   \n",
      "253 -47.152470 -17.196348  -8.743312 -30.625648 -21.736094  -5.664845    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0     1.156869  -2.449895  -5.886379 -16.528439 -66.641327  -6.012829   \n",
      "1     9.995738   8.337709   4.593945   8.983515  10.256750  14.292282   \n",
      "2    -0.288475   7.514801   2.965813  19.223730 -15.726574  10.766074   \n",
      "3    -6.939788  -6.504198 -17.336435  -6.546753   2.481261 -15.306954   \n",
      "4   -33.056799  40.309194  33.910752  22.607983  25.872314  23.102291   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243 -30.846291 -26.020109  -0.970418  -1.005224 -22.919530   1.566388   \n",
      "245  73.416845  10.699166  11.009574  10.098344  14.922637  14.718962   \n",
      "246 -56.527921 -18.820795 -19.219090  -1.413332 -40.581165 -27.213453   \n",
      "250 -39.148098 -13.464139   1.494951  31.145676 -39.944107   6.914470   \n",
      "253   5.825525  13.130204  16.262379  13.977830  24.299183  14.732634   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -24.858889  -3.477535  -3.812908 -31.209049  ...   5.948674  24.498304   \n",
      "1     0.885649  12.397371  15.023767  15.673249  ...   6.561145   9.687610   \n",
      "2     6.346774  -5.451121  -0.475784 -35.900824  ...  -7.087403 -13.521961   \n",
      "3     0.837864 -15.633682  -8.959703   9.400927  ...  28.876783  25.442107   \n",
      "4    19.178860  14.069262  20.888834  -5.603524  ...  10.233184  22.539575   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243  -3.405510  10.660924  13.045382  26.293805  ...  10.906049  -0.733187   \n",
      "245  -4.191503  25.718488  12.151522  15.441045  ...   0.174932   4.626953   \n",
      "246 -16.667941 -29.256598 -25.917236 -22.739637  ...   2.910665  21.457403   \n",
      "250  37.591976   3.006102   6.698232 -20.581657  ...  -0.491758 -14.407367   \n",
      "253  21.849937  15.451672  11.342791  12.382536  ...  20.985943  11.300530   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0   -55.319252  -5.260526  12.079073 -19.672142  22.109247  22.200924    0.0   \n",
      "1    22.425809  25.565666   9.476909  31.071327  12.506093   3.708268   10.0   \n",
      "2   -21.360309   4.385437  -6.222262   0.632713  -2.758643 -14.281887    5.0   \n",
      "3    12.397745  58.026222  29.211427  27.981511  39.047459  39.193122   12.0   \n",
      "4    27.599006  20.987293   7.923811  59.408725   6.977596  20.699439    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  -9.744374  -6.860809   6.918459  -4.754379  -4.884617  -7.160952    0.0   \n",
      "245  11.850055  -2.273221  -6.527715 -15.209920  -3.434776 -14.237977    5.0   \n",
      "246 -18.736053  -9.556574  -1.577552 -11.473171  13.522279   5.818121   13.0   \n",
      "250 -23.968227 -11.786941  -9.499284 -29.865490  -7.215879 -17.628733   14.0   \n",
      "253 -51.287472  -3.016672  14.055930 -19.519487 -26.295904  -1.990776    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0    -5.056129   8.482432   5.390734   0.690385 -13.201880   3.757192   \n",
      "1   -21.807498   7.713395   9.038787  19.521887 -40.494477  18.700729   \n",
      "2     9.805843   7.926330  11.899646   8.812050  20.762432  19.389863   \n",
      "3    -7.212130  15.777846  11.306893  -6.483710  35.251008   7.080176   \n",
      "4   -58.046293  42.519941  38.041443  33.131590  11.074816  41.161505   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243 -10.866973 -19.161328  -8.579881 -14.920611 -22.094750 -11.538656   \n",
      "245  24.182816   9.534964   5.663302  15.392876   4.881711   5.734885   \n",
      "246 -22.810054  -6.107067  -7.092601 -19.886989 -26.841510 -27.461924   \n",
      "250 -36.058773  -8.437167   2.702673  26.120716 -13.172210  10.252818   \n",
      "253  -2.256930  14.951368  11.181938   6.137643   3.418499  12.677286   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0    -8.592201  -1.137213   2.697915 -14.775067  ... -14.603111   9.299025   \n",
      "1   -11.951902   1.251682  18.875904  19.535505  ...   4.700739  13.224225   \n",
      "2    11.787796  17.774280  13.462510   8.143119  ...  -2.409930  -2.993164   \n",
      "3    -8.344574  19.334002  17.002138  30.255670  ...  27.756918  28.741602   \n",
      "4    24.709232  27.723326  38.729270  -5.517825  ...   3.535256  15.353888   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243  -0.577467  -3.471044   1.483107   6.136277  ...   9.615708  13.643330   \n",
      "245  -0.074786  17.818587   8.018617   4.176883  ...  -4.564210   1.793009   \n",
      "246 -31.570041 -26.873676 -23.262583 -10.475656  ...   1.010823  19.294384   \n",
      "250  34.858593   7.702260   9.556059   0.172320  ...  -3.943494 -25.529659   \n",
      "253  15.443426  15.127616  14.942919  15.572418  ...  22.739986  26.531927   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0   -42.366729 -24.817148 -13.218471 -39.249133  -4.673933   0.134125    0.0   \n",
      "1    26.445247  12.361765   8.411903  44.069314  20.709768   9.136972   10.0   \n",
      "2   -11.157917  -4.981819   3.459961  10.907537  19.461394  10.366055    5.0   \n",
      "3    16.911360  48.874814  34.154589   4.612885  48.690264  41.645292   12.0   \n",
      "4    -0.995073   2.985795 -10.694711  15.344495  -8.628323   3.855104    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  -7.316778   0.800144  18.052184 -19.886583 -10.231987 -18.764810    0.0   \n",
      "245  25.407048   0.984781  -4.128762  12.665836  -4.912636  -4.201752    5.0   \n",
      "246   1.142546  -3.803176  -2.031635  -0.767315  10.250908  11.351913   13.0   \n",
      "250 -24.066914  -4.001155 -11.707579 -15.253782 -12.414370 -13.881524   14.0   \n",
      "253 -46.895855 -11.960884   0.190725 -24.181778 -43.522243   1.359612    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0    -9.678749  -5.623320  -9.795320 -13.344297 -25.533029  -9.676516   \n",
      "1   -21.989290 -24.844888 -19.116160  11.435725 -38.722697   0.718088   \n",
      "2   -14.541140   9.220488  12.112677  -8.938443   3.074910  -7.984098   \n",
      "3    -8.918052  31.850326  30.063316   7.997962  37.155000  20.221452   \n",
      "4   -82.098256  31.455168  34.380325  30.425776  20.884874  37.893067   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  -2.246002  -7.399843  -1.140434 -18.255772 -26.958920  -0.811076   \n",
      "245 -48.827655 -35.277450 -26.912270  -1.874055 -34.249797 -19.997563   \n",
      "246 -10.562850  -3.941268   8.486224 -14.491043  -7.106691  -5.237348   \n",
      "250 -42.082748 -19.342848  -0.232531  39.402397  -1.099633  14.432354   \n",
      "253  15.734000  27.120382  24.324482  19.161196  34.306000  30.840122   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -25.295692   0.379275  -9.868433   8.915428  ... -15.825933 -15.592626   \n",
      "1   -16.338275 -12.753122   4.372868 -16.853451  ...   3.594708   3.067107   \n",
      "2   -15.115151  -4.598324  -8.309597  14.602692  ...   8.530933   6.815420   \n",
      "3    -3.418764  30.740890  32.763834  51.902483  ...  27.453883  26.802708   \n",
      "4    15.044917  26.201072  32.233002 -13.689715  ...  15.565054  24.897748   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243   4.719399   6.301973   3.283552  -4.264810  ...  18.194083  22.249763   \n",
      "245 -12.320281 -13.583549  -6.467853 -14.242105  ...   2.688414  11.358033   \n",
      "246  -1.916154  -5.330405  -4.076913   6.901446  ... -11.761286   6.850869   \n",
      "250  31.934629   5.445789  12.887076 -17.475370  ...   8.766645  25.533857   \n",
      "253  16.468344  32.848942  29.895151  36.910748  ...  20.182587  35.961880   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    -2.337464   0.381190  -4.266922 -14.359122  -2.423964 -15.319850    0.0   \n",
      "1    23.776189  -2.132511  17.465853  25.005502  23.256227  16.807184   10.0   \n",
      "2     9.655736   4.376392  13.379627   9.582766  24.983541  21.842444    5.0   \n",
      "3    15.580492  35.643608  26.808365   9.092105  29.946242  30.469185   12.0   \n",
      "4    -7.150763  -9.710102   2.059174 -24.646665   0.610945  18.270807    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243  -0.501503  14.699261  22.783682 -16.751725  -7.780614 -22.347776    0.0   \n",
      "245  22.898134  18.623740   8.299856   9.180046  10.932853  12.241196    5.0   \n",
      "246  -5.233993 -10.874479 -10.630767 -19.662329 -12.060034  -1.409743   13.0   \n",
      "250 -18.958687  15.452668   7.466041   7.030146  -9.324376   0.899756   14.0   \n",
      "253 -88.614777 -30.383993 -11.047874 -47.826515 -51.528523  -7.067924    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0   -34.029318 -32.114535 -32.586026 -18.314403 -39.049087 -28.217715   \n",
      "1    24.738732  -3.280579   1.126144   8.507874  -5.231135  11.349145   \n",
      "2   -25.737252   2.732387   6.772879  -4.311196 -18.841827  -1.288174   \n",
      "3   -19.988404   2.493557   7.423235  -3.029756  -1.847752 -10.597967   \n",
      "4   -98.202686  22.490566  27.253861  25.903995  -1.855468  27.293391   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  14.019220 -19.291635 -11.909470  -0.884396 -31.861173   3.906654   \n",
      "245 -40.084459 -30.213658 -28.570801  -5.740676 -25.504625 -14.164729   \n",
      "246  -5.791407  -5.696637  -0.099657 -11.452840 -14.939465  -3.685325   \n",
      "250 -71.843796 -14.525453   0.138160  45.663612  -6.965661  25.726843   \n",
      "253  30.556507   2.815165  18.784531  11.861810   9.712448  28.973991   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -23.937691 -30.122204 -25.321320 -26.640018  ... -10.405347  -3.195154   \n",
      "1    -5.340679   4.985765  12.432304  -8.303195  ...  -7.149866  -2.049255   \n",
      "2     9.770393  -5.870954   6.748605   4.065500  ...  18.844939   4.534624   \n",
      "3   -15.898161  -1.520620  -7.016529   4.710850  ...  10.120523  13.456703   \n",
      "4    16.534297  12.901780  34.690618  -8.095849  ...   9.006317  15.817390   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243   5.774821   6.042346   1.388829  -6.088975  ...  27.864498  31.735516   \n",
      "245 -13.930545 -12.800101  -3.269580  -6.589552  ...  -3.332898 -25.606819   \n",
      "246 -10.967903  -3.296390  -2.706495   7.795779  ...  -1.469154   6.088633   \n",
      "250  30.453848  17.469267  23.256205  25.784006  ...  17.649296  27.153425   \n",
      "253   6.012367  32.790272  28.195579  29.232742  ...  40.529068  50.108723   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    29.362587  13.557388   6.745253  24.737063  -1.478378   4.358064    0.0   \n",
      "1     4.607951 -13.968566  10.682049  -3.884948  17.145306  15.114727   10.0   \n",
      "2    32.892447  23.390310  23.482976  25.909957  25.804961  11.609620    5.0   \n",
      "3     8.415991   5.473934  10.555448  -8.414853  12.157954  24.537216   12.0   \n",
      "4   -23.672355 -17.633808  10.732177 -56.772679  22.496945  32.162428    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243 -31.252386   9.363677  16.256330  -8.959850   0.394088 -27.644384    0.0   \n",
      "245  31.748542   0.557108  -2.549438   2.096661  -3.584403   5.792356    5.0   \n",
      "246   3.543758   8.736065   0.004953  -0.214331   4.065150  -0.659109   13.0   \n",
      "250   7.943738  20.618376  17.361618   4.995756   2.743247  10.024766   14.0   \n",
      "253 -41.686237  -4.171104   9.305798 -20.362534 -30.491354   2.108976    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns]])\n",
      " list([             0          1          2          3          4          5  \\\n",
      "0   -30.365461 -10.150289 -11.331446 -16.552408 -28.335586 -10.571514   \n",
      "1    16.352505  -1.382216  -3.737330  -6.441069  -2.179564  -4.548553   \n",
      "2    28.680750   5.363111   7.846627  10.799551  25.199766   9.925851   \n",
      "3    25.177320 -11.411666  -3.965030  -1.971574  36.135224  -8.079894   \n",
      "4    -2.129043  -2.727813  -0.231332   1.711546  -4.345160  -2.533794   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  25.889250  15.367246   3.373403 -19.092958  23.878752  -0.333913   \n",
      "245  10.093739  25.073274  15.982798  -5.930758  11.564861  17.482482   \n",
      "246 -65.875070 -13.910389  -8.230255  -1.407712 -36.866823 -11.310917   \n",
      "250  -9.650134  12.662954   4.334095  12.698063  -5.965759   7.015118   \n",
      "253  24.874542  19.454044  14.789652  24.397077  25.135026   0.771751   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -16.420266 -12.748386  -6.911270 -28.697455  ...   1.239601  -0.386368   \n",
      "1   -15.702785   4.733616  -8.297001   4.115984  ...   5.251277   4.015508   \n",
      "2    13.263838  20.311485   9.252942  24.104797  ... -12.256749 -10.624358   \n",
      "3     6.648679   5.842732  -2.543939  24.043087  ...  15.374823   2.636899   \n",
      "4     3.646301  -8.383315 -12.091149 -43.581179  ...  13.840515  27.285520   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -19.013382   1.604374  -5.494259  11.355676  ...  15.692410 -19.386428   \n",
      "245  -4.697566  18.856527  18.032894   0.240000  ...   5.154217  10.564885   \n",
      "246 -14.457366 -16.096883  -3.785280 -10.168857  ...  -1.521919  18.708921   \n",
      "250  15.340328   4.160679  10.498703  -7.819777  ...  -5.284569  -3.915860   \n",
      "253  25.994240   7.743110  -0.757395  19.225686  ...   8.941948   4.154771   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    19.279126   3.954614  -3.410700   0.631322  -3.929794  -1.308544    0.0   \n",
      "1    23.528056   7.568742   7.412839  23.122322   7.280164   1.310969   10.0   \n",
      "2    20.441000 -16.824257  -4.944206  13.745031  -6.300673  -8.493029    5.0   \n",
      "3    18.975569  45.359248  14.172396   6.833650   8.519727  -0.472798   12.0   \n",
      "4    -0.425951  21.258275   4.774990  44.327760  -0.145923  26.950054    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243 -12.696662   0.605671  -8.012867   0.925483 -18.769699  -3.643043    0.0   \n",
      "245  16.874527   8.459340  -1.499528   1.019263  -6.851688  -4.097659    5.0   \n",
      "246  -0.695259   3.774676   0.456916   4.452521   6.746612   8.941210   13.0   \n",
      "250 -24.163445 -21.229324 -19.678259 -22.540970  -0.709261  -9.176856   14.0   \n",
      "253 -32.135723 -20.311815   1.954862 -28.258098 -25.828570  -6.845559    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0     1.156869  -2.449895  -5.886379 -16.528439 -66.641327  -6.012828   \n",
      "1    22.520332   8.727436   5.791812  -1.848583  -7.854279  -5.785739   \n",
      "2    33.007620  12.795782  16.625761  31.153779  42.951913  32.126254   \n",
      "3     9.067772  -8.478199  -8.772685 -11.633325  18.411607 -22.582128   \n",
      "4   -19.620471  11.681633   8.344445   3.243586 -54.801448 -11.309498   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  43.806561  30.533924  20.981890 -17.281511  41.919544  24.295599   \n",
      "245  58.983556  38.041188  19.513310   6.163936  39.622151  27.921667   \n",
      "246 -33.594480  -6.333338   5.215799  -8.601956 -15.871087  -4.822406   \n",
      "250 -74.968225  -1.831519  11.020890  40.094327 -54.188922  17.281010   \n",
      "253 -13.682923   9.533133  11.133890  -6.765393 -11.429330   8.928809   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -24.858889  -3.477535  -3.812908 -31.209049  ...  11.917401  11.819148   \n",
      "1   -15.513298  -0.375780  -4.244596  11.343514  ...  15.654671  17.312132   \n",
      "2    34.659912  37.952971  30.144393  26.003318  ...  11.867141 -10.461090   \n",
      "3     4.920568 -10.271047 -15.100073   7.736702  ...  34.270122  13.051641   \n",
      "4    -0.268982 -17.101194 -20.740668 -45.477553  ...  16.142780  15.675707   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -18.164129  31.344633  16.725117  45.039127  ...  17.003790   2.405200   \n",
      "245   1.780464  36.026482  23.214341  14.057415  ...  -3.004780  12.453051   \n",
      "246 -16.931537  -7.041318   0.744559  10.574500  ...  -4.501034  20.394830   \n",
      "250  38.847824   9.575432  25.393030   8.170446  ...  -6.891868  -9.927851   \n",
      "253  13.699491  14.286090   5.123309  27.610364  ...  20.850541  11.376494   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0    -3.357177   5.154810  12.576762 -14.788489  20.878984  11.886606    0.0   \n",
      "1    13.543633  18.916091  13.369397  21.290442   9.320759   9.596081   10.0   \n",
      "2     8.509889  16.567954  11.921451  -1.866663  10.067244  -7.727549    5.0   \n",
      "3     9.491641  62.385877  29.275019  -4.390329  25.766548  14.358625   12.0   \n",
      "4    25.135167  22.177876  10.004360  27.204481   8.437420  10.571811    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243 -28.895776   5.012466  14.415730  -2.228127 -25.402811  -8.613295    0.0   \n",
      "245  25.144783   8.051999   0.355208   7.383590  -6.362791  10.076717    5.0   \n",
      "246   3.153326 -10.195641   5.862288 -14.183988  21.084226  16.393249   13.0   \n",
      "250 -14.052649 -10.093236  -6.792151   8.194829  12.628652  -1.773596   14.0   \n",
      "253 -43.697829  -2.699273  17.469793 -17.073861   0.867728  17.251242    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0    -5.056129   8.482432   5.390734   0.690385 -13.201880   3.757192   \n",
      "1    36.090878  20.765783  24.232712  27.645688   9.929265  24.073644   \n",
      "2     6.582380   8.442073   6.092722   5.219876  19.531455  10.088456   \n",
      "3   -21.427214  -2.381853  -6.686841 -10.638518  20.642757  -6.668700   \n",
      "4   -11.190494  43.011069  39.336526  23.805517 -21.510639  21.251060   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  32.914700  19.380751  19.187895 -26.405573  16.660807  30.042438   \n",
      "245  60.253155  19.507685  13.715955  22.184534  24.222609  21.304931   \n",
      "246 -14.365735  -3.342563   5.281680 -11.624981   4.856350  -3.192781   \n",
      "250 -50.703116 -14.182168  -2.431186  34.699803 -16.880570   4.025235   \n",
      "253  17.733312  28.880633  19.955080  -5.232879  34.146677  28.856472   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0    -8.592201  -1.137213   2.697915 -14.775067  ...   6.011110  26.170811   \n",
      "1    18.119493  26.733122  31.243864  47.441727  ...   7.866227   3.696713   \n",
      "2     2.502037  21.975266  13.504318  28.674628  ...   1.187496 -13.090667   \n",
      "3    -1.512245  12.559105   9.765120  26.676058  ...  45.930810  26.793570   \n",
      "4    21.961920  18.090480  20.476716 -16.634935  ...   2.683087  16.276373   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -30.452219  40.574406  26.504837  54.015884  ...  10.590182  -1.433398   \n",
      "245   3.907564  29.851710  14.935535  11.857182  ... -11.008662 -20.476043   \n",
      "246  -2.591371  -5.468661  -0.232633  13.827334  ...   3.263475  23.248953   \n",
      "250  39.612868  -3.232596   6.406111 -11.364877  ...  -7.226915  20.908110   \n",
      "253  -3.871566  28.838672  18.713659  44.635905  ...  12.475520  16.888076   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0   -25.499509 -15.433670   9.851047 -23.324309  12.001297  24.409874    0.0   \n",
      "1     8.810502  12.829723  10.678328  25.688507  16.692069   4.966752   10.0   \n",
      "2   -30.968526  -3.583855  -1.573725   5.068019   5.015039  -5.695254    5.0   \n",
      "3    33.440775  90.235993  51.133318  32.396506  54.456936  38.471372   12.0   \n",
      "4   -12.609796 -14.220472   1.830250  12.527509  10.516640  17.763167    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243 -30.584322  -2.713084  26.583643   7.327692  25.062530 -15.757200    0.0   \n",
      "245  46.940715   8.929644  -3.602352  22.859468  -7.994067   7.280396    5.0   \n",
      "246 -17.753895   0.505741  12.551472  -6.588999  28.009569  26.060347   13.0   \n",
      "250  16.112255  -3.496075  -5.988017  15.050259  29.625344  -5.588782   14.0   \n",
      "253 -43.953456 -20.497418 -10.892999 -39.821820 -49.622790  -6.895003    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns],              0          1          2          3          4          5  \\\n",
      "0    -9.678749  -5.623320  -9.795320 -13.344297 -25.533029  -9.676516   \n",
      "1   -14.787542   8.654541  13.649046  22.788524  -6.376388  13.565511   \n",
      "2     4.191272  25.680628  23.837116  33.188886   6.568336  27.298339   \n",
      "3     3.332591  17.325206  12.431872  -0.292033  17.164388   6.674118   \n",
      "4    -3.242230  52.717685  52.034085  43.561166 -13.937007  45.880756   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "243  33.302658  30.925133  13.904303 -36.269726  35.443176   8.721170   \n",
      "245 -12.818099   7.990832   5.074563  13.047944  12.481680   7.844673   \n",
      "246 -19.789820   9.877687  10.178302  -3.100027  11.476092   5.485318   \n",
      "250 -15.623932  -4.591664  11.303625  41.520940   0.224646  17.809526   \n",
      "253  75.533102  11.653425   7.660983 -20.106292  19.526348  25.212360   \n",
      "\n",
      "             6          7          8          9  ...      59992      59993  \\\n",
      "0   -25.295692   0.379275  -9.868433   8.915428  ...   2.788833  15.341499   \n",
      "1     0.268815  10.557938  14.047730   6.445056  ...   4.080785  22.175056   \n",
      "2    12.622334  16.585580  19.543767  -6.148704  ...  10.472186   5.759355   \n",
      "3   -12.495150  19.191946  14.283919  26.305705  ...  29.178839  32.583772   \n",
      "4    40.767311  34.065876  50.700452   3.626784  ...   0.114472   7.804093   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "243 -36.931427  21.117540   6.612627  40.421917  ...  13.802366   2.849678   \n",
      "245   2.784566  15.669099  11.198077  12.533778  ...  -5.267862 -28.867121   \n",
      "246  -4.224465   3.411184   3.878333  15.095757  ...  -3.036837  11.432945   \n",
      "250  46.042619  13.575319  18.969004  -2.455038  ...  -4.267259  34.002614   \n",
      "253 -49.482532  30.530721   6.592375  33.026210  ...  27.659384  34.974307   \n",
      "\n",
      "         59994      59995      59996      59997      59998      59999  label  \\\n",
      "0   -15.781096  -1.966828  10.700739 -23.982484   6.737133  13.543833    0.0   \n",
      "1     8.958762  -3.195084   5.754073  26.122473  15.133528  16.682060   10.0   \n",
      "2    -2.985481  19.664401   3.921946  25.903258  12.533810   9.232214    5.0   \n",
      "3    18.931240  54.268890  29.900326  27.773743  37.919282  43.339812   12.0   \n",
      "4     7.218335 -11.439462   0.877457  -4.806643   4.437482  11.633721    7.0   \n",
      "..         ...        ...        ...        ...        ...        ...    ...   \n",
      "243 -15.822139 -12.305102  16.380404  -2.582023   6.403317 -19.841056    0.0   \n",
      "245  20.794528   0.572383  -7.864982   4.470702 -20.380432   7.078761    5.0   \n",
      "246  17.191807   3.310063   3.388924 -17.106790   8.982513   5.626297   13.0   \n",
      "250  20.108738  20.269511  17.548552  23.488552  45.920583  13.184510   14.0   \n",
      "253 -39.040562 -14.710651  -7.458034 -29.709865 -47.221551  -3.965048    5.0   \n",
      "\n",
      "     participant  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "243            2  \n",
      "245            2  \n",
      "246            2  \n",
      "250            2  \n",
      "253            2  \n",
      "\n",
      "[113 rows x 60002 columns]])]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Train on no_average, with error rate ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 8.  7. 11.  6. 10.  5. 11.  5. 13.  4.  7. 13.  9.  2.  9.  4. 14.  6.\n 10.  7.  8. 13.  6.  2. 11. 10.  0.  4.  5.  2.  9.  6.  7. 10.  7.  2.\n  0.  5. 13. 14.  5.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a682aef21773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_test_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    227\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr',\n\u001b[1;32m    228\u001b[0m                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 8.  7. 11.  6. 10.  5. 11.  5. 13.  4.  7. 13.  9.  2.  9.  4. 14.  6.\n 10.  7.  8. 13.  6.  2. 11. 10.  0.  4.  5.  2.  9.  6.  7. 10.  7.  2.\n  0.  5. 13. 14.  5.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train_n)):\n",
    "    for j in range(len(X_train_n[i])):\n",
    "        model.fit(X_train_n[i][j], y_train_n[i][j])\n",
    "        print(np.mean(model.predict(X_test_n[i][j]) != y_test_n[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Train on average_trials, with error rate ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t, y_train_t)\n",
    "\n",
    "np.mean(model.predict(X_test_t) != y_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Train on average_trials_and_participants, with error rate ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tp, y_train_tp)\n",
    "\n",
    "np.mean(model.predict(X_test_tp) != y_test_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-853373634d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_n' is not defined"
     ]
    }
   ],
   "source": [
    "X_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 60000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 60000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
