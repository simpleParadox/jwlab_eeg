{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup_jwlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jwlab.constants import cleaned_data_filepath\n",
    "participants = [\"107\", \"904\", \"905\", \"906\"] #, \"111\", \"908\"]\n",
    "\n",
    "from jwlab.ml_prep import prep_ml\n",
    "downsample_num = 100\n",
    "X,y,p,w = prep_ml(cleaned_data_filepath, participants, averaging=\"average_trials_and_participants\", downsample_num=downsample_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, d) = X.shape\n",
    "assert n == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC(C=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# model = BaggingClassifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def dist(a, b):\n",
    "    a = np.reshape(a, (-1, downsample_num))\n",
    "    b = np.reshape(b, (-1, downsample_num))\n",
    "    \n",
    "    dists = np.array([fastdtw(a[i, :], b[i, :])[0] for i in range(a.shape[0])])\n",
    "    print(dists)\n",
    "    \n",
    "    return np.sum(np.square(dists))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = {'n_neighbors':[2, 4, 8]}\n",
    "# model = GridSearchCV(KNeighborsClassifier(metric=DTW), parameters, cv=3, verbose=1)\n",
    "model = KNeighborsClassifier(metric=dist, n_neighbors=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = [\n",
    "  # {'C': np.logspace(-10, -5, 3)}\n",
    " # ]\n",
    "\n",
    "# tuned_model = GridSearchCV(model, param_grid)\n",
    "# tuned_model.fit(X, y)\n",
    "\n",
    "# tuned_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(model.predict(X_test) != y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import eval_normal\n",
    "errs = eval_normal(model, X, y, 100, random_state=21)\n",
    "np.mean(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import eval_across_categories\n",
    "errs = eval_across_categories(model, X, y, p, 100, random_state=43598)\n",
    "print(\"\\n---\\n\")\n",
    "for j in range(errs.shape[0]):\n",
    "   print(np.mean(errs[j, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs2 = eval_across_categories(model, X, y, w, 100, random_state=498)\n",
    "print(\"\\n---\\n\")\n",
    "for j in range(errs2.shape[0]):\n",
    "   print(np.mean(errs2[j, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
